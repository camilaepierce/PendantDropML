Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 8000]               648,000
│    └─ReLU: 2-2                         [100, 8000]               --
│    └─Linear: 2-3                       [100, 80]                 640,080
==========================================================================================
Total params: 1,288,080
Trainable params: 1,288,080
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 128.81
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 6.46
Params size (MB): 5.15
Estimated Total Size (MB): 11.65
==========================================================================================
Epoch 1
-------------------------------
loss: 17.178326  [   79/ 7851]
loss: 12.206283  [  547/ 7851]
loss: 10.914618  [ 1015/ 7851]
loss: 9.938622  [ 1483/ 7851]
loss: 9.773174  [ 1951/ 7851]
loss: 6.121624  [ 2419/ 7851]
loss: 9.432230  [ 2887/ 7851]
loss: 5.884112  [ 3355/ 7851]
loss: 5.814712  [ 3823/ 7851]
loss: 4.851971  [ 4290/ 7851]
loss: 5.653223  [ 4758/ 7851]
loss: 6.360548  [ 5226/ 7851]
loss: 4.843977  [ 5694/ 7851]
loss: 7.400653  [ 6162/ 7851]
loss: 8.530547  [ 6630/ 7851]
loss: 6.426027  [ 7098/ 7851]
loss: 9.680829  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 6.921958 
Epoch 2
-------------------------------
loss: 8.762300  [   79/ 7851]
loss: 11.508518  [  547/ 7851]
loss: 10.632367  [ 1015/ 7851]
loss: 8.306655  [ 1483/ 7851]
loss: 6.432346  [ 1951/ 7851]
loss: 6.563695  [ 2419/ 7851]
loss: 8.404485  [ 2887/ 7851]
loss: 5.463329  [ 3355/ 7851]
loss: 5.431908  [ 3823/ 7851]
loss: 5.078425  [ 4290/ 7851]
loss: 4.199954  [ 4758/ 7851]
loss: 6.957891  [ 5226/ 7851]
loss: 4.502887  [ 5694/ 7851]
loss: 7.403701  [ 6162/ 7851]
loss: 7.095657  [ 6630/ 7851]
loss: 5.987179  [ 7098/ 7851]
loss: 9.177143  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.089168 
Epoch 3
-------------------------------
loss: 7.101141  [   79/ 7851]
loss: 10.723951  [  547/ 7851]
loss: 8.434531  [ 1015/ 7851]
loss: 7.861804  [ 1483/ 7851]
loss: 6.338260  [ 1951/ 7851]
loss: 6.451449  [ 2419/ 7851]
loss: 8.676955  [ 2887/ 7851]
loss: 5.610966  [ 3355/ 7851]
loss: 5.737212  [ 3823/ 7851]
loss: 4.602636  [ 4290/ 7851]
loss: 5.168898  [ 4758/ 7851]
loss: 6.775865  [ 5226/ 7851]
loss: 4.566113  [ 5694/ 7851]
loss: 7.227528  [ 6162/ 7851]
loss: 7.145530  [ 6630/ 7851]
loss: 5.904050  [ 7098/ 7851]
loss: 9.130699  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.318742 
Epoch 4
-------------------------------
loss: 7.325210  [   79/ 7851]
loss: 12.234337  [  547/ 7851]
loss: 8.773335  [ 1015/ 7851]
loss: 7.744095  [ 1483/ 7851]
loss: 6.505290  [ 1951/ 7851]
loss: 6.360138  [ 2419/ 7851]
loss: 9.482401  [ 2887/ 7851]
loss: 4.739414  [ 3355/ 7851]
loss: 5.267853  [ 3823/ 7851]
loss: 4.569812  [ 4290/ 7851]
loss: 4.001905  [ 4758/ 7851]
loss: 6.090496  [ 5226/ 7851]
loss: 5.309000  [ 5694/ 7851]
loss: 6.952277  [ 6162/ 7851]
loss: 6.689258  [ 6630/ 7851]
loss: 5.320062  [ 7098/ 7851]
loss: 10.146231  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 7.163859 
Epoch 5
-------------------------------
loss: 7.593741  [   79/ 7851]
loss: 12.061140  [  547/ 7851]
loss: 8.834496  [ 1015/ 7851]
loss: 7.999737  [ 1483/ 7851]
loss: 6.189213  [ 1951/ 7851]
loss: 4.729831  [ 2419/ 7851]
loss: 8.918396  [ 2887/ 7851]
loss: 5.428924  [ 3355/ 7851]
loss: 5.062104  [ 3823/ 7851]
loss: 4.233267  [ 4290/ 7851]
loss: 4.435958  [ 4758/ 7851]
loss: 6.605541  [ 5226/ 7851]
loss: 5.663218  [ 5694/ 7851]
loss: 7.424495  [ 6162/ 7851]
loss: 7.057897  [ 6630/ 7851]
loss: 5.396264  [ 7098/ 7851]
loss: 8.862860  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 6.002187 
Epoch 6
-------------------------------
loss: 7.578522  [   79/ 7851]
loss: 11.173394  [  547/ 7851]
loss: 8.650423  [ 1015/ 7851]
loss: 8.262684  [ 1483/ 7851]
loss: 6.448356  [ 1951/ 7851]
loss: 5.333186  [ 2419/ 7851]
loss: 9.003600  [ 2887/ 7851]
loss: 5.185399  [ 3355/ 7851]
loss: 5.524064  [ 3823/ 7851]
loss: 4.471085  [ 4290/ 7851]
loss: 4.447287  [ 4758/ 7851]
loss: 6.373415  [ 5226/ 7851]
loss: 4.264544  [ 5694/ 7851]
loss: 7.310641  [ 6162/ 7851]
loss: 6.856380  [ 6630/ 7851]
loss: 5.754528  [ 7098/ 7851]
loss: 9.099388  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 6.401436 
Epoch 7
-------------------------------
loss: 7.149893  [   79/ 7851]
loss: 11.354054  [  547/ 7851]
loss: 7.949775  [ 1015/ 7851]
loss: 9.253757  [ 1483/ 7851]
loss: 6.428108  [ 1951/ 7851]
loss: 5.344668  [ 2419/ 7851]
loss: 8.964142  [ 2887/ 7851]
loss: 5.121515  [ 3355/ 7851]
loss: 5.519496  [ 3823/ 7851]
loss: 4.016966  [ 4290/ 7851]
loss: 4.978434  [ 4758/ 7851]
loss: 6.489986  [ 5226/ 7851]
loss: 4.913946  [ 5694/ 7851]
loss: 7.252217  [ 6162/ 7851]
loss: 6.668243  [ 6630/ 7851]
loss: 5.392444  [ 7098/ 7851]
loss: 8.698536  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.7%, Avg loss: 6.135042 
Epoch 8
-------------------------------
loss: 7.336399  [   79/ 7851]
loss: 11.299480  [  547/ 7851]
loss: 7.768484  [ 1015/ 7851]
loss: 7.856320  [ 1483/ 7851]
loss: 6.140821  [ 1951/ 7851]
loss: 6.312009  [ 2419/ 7851]
loss: 10.757792  [ 2887/ 7851]
loss: 5.301113  [ 3355/ 7851]
loss: 5.492309  [ 3823/ 7851]
loss: 4.474629  [ 4290/ 7851]
loss: 4.663300  [ 4758/ 7851]
loss: 6.651825  [ 5226/ 7851]
loss: 4.522729  [ 5694/ 7851]
loss: 7.223687  [ 6162/ 7851]
loss: 6.701592  [ 6630/ 7851]
loss: 5.644775  [ 7098/ 7851]
loss: 9.224962  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.286626 
Epoch 9
-------------------------------
loss: 7.470916  [   79/ 7851]
loss: 11.349754  [  547/ 7851]
loss: 8.024508  [ 1015/ 7851]
loss: 8.198370  [ 1483/ 7851]
loss: 6.725723  [ 1951/ 7851]
loss: 5.639277  [ 2419/ 7851]
loss: 8.792624  [ 2887/ 7851]
loss: 5.440196  [ 3355/ 7851]
loss: 5.298751  [ 3823/ 7851]
loss: 4.361842  [ 4290/ 7851]
loss: 3.615868  [ 4758/ 7851]
loss: 6.677239  [ 5226/ 7851]
loss: 4.329445  [ 5694/ 7851]
loss: 7.042136  [ 6162/ 7851]
loss: 6.490431  [ 6630/ 7851]
loss: 5.492386  [ 7098/ 7851]
loss: 9.389065  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 6.148499 
Epoch 10
-------------------------------
loss: 7.324504  [   79/ 7851]
loss: 12.268003  [  547/ 7851]
loss: 8.097856  [ 1015/ 7851]
loss: 8.179762  [ 1483/ 7851]
loss: 5.765440  [ 1951/ 7851]
loss: 4.631664  [ 2419/ 7851]
loss: 8.164658  [ 2887/ 7851]
loss: 4.935002  [ 3355/ 7851]
loss: 5.276072  [ 3823/ 7851]
loss: 4.124482  [ 4290/ 7851]
loss: 4.178049  [ 4758/ 7851]
loss: 6.542781  [ 5226/ 7851]
loss: 4.758831  [ 5694/ 7851]
loss: 13.199391  [ 6162/ 7851]
loss: 6.953839  [ 6630/ 7851]
loss: 5.996383  [ 7098/ 7851]
loss: 9.331796  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 6.016302 
Epoch 11
-------------------------------
loss: 6.977477  [   79/ 7851]
loss: 11.424007  [  547/ 7851]
loss: 8.095942  [ 1015/ 7851]
loss: 8.673696  [ 1483/ 7851]
loss: 5.854618  [ 1951/ 7851]
loss: 5.228331  [ 2419/ 7851]
loss: 8.722757  [ 2887/ 7851]
loss: 5.561171  [ 3355/ 7851]
loss: 5.030450  [ 3823/ 7851]
loss: 4.150935  [ 4290/ 7851]
loss: 4.162746  [ 4758/ 7851]
loss: 6.785308  [ 5226/ 7851]
loss: 5.382150  [ 5694/ 7851]
loss: 6.026118  [ 6162/ 7851]
loss: 6.123411  [ 6630/ 7851]
loss: 5.416500  [ 7098/ 7851]
loss: 9.056561  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.901793 
Epoch 12
-------------------------------
loss: 6.832024  [   79/ 7851]
loss: 12.031655  [  547/ 7851]
loss: 8.664028  [ 1015/ 7851]
loss: 7.966695  [ 1483/ 7851]
loss: 6.206388  [ 1951/ 7851]
loss: 4.618223  [ 2419/ 7851]
loss: 8.724407  [ 2887/ 7851]
loss: 5.855129  [ 3355/ 7851]
loss: 5.074480  [ 3823/ 7851]
loss: 3.557934  [ 4290/ 7851]
loss: 3.983151  [ 4758/ 7851]
loss: 7.187770  [ 5226/ 7851]
loss: 4.838693  [ 5694/ 7851]
loss: 7.072097  [ 6162/ 7851]
loss: 6.319600  [ 6630/ 7851]
loss: 6.079820  [ 7098/ 7851]
loss: 8.953850  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 6.034901 
Epoch 13
-------------------------------
loss: 7.235209  [   79/ 7851]
loss: 10.794668  [  547/ 7851]
loss: 8.487556  [ 1015/ 7851]
loss: 7.386021  [ 1483/ 7851]
loss: 6.459445  [ 1951/ 7851]
loss: 4.435482  [ 2419/ 7851]
loss: 8.316084  [ 2887/ 7851]
loss: 5.081082  [ 3355/ 7851]
loss: 5.405155  [ 3823/ 7851]
loss: 4.079280  [ 4290/ 7851]
loss: 3.834028  [ 4758/ 7851]
loss: 6.466844  [ 5226/ 7851]
loss: 4.926946  [ 5694/ 7851]
loss: 7.909658  [ 6162/ 7851]
loss: 7.005783  [ 6630/ 7851]
loss: 5.604792  [ 7098/ 7851]
loss: 8.411448  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.781876 
Epoch 14
-------------------------------
loss: 7.523148  [   79/ 7851]
loss: 11.394748  [  547/ 7851]
loss: 7.783230  [ 1015/ 7851]
loss: 7.612562  [ 1483/ 7851]
loss: 6.136433  [ 1951/ 7851]
loss: 5.271336  [ 2419/ 7851]
loss: 9.126891  [ 2887/ 7851]
loss: 5.375384  [ 3355/ 7851]
loss: 5.366920  [ 3823/ 7851]
loss: 4.114266  [ 4290/ 7851]
loss: 3.832179  [ 4758/ 7851]
loss: 6.614650  [ 5226/ 7851]
loss: 4.427280  [ 5694/ 7851]
loss: 7.167489  [ 6162/ 7851]
loss: 6.269449  [ 6630/ 7851]
loss: 5.245859  [ 7098/ 7851]
loss: 9.069324  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 5.918687 
Epoch 15
-------------------------------
loss: 7.844132  [   79/ 7851]
loss: 11.601969  [  547/ 7851]
loss: 8.738883  [ 1015/ 7851]
loss: 8.354879  [ 1483/ 7851]
loss: 5.999322  [ 1951/ 7851]
loss: 5.112541  [ 2419/ 7851]
loss: 8.732653  [ 2887/ 7851]
loss: 5.364244  [ 3355/ 7851]
loss: 5.930860  [ 3823/ 7851]
loss: 4.178893  [ 4290/ 7851]
loss: 4.483847  [ 4758/ 7851]
loss: 6.288464  [ 5226/ 7851]
loss: 4.955005  [ 5694/ 7851]
loss: 8.057938  [ 6162/ 7851]
loss: 7.388949  [ 6630/ 7851]
loss: 5.349456  [ 7098/ 7851]
loss: 9.597279  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 5.987560 
Epoch 16
-------------------------------
loss: 7.554437  [   79/ 7851]
loss: 11.131678  [  547/ 7851]
loss: 8.726064  [ 1015/ 7851]
loss: 8.548843  [ 1483/ 7851]
loss: 6.538216  [ 1951/ 7851]
loss: 4.906278  [ 2419/ 7851]
loss: 9.207607  [ 2887/ 7851]
loss: 4.382979  [ 3355/ 7851]
loss: 5.360408  [ 3823/ 7851]
loss: 3.927508  [ 4290/ 7851]
loss: 4.351649  [ 4758/ 7851]
loss: 6.377279  [ 5226/ 7851]
loss: 5.363808  [ 5694/ 7851]
loss: 7.160198  [ 6162/ 7851]
loss: 6.879028  [ 6630/ 7851]
loss: 5.684094  [ 7098/ 7851]
loss: 9.084974  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 6.000175 
Epoch 17
-------------------------------
loss: 7.306616  [   79/ 7851]
loss: 10.587591  [  547/ 7851]
loss: 7.811245  [ 1015/ 7851]
loss: 8.532566  [ 1483/ 7851]
loss: 6.095001  [ 1951/ 7851]
loss: 5.107994  [ 2419/ 7851]
loss: 9.607216  [ 2887/ 7851]
loss: 5.882335  [ 3355/ 7851]
loss: 5.287654  [ 3823/ 7851]
loss: 3.788419  [ 4290/ 7851]
loss: 4.014597  [ 4758/ 7851]
loss: 6.324547  [ 5226/ 7851]
loss: 4.370581  [ 5694/ 7851]
loss: 6.838377  [ 6162/ 7851]
loss: 6.585379  [ 6630/ 7851]
loss: 5.700307  [ 7098/ 7851]
loss: 9.158108  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.9%, Avg loss: 6.144232 
Epoch 18
-------------------------------
loss: 7.076977  [   79/ 7851]
loss: 11.102313  [  547/ 7851]
loss: 7.931417  [ 1015/ 7851]
loss: 8.688202  [ 1483/ 7851]
loss: 6.031851  [ 1951/ 7851]
loss: 4.597564  [ 2419/ 7851]
loss: 9.246893  [ 2887/ 7851]
loss: 4.968532  [ 3355/ 7851]
loss: 5.662144  [ 3823/ 7851]
loss: 4.515424  [ 4290/ 7851]
loss: 4.343409  [ 4758/ 7851]
loss: 6.631294  [ 5226/ 7851]
loss: 4.486327  [ 5694/ 7851]
loss: 7.041171  [ 6162/ 7851]
loss: 6.611962  [ 6630/ 7851]
loss: 5.547595  [ 7098/ 7851]
loss: 8.923246  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.887894 
Epoch 19
-------------------------------
loss: 7.175810  [   79/ 7851]
loss: 12.170395  [  547/ 7851]
loss: 8.753204  [ 1015/ 7851]
loss: 8.036612  [ 1483/ 7851]
loss: 5.858778  [ 1951/ 7851]
loss: 5.172771  [ 2419/ 7851]
loss: 8.823844  [ 2887/ 7851]
loss: 5.577990  [ 3355/ 7851]
loss: 5.472838  [ 3823/ 7851]
loss: 4.095733  [ 4290/ 7851]
loss: 3.851636  [ 4758/ 7851]
loss: 5.899917  [ 5226/ 7851]
loss: 4.753659  [ 5694/ 7851]
loss: 7.089456  [ 6162/ 7851]
loss: 6.799012  [ 6630/ 7851]
loss: 5.540231  [ 7098/ 7851]
loss: 9.314816  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 6.009481 
Epoch 20
-------------------------------
loss: 6.952912  [   79/ 7851]
loss: 11.413140  [  547/ 7851]
loss: 8.624660  [ 1015/ 7851]
loss: 8.844577  [ 1483/ 7851]
loss: 6.851231  [ 1951/ 7851]
loss: 5.492833  [ 2419/ 7851]
loss: 8.823600  [ 2887/ 7851]
loss: 5.368510  [ 3355/ 7851]
loss: 5.162073  [ 3823/ 7851]
loss: 4.487635  [ 4290/ 7851]
loss: 3.970262  [ 4758/ 7851]
loss: 6.545892  [ 5226/ 7851]
loss: 4.224204  [ 5694/ 7851]
loss: 6.774362  [ 6162/ 7851]
loss: 6.373982  [ 6630/ 7851]
loss: 5.772029  [ 7098/ 7851]
loss: 8.551166  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 5.808818 
Epoch 21
-------------------------------
loss: 7.190477  [   79/ 7851]
loss: 10.874804  [  547/ 7851]
loss: 9.330516  [ 1015/ 7851]
loss: 8.932313  [ 1483/ 7851]
loss: 6.369533  [ 1951/ 7851]
loss: 4.929297  [ 2419/ 7851]
loss: 9.233273  [ 2887/ 7851]
loss: 5.408560  [ 3355/ 7851]
loss: 5.490480  [ 3823/ 7851]
loss: 3.754867  [ 4290/ 7851]
loss: 4.437838  [ 4758/ 7851]
loss: 6.627787  [ 5226/ 7851]
loss: 4.968030  [ 5694/ 7851]
loss: 7.663136  [ 6162/ 7851]
loss: 6.493933  [ 6630/ 7851]
loss: 5.818943  [ 7098/ 7851]
loss: 15.296432  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.7%, Avg loss: 6.991383 
Epoch 22
-------------------------------
loss: 7.180405  [   79/ 7851]
loss: 11.500438  [  547/ 7851]
loss: 7.789791  [ 1015/ 7851]
loss: 7.892597  [ 1483/ 7851]
loss: 6.020904  [ 1951/ 7851]
loss: 4.649475  [ 2419/ 7851]
loss: 7.650192  [ 2887/ 7851]
loss: 6.056295  [ 3355/ 7851]
loss: 4.991961  [ 3823/ 7851]
loss: 4.283854  [ 4290/ 7851]
loss: 3.880946  [ 4758/ 7851]
loss: 6.453650  [ 5226/ 7851]
loss: 5.051662  [ 5694/ 7851]
loss: 6.828463  [ 6162/ 7851]
loss: 7.448964  [ 6630/ 7851]
loss: 5.719217  [ 7098/ 7851]
loss: 8.855098  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 6.211691 
Epoch 23
-------------------------------
loss: 7.279275  [   79/ 7851]
loss: 11.163787  [  547/ 7851]
loss: 8.106412  [ 1015/ 7851]
loss: 7.381251  [ 1483/ 7851]
loss: 6.116360  [ 1951/ 7851]
loss: 4.885449  [ 2419/ 7851]
loss: 7.633052  [ 2887/ 7851]
loss: 5.319587  [ 3355/ 7851]
loss: 5.294337  [ 3823/ 7851]
loss: 4.236497  [ 4290/ 7851]
loss: 3.893670  [ 4758/ 7851]
loss: 6.079362  [ 5226/ 7851]
loss: 4.764758  [ 5694/ 7851]
loss: 6.864762  [ 6162/ 7851]
loss: 7.016789  [ 6630/ 7851]
loss: 5.171369  [ 7098/ 7851]
loss: 8.668953  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 5.903704 
Epoch 24
-------------------------------
loss: 7.703241  [   79/ 7851]
loss: 10.779818  [  547/ 7851]
loss: 9.391982  [ 1015/ 7851]
loss: 9.056466  [ 1483/ 7851]
loss: 6.078304  [ 1951/ 7851]
loss: 5.051764  [ 2419/ 7851]
loss: 8.778142  [ 2887/ 7851]
loss: 5.159935  [ 3355/ 7851]
loss: 4.989980  [ 3823/ 7851]
loss: 4.112363  [ 4290/ 7851]
loss: 4.018260  [ 4758/ 7851]
loss: 6.604920  [ 5226/ 7851]
loss: 4.998984  [ 5694/ 7851]
loss: 6.556360  [ 6162/ 7851]
loss: 6.567301  [ 6630/ 7851]
loss: 5.090568  [ 7098/ 7851]
loss: 10.115634  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 5.782559 
Epoch 25
-------------------------------
loss: 6.961310  [   79/ 7851]
loss: 11.363764  [  547/ 7851]
loss: 8.259327  [ 1015/ 7851]
loss: 7.845966  [ 1483/ 7851]
loss: 7.307562  [ 1951/ 7851]
loss: 5.298958  [ 2419/ 7851]
loss: 8.860744  [ 2887/ 7851]
loss: 5.627506  [ 3355/ 7851]
loss: 4.809823  [ 3823/ 7851]
loss: 4.451676  [ 4290/ 7851]
loss: 3.924904  [ 4758/ 7851]
loss: 6.999734  [ 5226/ 7851]
loss: 4.206417  [ 5694/ 7851]
loss: 7.328602  [ 6162/ 7851]
loss: 6.541950  [ 6630/ 7851]
loss: 5.188594  [ 7098/ 7851]
loss: 8.729016  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.999610 
Epoch 26
-------------------------------
loss: 7.189345  [   79/ 7851]
loss: 11.708467  [  547/ 7851]
loss: 8.319837  [ 1015/ 7851]
loss: 7.902451  [ 1483/ 7851]
loss: 7.092329  [ 1951/ 7851]
loss: 4.949122  [ 2419/ 7851]
loss: 8.256865  [ 2887/ 7851]
loss: 5.302769  [ 3355/ 7851]
loss: 4.827326  [ 3823/ 7851]
loss: 4.618299  [ 4290/ 7851]
loss: 4.005476  [ 4758/ 7851]
loss: 6.201334  [ 5226/ 7851]
loss: 4.546056  [ 5694/ 7851]
loss: 7.182951  [ 6162/ 7851]
loss: 6.384109  [ 6630/ 7851]
loss: 5.355000  [ 7098/ 7851]
loss: 8.272554  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.730283 
Epoch 27
-------------------------------
loss: 7.028704  [   79/ 7851]
loss: 11.425372  [  547/ 7851]
loss: 9.213618  [ 1015/ 7851]
loss: 8.560650  [ 1483/ 7851]
loss: 6.539137  [ 1951/ 7851]
loss: 5.345050  [ 2419/ 7851]
loss: 8.846411  [ 2887/ 7851]
loss: 4.804084  [ 3355/ 7851]
loss: 5.333680  [ 3823/ 7851]
loss: 4.407456  [ 4290/ 7851]
loss: 3.736113  [ 4758/ 7851]
loss: 10.580827  [ 5226/ 7851]
loss: 5.007170  [ 5694/ 7851]
loss: 7.344598  [ 6162/ 7851]
loss: 6.811701  [ 6630/ 7851]
loss: 5.741541  [ 7098/ 7851]
loss: 9.103648  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.138921 
Epoch 28
-------------------------------
loss: 7.794844  [   79/ 7851]
loss: 11.327736  [  547/ 7851]
loss: 7.179003  [ 1015/ 7851]
loss: 8.774352  [ 1483/ 7851]
loss: 6.590468  [ 1951/ 7851]
loss: 5.794595  [ 2419/ 7851]
loss: 8.289879  [ 2887/ 7851]
loss: 5.443758  [ 3355/ 7851]
loss: 4.845292  [ 3823/ 7851]
loss: 4.419727  [ 4290/ 7851]
loss: 3.657307  [ 4758/ 7851]
loss: 6.396708  [ 5226/ 7851]
loss: 5.531983  [ 5694/ 7851]
loss: 7.358264  [ 6162/ 7851]
loss: 6.096200  [ 6630/ 7851]
loss: 4.998778  [ 7098/ 7851]
loss: 9.670527  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 5.896443 
Epoch 29
-------------------------------
loss: 7.282251  [   79/ 7851]
loss: 11.908162  [  547/ 7851]
loss: 8.745953  [ 1015/ 7851]
loss: 7.858771  [ 1483/ 7851]
loss: 7.057627  [ 1951/ 7851]
loss: 5.122232  [ 2419/ 7851]
loss: 7.981180  [ 2887/ 7851]
loss: 4.768624  [ 3355/ 7851]
loss: 5.138943  [ 3823/ 7851]
loss: 4.121154  [ 4290/ 7851]
loss: 3.704471  [ 4758/ 7851]
loss: 6.156518  [ 5226/ 7851]
loss: 4.776071  [ 5694/ 7851]
loss: 7.248594  [ 6162/ 7851]
loss: 7.441751  [ 6630/ 7851]
loss: 5.418635  [ 7098/ 7851]
loss: 8.875847  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.058875 
Epoch 30
-------------------------------
loss: 7.558349  [   79/ 7851]
loss: 11.232561  [  547/ 7851]
loss: 7.815131  [ 1015/ 7851]
loss: 8.126040  [ 1483/ 7851]
loss: 7.192088  [ 1951/ 7851]
loss: 5.348863  [ 2419/ 7851]
loss: 8.162496  [ 2887/ 7851]
loss: 5.327184  [ 3355/ 7851]
loss: 5.098333  [ 3823/ 7851]
loss: 3.874489  [ 4290/ 7851]
loss: 4.119855  [ 4758/ 7851]
loss: 6.413030  [ 5226/ 7851]
loss: 4.655113  [ 5694/ 7851]
loss: 6.907804  [ 6162/ 7851]
loss: 6.726487  [ 6630/ 7851]
loss: 9.919501  [ 7098/ 7851]
loss: 9.343650  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 6.060900 
Epoch 31
-------------------------------
loss: 7.017607  [   79/ 7851]
loss: 10.547389  [  547/ 7851]
loss: 8.711567  [ 1015/ 7851]
loss: 8.105469  [ 1483/ 7851]
loss: 7.253674  [ 1951/ 7851]
loss: 5.003595  [ 2419/ 7851]
loss: 8.825387  [ 2887/ 7851]
loss: 5.217811  [ 3355/ 7851]
loss: 5.570048  [ 3823/ 7851]
loss: 3.625104  [ 4290/ 7851]
loss: 3.896166  [ 4758/ 7851]
loss: 5.934081  [ 5226/ 7851]
loss: 4.943882  [ 5694/ 7851]
loss: 7.146335  [ 6162/ 7851]
loss: 6.813485  [ 6630/ 7851]
loss: 5.627584  [ 7098/ 7851]
loss: 9.079506  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.998518 
Epoch 32
-------------------------------
loss: 7.091434  [   79/ 7851]
loss: 11.240664  [  547/ 7851]
loss: 7.807237  [ 1015/ 7851]
loss: 8.275599  [ 1483/ 7851]
loss: 7.597222  [ 1951/ 7851]
loss: 5.641426  [ 2419/ 7851]
loss: 8.956160  [ 2887/ 7851]
loss: 5.680117  [ 3355/ 7851]
loss: 4.933616  [ 3823/ 7851]
loss: 3.816684  [ 4290/ 7851]
loss: 4.070115  [ 4758/ 7851]
loss: 5.961195  [ 5226/ 7851]
loss: 4.585855  [ 5694/ 7851]
loss: 7.244325  [ 6162/ 7851]
loss: 5.702641  [ 6630/ 7851]
loss: 5.534065  [ 7098/ 7851]
loss: 8.379897  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.179517 
Epoch 33
-------------------------------
loss: 6.958272  [   79/ 7851]
loss: 11.218716  [  547/ 7851]
loss: 8.744774  [ 1015/ 7851]
loss: 8.285702  [ 1483/ 7851]
loss: 5.963068  [ 1951/ 7851]
loss: 4.954133  [ 2419/ 7851]
loss: 8.875481  [ 2887/ 7851]
loss: 4.926929  [ 3355/ 7851]
loss: 5.786427  [ 3823/ 7851]
loss: 4.393746  [ 4290/ 7851]
loss: 4.525364  [ 4758/ 7851]
loss: 6.198531  [ 5226/ 7851]
loss: 5.359001  [ 5694/ 7851]
loss: 6.993258  [ 6162/ 7851]
loss: 7.128363  [ 6630/ 7851]
loss: 5.250769  [ 7098/ 7851]
loss: 8.671189  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.720570 
Epoch 34
-------------------------------
loss: 7.486598  [   79/ 7851]
loss: 11.792778  [  547/ 7851]
loss: 8.308245  [ 1015/ 7851]
loss: 8.003925  [ 1483/ 7851]
loss: 6.300596  [ 1951/ 7851]
loss: 5.200222  [ 2419/ 7851]
loss: 8.675962  [ 2887/ 7851]
loss: 5.130556  [ 3355/ 7851]
loss: 5.343076  [ 3823/ 7851]
loss: 4.049027  [ 4290/ 7851]
loss: 4.377484  [ 4758/ 7851]
loss: 6.429542  [ 5226/ 7851]
loss: 4.473993  [ 5694/ 7851]
loss: 7.554934  [ 6162/ 7851]
loss: 6.635320  [ 6630/ 7851]
loss: 5.232352  [ 7098/ 7851]
loss: 8.452538  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.485283 
Epoch 35
-------------------------------
loss: 7.296253  [   79/ 7851]
loss: 11.530047  [  547/ 7851]
loss: 7.183465  [ 1015/ 7851]
loss: 9.439118  [ 1483/ 7851]
loss: 5.836856  [ 1951/ 7851]
loss: 5.790182  [ 2419/ 7851]
loss: 8.632219  [ 2887/ 7851]
loss: 5.953282  [ 3355/ 7851]
loss: 5.113780  [ 3823/ 7851]
loss: 3.726690  [ 4290/ 7851]
loss: 4.517513  [ 4758/ 7851]
loss: 6.294547  [ 5226/ 7851]
loss: 5.076765  [ 5694/ 7851]
loss: 7.165405  [ 6162/ 7851]
loss: 6.273797  [ 6630/ 7851]
loss: 5.506547  [ 7098/ 7851]
loss: 9.171892  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.8%, Avg loss: 5.927489 
Epoch 36
-------------------------------
loss: 7.299930  [   79/ 7851]
loss: 11.290644  [  547/ 7851]
loss: 7.811784  [ 1015/ 7851]
loss: 7.950979  [ 1483/ 7851]
loss: 6.169283  [ 1951/ 7851]
loss: 4.886775  [ 2419/ 7851]
loss: 8.685268  [ 2887/ 7851]
loss: 5.707743  [ 3355/ 7851]
loss: 5.275656  [ 3823/ 7851]
loss: 4.121248  [ 4290/ 7851]
loss: 4.127773  [ 4758/ 7851]
loss: 6.005877  [ 5226/ 7851]
loss: 4.867816  [ 5694/ 7851]
loss: 6.764412  [ 6162/ 7851]
loss: 6.329171  [ 6630/ 7851]
loss: 5.368787  [ 7098/ 7851]
loss: 9.010553  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 5.977764 
Epoch 37
-------------------------------
loss: 6.991933  [   79/ 7851]
loss: 11.503456  [  547/ 7851]
loss: 8.098869  [ 1015/ 7851]
loss: 8.932392  [ 1483/ 7851]
loss: 6.747736  [ 1951/ 7851]
loss: 5.365370  [ 2419/ 7851]
loss: 8.805881  [ 2887/ 7851]
loss: 5.244538  [ 3355/ 7851]
loss: 4.720657  [ 3823/ 7851]
loss: 4.179103  [ 4290/ 7851]
loss: 4.212865  [ 4758/ 7851]
loss: 6.687709  [ 5226/ 7851]
loss: 4.359200  [ 5694/ 7851]
loss: 7.278643  [ 6162/ 7851]
loss: 6.149062  [ 6630/ 7851]
loss: 5.549254  [ 7098/ 7851]
loss: 8.585229  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.5%, Avg loss: 6.059668 
Epoch 38
-------------------------------
loss: 7.129255  [   79/ 7851]
loss: 11.759403  [  547/ 7851]
loss: 8.319608  [ 1015/ 7851]
loss: 8.925177  [ 1483/ 7851]
loss: 6.603387  [ 1951/ 7851]
loss: 5.740833  [ 2419/ 7851]
loss: 7.905286  [ 2887/ 7851]
loss: 5.193983  [ 3355/ 7851]
loss: 5.763470  [ 3823/ 7851]
loss: 4.324364  [ 4290/ 7851]
loss: 4.235452  [ 4758/ 7851]
loss: 6.566120  [ 5226/ 7851]
loss: 4.737541  [ 5694/ 7851]
loss: 7.365557  [ 6162/ 7851]
loss: 6.385440  [ 6630/ 7851]
loss: 5.647815  [ 7098/ 7851]
loss: 8.771424  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.111595 
Epoch 39
-------------------------------
loss: 7.316856  [   79/ 7851]
loss: 10.689238  [  547/ 7851]
loss: 8.912662  [ 1015/ 7851]
loss: 8.687914  [ 1483/ 7851]
loss: 5.544934  [ 1951/ 7851]
loss: 5.199410  [ 2419/ 7851]
loss: 8.334054  [ 2887/ 7851]
loss: 5.931242  [ 3355/ 7851]
loss: 4.810527  [ 3823/ 7851]
loss: 4.259037  [ 4290/ 7851]
loss: 4.516223  [ 4758/ 7851]
loss: 6.404656  [ 5226/ 7851]
loss: 4.781742  [ 5694/ 7851]
loss: 7.500144  [ 6162/ 7851]
loss: 6.826281  [ 6630/ 7851]
loss: 6.207160  [ 7098/ 7851]
loss: 8.804933  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 5.725867 
Epoch 40
-------------------------------
loss: 7.592062  [   79/ 7851]
loss: 11.178315  [  547/ 7851]
loss: 8.726708  [ 1015/ 7851]
loss: 8.164989  [ 1483/ 7851]
loss: 7.585620  [ 1951/ 7851]
loss: 5.360318  [ 2419/ 7851]
loss: 8.215710  [ 2887/ 7851]
loss: 5.979698  [ 3355/ 7851]
loss: 5.020194  [ 3823/ 7851]
loss: 5.632897  [ 4290/ 7851]
loss: 4.139611  [ 4758/ 7851]
loss: 6.014963  [ 5226/ 7851]
loss: 4.721737  [ 5694/ 7851]
loss: 7.146196  [ 6162/ 7851]
loss: 6.067661  [ 6630/ 7851]
loss: 5.111245  [ 7098/ 7851]
loss: 9.458054  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 5.806944 
Epoch 41
-------------------------------
loss: 7.420217  [   79/ 7851]
loss: 10.796678  [  547/ 7851]
loss: 8.470370  [ 1015/ 7851]
loss: 7.850167  [ 1483/ 7851]
loss: 5.954347  [ 1951/ 7851]
loss: 4.898983  [ 2419/ 7851]
loss: 7.723164  [ 2887/ 7851]
loss: 5.614872  [ 3355/ 7851]
loss: 5.438673  [ 3823/ 7851]
loss: 4.204248  [ 4290/ 7851]
loss: 3.951966  [ 4758/ 7851]
loss: 6.841858  [ 5226/ 7851]
loss: 4.576625  [ 5694/ 7851]
loss: 7.507264  [ 6162/ 7851]
loss: 6.104146  [ 6630/ 7851]
loss: 5.839098  [ 7098/ 7851]
loss: 8.801088  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.023779 
Epoch 42
-------------------------------
loss: 7.184687  [   79/ 7851]
loss: 11.150958  [  547/ 7851]
loss: 8.789739  [ 1015/ 7851]
loss: 8.575428  [ 1483/ 7851]
loss: 6.181989  [ 1951/ 7851]
loss: 5.046850  [ 2419/ 7851]
loss: 9.032529  [ 2887/ 7851]
loss: 5.505459  [ 3355/ 7851]
loss: 5.000275  [ 3823/ 7851]
loss: 3.776285  [ 4290/ 7851]
loss: 4.461541  [ 4758/ 7851]
loss: 5.939149  [ 5226/ 7851]
loss: 4.880635  [ 5694/ 7851]
loss: 6.939268  [ 6162/ 7851]
loss: 6.257176  [ 6630/ 7851]
loss: 5.852715  [ 7098/ 7851]
loss: 8.833357  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.885406 
Epoch 43
-------------------------------
loss: 7.461838  [   79/ 7851]
loss: 11.670666  [  547/ 7851]
loss: 8.025778  [ 1015/ 7851]
loss: 7.955444  [ 1483/ 7851]
loss: 6.398222  [ 1951/ 7851]
loss: 5.317880  [ 2419/ 7851]
loss: 9.468638  [ 2887/ 7851]
loss: 5.413497  [ 3355/ 7851]
loss: 5.262661  [ 3823/ 7851]
loss: 3.749239  [ 4290/ 7851]
loss: 4.638700  [ 4758/ 7851]
loss: 6.167636  [ 5226/ 7851]
loss: 4.600478  [ 5694/ 7851]
loss: 6.883798  [ 6162/ 7851]
loss: 6.153996  [ 6630/ 7851]
loss: 5.953201  [ 7098/ 7851]
loss: 9.113714  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 5.883597 
Epoch 44
-------------------------------
loss: 7.169899  [   79/ 7851]
loss: 11.115335  [  547/ 7851]
loss: 8.759101  [ 1015/ 7851]
loss: 8.767070  [ 1483/ 7851]
loss: 6.084529  [ 1951/ 7851]
loss: 5.410036  [ 2419/ 7851]
loss: 8.332010  [ 2887/ 7851]
loss: 6.176952  [ 3355/ 7851]
loss: 5.474500  [ 3823/ 7851]
loss: 3.911455  [ 4290/ 7851]
loss: 3.680188  [ 4758/ 7851]
loss: 6.488317  [ 5226/ 7851]
loss: 4.610378  [ 5694/ 7851]
loss: 6.825166  [ 6162/ 7851]
loss: 6.145248  [ 6630/ 7851]
loss: 5.098252  [ 7098/ 7851]
loss: 9.144979  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.913989 
Epoch 45
-------------------------------
loss: 7.759375  [   79/ 7851]
loss: 11.204708  [  547/ 7851]
loss: 7.892622  [ 1015/ 7851]
loss: 8.729804  [ 1483/ 7851]
loss: 6.651326  [ 1951/ 7851]
loss: 5.474191  [ 2419/ 7851]
loss: 8.038196  [ 2887/ 7851]
loss: 5.445229  [ 3355/ 7851]
loss: 5.097085  [ 3823/ 7851]
loss: 3.976606  [ 4290/ 7851]
loss: 3.800204  [ 4758/ 7851]
loss: 6.367622  [ 5226/ 7851]
loss: 5.204846  [ 5694/ 7851]
loss: 7.853346  [ 6162/ 7851]
loss: 6.285262  [ 6630/ 7851]
loss: 5.592806  [ 7098/ 7851]
loss: 9.475412  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 6.119850 
Epoch 46
-------------------------------
loss: 7.926888  [   79/ 7851]
loss: 11.494208  [  547/ 7851]
loss: 8.334010  [ 1015/ 7851]
loss: 8.685475  [ 1483/ 7851]
loss: 6.154583  [ 1951/ 7851]
loss: 5.168743  [ 2419/ 7851]
loss: 8.260591  [ 2887/ 7851]
loss: 5.358590  [ 3355/ 7851]
loss: 5.172046  [ 3823/ 7851]
loss: 4.123493  [ 4290/ 7851]
loss: 4.268948  [ 4758/ 7851]
loss: 6.127797  [ 5226/ 7851]
loss: 4.295824  [ 5694/ 7851]
loss: 7.520165  [ 6162/ 7851]
loss: 7.074033  [ 6630/ 7851]
loss: 5.797417  [ 7098/ 7851]
loss: 8.681221  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.958368 
Epoch 47
-------------------------------
loss: 7.140174  [   79/ 7851]
loss: 11.714191  [  547/ 7851]
loss: 9.224792  [ 1015/ 7851]
loss: 9.524611  [ 1483/ 7851]
loss: 6.557087  [ 1951/ 7851]
loss: 5.417691  [ 2419/ 7851]
loss: 8.600931  [ 2887/ 7851]
loss: 5.335799  [ 3355/ 7851]
loss: 5.388429  [ 3823/ 7851]
loss: 4.405213  [ 4290/ 7851]
loss: 4.124353  [ 4758/ 7851]
loss: 6.350634  [ 5226/ 7851]
loss: 4.640645  [ 5694/ 7851]
loss: 6.595944  [ 6162/ 7851]
loss: 6.641945  [ 6630/ 7851]
loss: 6.586410  [ 7098/ 7851]
loss: 9.194128  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 5.645136 
Epoch 48
-------------------------------
loss: 7.647350  [   79/ 7851]
loss: 11.417175  [  547/ 7851]
loss: 8.169459  [ 1015/ 7851]
loss: 8.913876  [ 1483/ 7851]
loss: 6.980780  [ 1951/ 7851]
loss: 5.244453  [ 2419/ 7851]
loss: 8.666297  [ 2887/ 7851]
loss: 5.169602  [ 3355/ 7851]
loss: 5.287892  [ 3823/ 7851]
loss: 4.589268  [ 4290/ 7851]
loss: 3.995417  [ 4758/ 7851]
loss: 6.496440  [ 5226/ 7851]
loss: 4.754711  [ 5694/ 7851]
loss: 6.966487  [ 6162/ 7851]
loss: 6.074568  [ 6630/ 7851]
loss: 4.902828  [ 7098/ 7851]
loss: 8.566081  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.772321 
Epoch 49
-------------------------------
loss: 7.142021  [   79/ 7851]
loss: 11.085763  [  547/ 7851]
loss: 8.066816  [ 1015/ 7851]
loss: 8.013269  [ 1483/ 7851]
loss: 5.817542  [ 1951/ 7851]
loss: 4.638227  [ 2419/ 7851]
loss: 7.844314  [ 2887/ 7851]
loss: 5.492841  [ 3355/ 7851]
loss: 4.984237  [ 3823/ 7851]
loss: 3.522615  [ 4290/ 7851]
loss: 3.914135  [ 4758/ 7851]
loss: 6.525177  [ 5226/ 7851]
loss: 5.238355  [ 5694/ 7851]
loss: 7.091439  [ 6162/ 7851]
loss: 6.300846  [ 6630/ 7851]
loss: 5.807803  [ 7098/ 7851]
loss: 8.474058  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.091803 
Epoch 50
-------------------------------
loss: 7.048023  [   79/ 7851]
loss: 11.365073  [  547/ 7851]
loss: 8.309754  [ 1015/ 7851]
loss: 8.219379  [ 1483/ 7851]
loss: 6.156144  [ 1951/ 7851]
loss: 4.578283  [ 2419/ 7851]
loss: 8.406384  [ 2887/ 7851]
loss: 5.652606  [ 3355/ 7851]
loss: 5.476058  [ 3823/ 7851]
loss: 4.242742  [ 4290/ 7851]
loss: 3.914503  [ 4758/ 7851]
loss: 6.320951  [ 5226/ 7851]
loss: 3.714018  [ 5694/ 7851]
loss: 7.465052  [ 6162/ 7851]
loss: 6.175294  [ 6630/ 7851]
loss: 5.063958  [ 7098/ 7851]
loss: 8.457030  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.708525 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 8000]               648,000
│    └─ReLU: 2-2                         [100, 8000]               --
│    └─Linear: 2-3                       [100, 80]                 640,080
==========================================================================================
Total params: 1,288,080
Trainable params: 1,288,080
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 128.81
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 6.46
Params size (MB): 5.15
Estimated Total Size (MB): 11.65
==========================================================================================
Epoch 1
-------------------------------
loss: 12.853233  [   79/ 7851]
loss: 13.679599  [  547/ 7851]
loss: 8.674546  [ 1015/ 7851]
loss: 8.069259  [ 1483/ 7851]
loss: 8.040382  [ 1951/ 7851]
loss: 7.478405  [ 2419/ 7851]
loss: 11.659621  [ 2887/ 7851]
loss: 6.225857  [ 3355/ 7851]
loss: 7.747371  [ 3823/ 7851]
loss: 7.408733  [ 4290/ 7851]
loss: 8.414765  [ 4758/ 7851]
loss: 6.896020  [ 5226/ 7851]
loss: 4.564499  [ 5694/ 7851]
loss: 9.132160  [ 6162/ 7851]
loss: 7.450658  [ 6630/ 7851]
loss: 5.920910  [ 7098/ 7851]
loss: 4.816203  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.853656 
Epoch 2
-------------------------------
loss: 7.956970  [   79/ 7851]
loss: 7.182806  [  547/ 7851]
loss: 6.923561  [ 1015/ 7851]
loss: 8.668627  [ 1483/ 7851]
loss: 6.618275  [ 1951/ 7851]
loss: 4.994414  [ 2419/ 7851]
loss: 5.246060  [ 2887/ 7851]
loss: 5.527938  [ 3355/ 7851]
loss: 8.181245  [ 3823/ 7851]
loss: 9.280019  [ 4290/ 7851]
loss: 6.731927  [ 4758/ 7851]
loss: 6.660372  [ 5226/ 7851]
loss: 3.540016  [ 5694/ 7851]
loss: 8.908955  [ 6162/ 7851]
loss: 7.754015  [ 6630/ 7851]
loss: 7.733442  [ 7098/ 7851]
loss: 4.719332  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.252849 
Epoch 3
-------------------------------
loss: 6.513995  [   79/ 7851]
loss: 6.400696  [  547/ 7851]
loss: 6.641844  [ 1015/ 7851]
loss: 8.331592  [ 1483/ 7851]
loss: 6.839146  [ 1951/ 7851]
loss: 6.126269  [ 2419/ 7851]
loss: 6.653089  [ 2887/ 7851]
loss: 6.115548  [ 3355/ 7851]
loss: 8.218863  [ 3823/ 7851]
loss: 7.932355  [ 4290/ 7851]
loss: 6.737643  [ 4758/ 7851]
loss: 6.390831  [ 5226/ 7851]
loss: 3.479885  [ 5694/ 7851]
loss: 8.621487  [ 6162/ 7851]
loss: 5.642962  [ 6630/ 7851]
loss: 6.403692  [ 7098/ 7851]
loss: 4.962396  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.441743 
Epoch 4
-------------------------------
loss: 5.960219  [   79/ 7851]
loss: 6.488592  [  547/ 7851]
loss: 7.629578  [ 1015/ 7851]
loss: 9.354822  [ 1483/ 7851]
loss: 7.360335  [ 1951/ 7851]
loss: 5.842997  [ 2419/ 7851]
loss: 5.084085  [ 2887/ 7851]
loss: 6.364360  [ 3355/ 7851]
loss: 7.960863  [ 3823/ 7851]
loss: 6.907669  [ 4290/ 7851]
loss: 6.984167  [ 4758/ 7851]
loss: 6.737525  [ 5226/ 7851]
loss: 4.011981  [ 5694/ 7851]
loss: 8.246911  [ 6162/ 7851]
loss: 5.177530  [ 6630/ 7851]
loss: 5.745391  [ 7098/ 7851]
loss: 5.909942  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 6.068028 
Epoch 5
-------------------------------
loss: 6.218347  [   79/ 7851]
loss: 7.118874  [  547/ 7851]
loss: 6.634781  [ 1015/ 7851]
loss: 7.763564  [ 1483/ 7851]
loss: 7.435426  [ 1951/ 7851]
loss: 5.241288  [ 2419/ 7851]
loss: 5.142948  [ 2887/ 7851]
loss: 5.930752  [ 3355/ 7851]
loss: 7.749589  [ 3823/ 7851]
loss: 7.734933  [ 4290/ 7851]
loss: 6.669673  [ 4758/ 7851]
loss: 6.863135  [ 5226/ 7851]
loss: 3.622868  [ 5694/ 7851]
loss: 8.760732  [ 6162/ 7851]
loss: 6.152343  [ 6630/ 7851]
loss: 5.054423  [ 7098/ 7851]
loss: 5.888986  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.125766 
Epoch 6
-------------------------------
loss: 7.179116  [   79/ 7851]
loss: 6.524777  [  547/ 7851]
loss: 6.751160  [ 1015/ 7851]
loss: 8.489348  [ 1483/ 7851]
loss: 7.334925  [ 1951/ 7851]
loss: 5.349732  [ 2419/ 7851]
loss: 5.866601  [ 2887/ 7851]
loss: 5.796994  [ 3355/ 7851]
loss: 7.632364  [ 3823/ 7851]
loss: 7.885460  [ 4290/ 7851]
loss: 7.630071  [ 4758/ 7851]
loss: 6.637152  [ 5226/ 7851]
loss: 3.951498  [ 5694/ 7851]
loss: 8.636649  [ 6162/ 7851]
loss: 5.706982  [ 6630/ 7851]
loss: 6.174263  [ 7098/ 7851]
loss: 4.932289  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 5.957540 
Epoch 7
-------------------------------
loss: 6.646347  [   79/ 7851]
loss: 6.983449  [  547/ 7851]
loss: 8.027132  [ 1015/ 7851]
loss: 8.034648  [ 1483/ 7851]
loss: 8.018348  [ 1951/ 7851]
loss: 5.777723  [ 2419/ 7851]
loss: 3.904010  [ 2887/ 7851]
loss: 5.716947  [ 3355/ 7851]
loss: 7.451021  [ 3823/ 7851]
loss: 7.230277  [ 4290/ 7851]
loss: 7.256839  [ 4758/ 7851]
loss: 6.638781  [ 5226/ 7851]
loss: 4.265718  [ 5694/ 7851]
loss: 8.083897  [ 6162/ 7851]
loss: 5.621284  [ 6630/ 7851]
loss: 4.906587  [ 7098/ 7851]
loss: 4.713709  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.134556 
Epoch 8
-------------------------------
loss: 6.690393  [   79/ 7851]
loss: 7.294415  [  547/ 7851]
loss: 6.892847  [ 1015/ 7851]
loss: 7.761891  [ 1483/ 7851]
loss: 7.573425  [ 1951/ 7851]
loss: 5.501536  [ 2419/ 7851]
loss: 6.614997  [ 2887/ 7851]
loss: 6.293434  [ 3355/ 7851]
loss: 7.914952  [ 3823/ 7851]
loss: 6.977041  [ 4290/ 7851]
loss: 6.937548  [ 4758/ 7851]
loss: 6.073575  [ 5226/ 7851]
loss: 4.368273  [ 5694/ 7851]
loss: 7.694516  [ 6162/ 7851]
loss: 5.427653  [ 6630/ 7851]
loss: 5.307569  [ 7098/ 7851]
loss: 5.186237  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 5.842916 
Epoch 9
-------------------------------
loss: 6.379866  [   79/ 7851]
loss: 6.333879  [  547/ 7851]
loss: 7.053338  [ 1015/ 7851]
loss: 8.452403  [ 1483/ 7851]
loss: 8.758663  [ 1951/ 7851]
loss: 5.999408  [ 2419/ 7851]
loss: 4.624094  [ 2887/ 7851]
loss: 5.357109  [ 3355/ 7851]
loss: 7.622252  [ 3823/ 7851]
loss: 7.635652  [ 4290/ 7851]
loss: 7.049892  [ 4758/ 7851]
loss: 6.566284  [ 5226/ 7851]
loss: 4.453231  [ 5694/ 7851]
loss: 9.345332  [ 6162/ 7851]
loss: 6.292228  [ 6630/ 7851]
loss: 6.142276  [ 7098/ 7851]
loss: 4.873799  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 7.119544 
Epoch 10
-------------------------------
loss: 6.274242  [   79/ 7851]
loss: 6.880639  [  547/ 7851]
loss: 5.986587  [ 1015/ 7851]
loss: 8.056911  [ 1483/ 7851]
loss: 8.188908  [ 1951/ 7851]
loss: 5.582225  [ 2419/ 7851]
loss: 5.703361  [ 2887/ 7851]
loss: 6.148874  [ 3355/ 7851]
loss: 7.481926  [ 3823/ 7851]
loss: 7.557789  [ 4290/ 7851]
loss: 7.159090  [ 4758/ 7851]
loss: 6.321651  [ 5226/ 7851]
loss: 5.591471  [ 5694/ 7851]
loss: 9.391919  [ 6162/ 7851]
loss: 6.827643  [ 6630/ 7851]
loss: 6.384054  [ 7098/ 7851]
loss: 4.567385  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.9%, Avg loss: 5.614460 
Epoch 11
-------------------------------
loss: 5.983908  [   79/ 7851]
loss: 6.671502  [  547/ 7851]
loss: 6.704687  [ 1015/ 7851]
loss: 8.613235  [ 1483/ 7851]
loss: 7.142324  [ 1951/ 7851]
loss: 5.492520  [ 2419/ 7851]
loss: 6.534674  [ 2887/ 7851]
loss: 5.594893  [ 3355/ 7851]
loss: 8.241488  [ 3823/ 7851]
loss: 7.624814  [ 4290/ 7851]
loss: 7.319322  [ 4758/ 7851]
loss: 6.587237  [ 5226/ 7851]
loss: 4.014905  [ 5694/ 7851]
loss: 8.005012  [ 6162/ 7851]
loss: 5.849663  [ 6630/ 7851]
loss: 6.683700  [ 7098/ 7851]
loss: 5.009106  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 5.687479 
Epoch 12
-------------------------------
loss: 6.725616  [   79/ 7851]
loss: 7.175606  [  547/ 7851]
loss: 6.477533  [ 1015/ 7851]
loss: 7.718644  [ 1483/ 7851]
loss: 6.323742  [ 1951/ 7851]
loss: 5.956444  [ 2419/ 7851]
loss: 3.829432  [ 2887/ 7851]
loss: 5.098998  [ 3355/ 7851]
loss: 8.109926  [ 3823/ 7851]
loss: 7.491227  [ 4290/ 7851]
loss: 7.391363  [ 4758/ 7851]
loss: 6.385284  [ 5226/ 7851]
loss: 3.364134  [ 5694/ 7851]
loss: 7.592223  [ 6162/ 7851]
loss: 5.859813  [ 6630/ 7851]
loss: 5.805176  [ 7098/ 7851]
loss: 4.494328  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.494777 
Epoch 13
-------------------------------
loss: 6.046509  [   79/ 7851]
loss: 6.515622  [  547/ 7851]
loss: 6.356489  [ 1015/ 7851]
loss: 7.930673  [ 1483/ 7851]
loss: 7.166876  [ 1951/ 7851]
loss: 5.201320  [ 2419/ 7851]
loss: 4.698747  [ 2887/ 7851]
loss: 5.384067  [ 3355/ 7851]
loss: 7.552320  [ 3823/ 7851]
loss: 7.487625  [ 4290/ 7851]
loss: 7.088788  [ 4758/ 7851]
loss: 6.842194  [ 5226/ 7851]
loss: 3.899903  [ 5694/ 7851]
loss: 8.512630  [ 6162/ 7851]
loss: 5.857262  [ 6630/ 7851]
loss: 5.739309  [ 7098/ 7851]
loss: 4.792972  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.002690 
Epoch 14
-------------------------------
loss: 5.316673  [   79/ 7851]
loss: 6.582561  [  547/ 7851]
loss: 5.683084  [ 1015/ 7851]
loss: 6.847260  [ 1483/ 7851]
loss: 6.574499  [ 1951/ 7851]
loss: 5.517962  [ 2419/ 7851]
loss: 4.522937  [ 2887/ 7851]
loss: 5.975615  [ 3355/ 7851]
loss: 7.021576  [ 3823/ 7851]
loss: 6.647871  [ 4290/ 7851]
loss: 6.965241  [ 4758/ 7851]
loss: 6.460799  [ 5226/ 7851]
loss: 4.115175  [ 5694/ 7851]
loss: 8.590069  [ 6162/ 7851]
loss: 5.978120  [ 6630/ 7851]
loss: 5.787177  [ 7098/ 7851]
loss: 4.743730  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.871217 
Epoch 15
-------------------------------
loss: 6.180001  [   79/ 7851]
loss: 6.170123  [  547/ 7851]
loss: 4.311556  [ 1015/ 7851]
loss: 7.069455  [ 1483/ 7851]
loss: 6.928648  [ 1951/ 7851]
loss: 5.388749  [ 2419/ 7851]
loss: 3.946410  [ 2887/ 7851]
loss: 5.100410  [ 3355/ 7851]
loss: 5.791935  [ 3823/ 7851]
loss: 5.981891  [ 4290/ 7851]
loss: 7.121992  [ 4758/ 7851]
loss: 6.581151  [ 5226/ 7851]
loss: 3.935676  [ 5694/ 7851]
loss: 9.465283  [ 6162/ 7851]
loss: 7.263462  [ 6630/ 7851]
loss: 5.773022  [ 7098/ 7851]
loss: 4.643131  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.403854 
Epoch 16
-------------------------------
loss: 5.149066  [   79/ 7851]
loss: 6.936862  [  547/ 7851]
loss: 4.895207  [ 1015/ 7851]
loss: 6.358417  [ 1483/ 7851]
loss: 6.230790  [ 1951/ 7851]
loss: 5.721603  [ 2419/ 7851]
loss: 4.232185  [ 2887/ 7851]
loss: 5.927167  [ 3355/ 7851]
loss: 6.783783  [ 3823/ 7851]
loss: 6.099123  [ 4290/ 7851]
loss: 7.072228  [ 4758/ 7851]
loss: 6.647739  [ 5226/ 7851]
loss: 4.013217  [ 5694/ 7851]
loss: 8.742303  [ 6162/ 7851]
loss: 6.223305  [ 6630/ 7851]
loss: 5.953916  [ 7098/ 7851]
loss: 4.815286  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.552694 
Epoch 17
-------------------------------
loss: 6.613127  [   79/ 7851]
loss: 7.218699  [  547/ 7851]
loss: 4.655786  [ 1015/ 7851]
loss: 6.336978  [ 1483/ 7851]
loss: 6.827428  [ 1951/ 7851]
loss: 5.459774  [ 2419/ 7851]
loss: 3.747073  [ 2887/ 7851]
loss: 5.009411  [ 3355/ 7851]
loss: 6.637715  [ 3823/ 7851]
loss: 6.362431  [ 4290/ 7851]
loss: 7.064644  [ 4758/ 7851]
loss: 7.239443  [ 5226/ 7851]
loss: 3.549527  [ 5694/ 7851]
loss: 8.567488  [ 6162/ 7851]
loss: 7.012605  [ 6630/ 7851]
loss: 6.137224  [ 7098/ 7851]
loss: 4.288626  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.981566 
Epoch 18
-------------------------------
loss: 5.603478  [   79/ 7851]
loss: 7.356846  [  547/ 7851]
loss: 4.711319  [ 1015/ 7851]
loss: 5.976846  [ 1483/ 7851]
loss: 7.707373  [ 1951/ 7851]
loss: 5.038344  [ 2419/ 7851]
loss: 4.817656  [ 2887/ 7851]
loss: 6.472031  [ 3355/ 7851]
loss: 5.821846  [ 3823/ 7851]
loss: 6.562901  [ 4290/ 7851]
loss: 6.576937  [ 4758/ 7851]
loss: 6.481679  [ 5226/ 7851]
loss: 3.891916  [ 5694/ 7851]
loss: 8.251311  [ 6162/ 7851]
loss: 6.224686  [ 6630/ 7851]
loss: 5.863408  [ 7098/ 7851]
loss: 4.626872  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 5.669675 
Epoch 19
-------------------------------
loss: 6.248190  [   79/ 7851]
loss: 6.635194  [  547/ 7851]
loss: 5.764625  [ 1015/ 7851]
loss: 7.384490  [ 1483/ 7851]
loss: 7.254127  [ 1951/ 7851]
loss: 5.982257  [ 2419/ 7851]
loss: 5.708329  [ 2887/ 7851]
loss: 5.388524  [ 3355/ 7851]
loss: 6.933167  [ 3823/ 7851]
loss: 5.375368  [ 4290/ 7851]
loss: 6.182688  [ 4758/ 7851]
loss: 6.110743  [ 5226/ 7851]
loss: 3.453430  [ 5694/ 7851]
loss: 7.525687  [ 6162/ 7851]
loss: 5.503275  [ 6630/ 7851]
loss: 5.046937  [ 7098/ 7851]
loss: 5.378906  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.0%, Avg loss: 5.997933 
Epoch 20
-------------------------------
loss: 6.124527  [   79/ 7851]
loss: 7.924746  [  547/ 7851]
loss: 4.598005  [ 1015/ 7851]
loss: 5.288866  [ 1483/ 7851]
loss: 6.935233  [ 1951/ 7851]
loss: 5.475861  [ 2419/ 7851]
loss: 4.305520  [ 2887/ 7851]
loss: 5.466903  [ 3355/ 7851]
loss: 5.903566  [ 3823/ 7851]
loss: 6.636399  [ 4290/ 7851]
loss: 7.026629  [ 4758/ 7851]
loss: 6.862088  [ 5226/ 7851]
loss: 3.482711  [ 5694/ 7851]
loss: 8.190825  [ 6162/ 7851]
loss: 6.326591  [ 6630/ 7851]
loss: 5.563761  [ 7098/ 7851]
loss: 4.148407  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 5.671318 
Epoch 21
-------------------------------
loss: 5.215483  [   79/ 7851]
loss: 6.366354  [  547/ 7851]
loss: 4.676667  [ 1015/ 7851]
loss: 5.366548  [ 1483/ 7851]
loss: 6.848113  [ 1951/ 7851]
loss: 5.615613  [ 2419/ 7851]
loss: 4.684366  [ 2887/ 7851]
loss: 5.761894  [ 3355/ 7851]
loss: 5.434122  [ 3823/ 7851]
loss: 6.727322  [ 4290/ 7851]
loss: 7.241199  [ 4758/ 7851]
loss: 6.208852  [ 5226/ 7851]
loss: 3.778891  [ 5694/ 7851]
loss: 8.413281  [ 6162/ 7851]
loss: 6.788849  [ 6630/ 7851]
loss: 4.976127  [ 7098/ 7851]
loss: 5.028772  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.9%, Avg loss: 5.468687 
Epoch 22
-------------------------------
loss: 6.122496  [   79/ 7851]
loss: 6.352434  [  547/ 7851]
loss: 4.762666  [ 1015/ 7851]
loss: 5.635920  [ 1483/ 7851]
loss: 6.987396  [ 1951/ 7851]
loss: 5.715727  [ 2419/ 7851]
loss: 4.362332  [ 2887/ 7851]
loss: 5.741159  [ 3355/ 7851]
loss: 5.666943  [ 3823/ 7851]
loss: 6.361950  [ 4290/ 7851]
loss: 6.084232  [ 4758/ 7851]
loss: 6.327537  [ 5226/ 7851]
loss: 3.360174  [ 5694/ 7851]
loss: 7.428362  [ 6162/ 7851]
loss: 5.684030  [ 6630/ 7851]
loss: 5.477851  [ 7098/ 7851]
loss: 4.992947  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 6.584034 
Epoch 23
-------------------------------
loss: 6.128861  [   79/ 7851]
loss: 7.030780  [  547/ 7851]
loss: 4.156215  [ 1015/ 7851]
loss: 5.419246  [ 1483/ 7851]
loss: 7.261754  [ 1951/ 7851]
loss: 5.416152  [ 2419/ 7851]
loss: 4.259067  [ 2887/ 7851]
loss: 5.241118  [ 3355/ 7851]
loss: 5.777719  [ 3823/ 7851]
loss: 6.663456  [ 4290/ 7851]
loss: 6.546094  [ 4758/ 7851]
loss: 6.249388  [ 5226/ 7851]
loss: 3.728679  [ 5694/ 7851]
loss: 8.188627  [ 6162/ 7851]
loss: 5.907002  [ 6630/ 7851]
loss: 5.739344  [ 7098/ 7851]
loss: 4.064270  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 5.794477 
Epoch 24
-------------------------------
loss: 5.466704  [   79/ 7851]
loss: 6.608530  [  547/ 7851]
loss: 4.447366  [ 1015/ 7851]
loss: 5.852728  [ 1483/ 7851]
loss: 6.971106  [ 1951/ 7851]
loss: 5.326297  [ 2419/ 7851]
loss: 5.263752  [ 2887/ 7851]
loss: 5.049089  [ 3355/ 7851]
loss: 5.773120  [ 3823/ 7851]
loss: 6.293385  [ 4290/ 7851]
loss: 6.428473  [ 4758/ 7851]
loss: 7.731502  [ 5226/ 7851]
loss: 4.024051  [ 5694/ 7851]
loss: 7.649721  [ 6162/ 7851]
loss: 5.940598  [ 6630/ 7851]
loss: 4.932227  [ 7098/ 7851]
loss: 4.762504  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.298942 
Epoch 25
-------------------------------
loss: 6.973956  [   79/ 7851]
loss: 6.660131  [  547/ 7851]
loss: 5.325650  [ 1015/ 7851]
loss: 5.748003  [ 1483/ 7851]
loss: 6.720230  [ 1951/ 7851]
loss: 5.496758  [ 2419/ 7851]
loss: 4.368561  [ 2887/ 7851]
loss: 5.102745  [ 3355/ 7851]
loss: 6.295591  [ 3823/ 7851]
loss: 6.377462  [ 4290/ 7851]
loss: 6.254075  [ 4758/ 7851]
loss: 6.052413  [ 5226/ 7851]
loss: 3.836952  [ 5694/ 7851]
loss: 7.457932  [ 6162/ 7851]
loss: 6.111309  [ 6630/ 7851]
loss: 5.539071  [ 7098/ 7851]
loss: 4.898238  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.9%, Avg loss: 5.829888 
Epoch 26
-------------------------------
loss: 5.843626  [   79/ 7851]
loss: 6.804374  [  547/ 7851]
loss: 5.290388  [ 1015/ 7851]
loss: 5.862315  [ 1483/ 7851]
loss: 7.347827  [ 1951/ 7851]
loss: 5.701016  [ 2419/ 7851]
loss: 5.346535  [ 2887/ 7851]
loss: 5.536473  [ 3355/ 7851]
loss: 5.627438  [ 3823/ 7851]
loss: 5.807353  [ 4290/ 7851]
loss: 6.963850  [ 4758/ 7851]
loss: 6.902559  [ 5226/ 7851]
loss: 4.342728  [ 5694/ 7851]
loss: 8.426828  [ 6162/ 7851]
loss: 5.870124  [ 6630/ 7851]
loss: 6.106397  [ 7098/ 7851]
loss: 5.184319  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 5.534690 
Epoch 27
-------------------------------
loss: 6.223817  [   79/ 7851]
loss: 6.020341  [  547/ 7851]
loss: 5.282511  [ 1015/ 7851]
loss: 7.088748  [ 1483/ 7851]
loss: 7.371957  [ 1951/ 7851]
loss: 6.053343  [ 2419/ 7851]
loss: 4.214289  [ 2887/ 7851]
loss: 5.351227  [ 3355/ 7851]
loss: 6.751591  [ 3823/ 7851]
loss: 5.509903  [ 4290/ 7851]
loss: 6.717583  [ 4758/ 7851]
loss: 6.034172  [ 5226/ 7851]
loss: 3.383336  [ 5694/ 7851]
loss: 7.708982  [ 6162/ 7851]
loss: 6.422619  [ 6630/ 7851]
loss: 5.810937  [ 7098/ 7851]
loss: 4.544258  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 6.200324 
Epoch 28
-------------------------------
loss: 5.680456  [   79/ 7851]
loss: 7.722715  [  547/ 7851]
loss: 4.780853  [ 1015/ 7851]
loss: 5.678680  [ 1483/ 7851]
loss: 7.951289  [ 1951/ 7851]
loss: 5.131826  [ 2419/ 7851]
loss: 3.661124  [ 2887/ 7851]
loss: 5.667565  [ 3355/ 7851]
loss: 5.979853  [ 3823/ 7851]
loss: 6.410744  [ 4290/ 7851]
loss: 6.848198  [ 4758/ 7851]
loss: 6.157246  [ 5226/ 7851]
loss: 4.795277  [ 5694/ 7851]
loss: 8.360864  [ 6162/ 7851]
loss: 6.395457  [ 6630/ 7851]
loss: 5.676749  [ 7098/ 7851]
loss: 4.601293  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.7%, Avg loss: 5.593831 
Epoch 29
-------------------------------
loss: 6.274378  [   79/ 7851]
loss: 5.992429  [  547/ 7851]
loss: 4.953769  [ 1015/ 7851]
loss: 6.246315  [ 1483/ 7851]
loss: 7.299362  [ 1951/ 7851]
loss: 4.697635  [ 2419/ 7851]
loss: 4.374179  [ 2887/ 7851]
loss: 5.529542  [ 3355/ 7851]
loss: 6.502934  [ 3823/ 7851]
loss: 5.972476  [ 4290/ 7851]
loss: 7.407086  [ 4758/ 7851]
loss: 6.789299  [ 5226/ 7851]
loss: 3.329014  [ 5694/ 7851]
loss: 8.161120  [ 6162/ 7851]
loss: 5.147115  [ 6630/ 7851]
loss: 5.512677  [ 7098/ 7851]
loss: 4.533089  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.886432 
Epoch 30
-------------------------------
loss: 6.221523  [   79/ 7851]
loss: 6.754156  [  547/ 7851]
loss: 5.261261  [ 1015/ 7851]
loss: 6.608079  [ 1483/ 7851]
loss: 6.390540  [ 1951/ 7851]
loss: 5.810899  [ 2419/ 7851]
loss: 4.182884  [ 2887/ 7851]
loss: 5.481846  [ 3355/ 7851]
loss: 5.998012  [ 3823/ 7851]
loss: 5.889955  [ 4290/ 7851]
loss: 6.680918  [ 4758/ 7851]
loss: 6.629688  [ 5226/ 7851]
loss: 4.431303  [ 5694/ 7851]
loss: 7.890222  [ 6162/ 7851]
loss: 6.031009  [ 6630/ 7851]
loss: 5.427597  [ 7098/ 7851]
loss: 4.972368  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.7%, Avg loss: 5.354565 
Epoch 31
-------------------------------
loss: 6.176530  [   79/ 7851]
loss: 6.603909  [  547/ 7851]
loss: 4.623075  [ 1015/ 7851]
loss: 6.354184  [ 1483/ 7851]
loss: 6.937969  [ 1951/ 7851]
loss: 5.213286  [ 2419/ 7851]
loss: 4.241681  [ 2887/ 7851]
loss: 5.787827  [ 3355/ 7851]
loss: 6.312984  [ 3823/ 7851]
loss: 5.940174  [ 4290/ 7851]
loss: 6.537818  [ 4758/ 7851]
loss: 6.767556  [ 5226/ 7851]
loss: 4.094591  [ 5694/ 7851]
loss: 8.422718  [ 6162/ 7851]
loss: 5.749974  [ 6630/ 7851]
loss: 5.362403  [ 7098/ 7851]
loss: 4.286676  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 5.824352 
Epoch 32
-------------------------------
loss: 6.453305  [   79/ 7851]
loss: 7.359885  [  547/ 7851]
loss: 4.769175  [ 1015/ 7851]
loss: 5.790751  [ 1483/ 7851]
loss: 7.949067  [ 1951/ 7851]
loss: 5.222209  [ 2419/ 7851]
loss: 4.463145  [ 2887/ 7851]
loss: 5.191438  [ 3355/ 7851]
loss: 6.176120  [ 3823/ 7851]
loss: 5.414629  [ 4290/ 7851]
loss: 6.454883  [ 4758/ 7851]
loss: 5.926319  [ 5226/ 7851]
loss: 3.411425  [ 5694/ 7851]
loss: 8.027382  [ 6162/ 7851]
loss: 5.122610  [ 6630/ 7851]
loss: 6.024244  [ 7098/ 7851]
loss: 4.103964  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 6.061442 
Epoch 33
-------------------------------
loss: 6.428111  [   79/ 7851]
loss: 6.974506  [  547/ 7851]
loss: 5.022869  [ 1015/ 7851]
loss: 6.032934  [ 1483/ 7851]
loss: 7.849548  [ 1951/ 7851]
loss: 4.839198  [ 2419/ 7851]
loss: 4.947903  [ 2887/ 7851]
loss: 5.436277  [ 3355/ 7851]
loss: 5.589198  [ 3823/ 7851]
loss: 5.977677  [ 4290/ 7851]
loss: 6.820717  [ 4758/ 7851]
loss: 7.279976  [ 5226/ 7851]
loss: 3.907867  [ 5694/ 7851]
loss: 9.153646  [ 6162/ 7851]
loss: 6.575393  [ 6630/ 7851]
loss: 4.880438  [ 7098/ 7851]
loss: 4.621464  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 5.870814 
Epoch 34
-------------------------------
loss: 6.071371  [   79/ 7851]
loss: 5.988058  [  547/ 7851]
loss: 4.870087  [ 1015/ 7851]
loss: 5.344445  [ 1483/ 7851]
loss: 6.679425  [ 1951/ 7851]
loss: 4.995365  [ 2419/ 7851]
loss: 4.096890  [ 2887/ 7851]
loss: 5.239226  [ 3355/ 7851]
loss: 6.084642  [ 3823/ 7851]
loss: 6.167445  [ 4290/ 7851]
loss: 6.414438  [ 4758/ 7851]
loss: 5.964762  [ 5226/ 7851]
loss: 3.306645  [ 5694/ 7851]
loss: 8.562720  [ 6162/ 7851]
loss: 6.261244  [ 6630/ 7851]
loss: 5.463546  [ 7098/ 7851]
loss: 4.918522  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 5.818937 
Epoch 35
-------------------------------
loss: 6.067283  [   79/ 7851]
loss: 5.981291  [  547/ 7851]
loss: 5.211390  [ 1015/ 7851]
loss: 5.659073  [ 1483/ 7851]
loss: 6.809756  [ 1951/ 7851]
loss: 5.192898  [ 2419/ 7851]
loss: 4.149022  [ 2887/ 7851]
loss: 5.221795  [ 3355/ 7851]
loss: 5.782823  [ 3823/ 7851]
loss: 5.546161  [ 4290/ 7851]
loss: 6.588154  [ 4758/ 7851]
loss: 5.835647  [ 5226/ 7851]
loss: 4.401702  [ 5694/ 7851]
loss: 8.375752  [ 6162/ 7851]
loss: 6.697216  [ 6630/ 7851]
loss: 4.928782  [ 7098/ 7851]
loss: 4.855809  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.515196 
Epoch 36
-------------------------------
loss: 6.303817  [   79/ 7851]
loss: 6.266406  [  547/ 7851]
loss: 5.440523  [ 1015/ 7851]
loss: 5.631511  [ 1483/ 7851]
loss: 6.681025  [ 1951/ 7851]
loss: 5.444714  [ 2419/ 7851]
loss: 5.364738  [ 2887/ 7851]
loss: 5.901801  [ 3355/ 7851]
loss: 6.150695  [ 3823/ 7851]
loss: 5.717486  [ 4290/ 7851]
loss: 7.102935  [ 4758/ 7851]
loss: 6.208971  [ 5226/ 7851]
loss: 4.232584  [ 5694/ 7851]
loss: 8.347854  [ 6162/ 7851]
loss: 6.032237  [ 6630/ 7851]
loss: 5.152971  [ 7098/ 7851]
loss: 4.450912  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 5.559194 
Epoch 37
-------------------------------
loss: 5.843627  [   79/ 7851]
loss: 6.860065  [  547/ 7851]
loss: 4.777357  [ 1015/ 7851]
loss: 6.792367  [ 1483/ 7851]
loss: 6.082288  [ 1951/ 7851]
loss: 5.451185  [ 2419/ 7851]
loss: 4.878172  [ 2887/ 7851]
loss: 5.584558  [ 3355/ 7851]
loss: 6.123870  [ 3823/ 7851]
loss: 5.182255  [ 4290/ 7851]
loss: 6.857758  [ 4758/ 7851]
loss: 6.043675  [ 5226/ 7851]
loss: 4.118321  [ 5694/ 7851]
loss: 8.112658  [ 6162/ 7851]
loss: 5.815715  [ 6630/ 7851]
loss: 4.949929  [ 7098/ 7851]
loss: 4.646337  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.691816 
Epoch 38
-------------------------------
loss: 5.585722  [   79/ 7851]
loss: 7.000234  [  547/ 7851]
loss: 5.130814  [ 1015/ 7851]
loss: 6.433909  [ 1483/ 7851]
loss: 6.915181  [ 1951/ 7851]
loss: 5.867955  [ 2419/ 7851]
loss: 5.376754  [ 2887/ 7851]
loss: 5.497776  [ 3355/ 7851]
loss: 6.066625  [ 3823/ 7851]
loss: 6.518384  [ 4290/ 7851]
loss: 6.497539  [ 4758/ 7851]
loss: 6.414243  [ 5226/ 7851]
loss: 3.615600  [ 5694/ 7851]
loss: 8.908563  [ 6162/ 7851]
loss: 6.206751  [ 6630/ 7851]
loss: 5.586772  [ 7098/ 7851]
loss: 4.616822  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.613589 
Epoch 39
-------------------------------
loss: 5.366333  [   79/ 7851]
loss: 6.266031  [  547/ 7851]
loss: 5.130637  [ 1015/ 7851]
loss: 6.301488  [ 1483/ 7851]
loss: 7.326758  [ 1951/ 7851]
loss: 5.519173  [ 2419/ 7851]
loss: 3.803491  [ 2887/ 7851]
loss: 5.074078  [ 3355/ 7851]
loss: 5.555560  [ 3823/ 7851]
loss: 5.846342  [ 4290/ 7851]
loss: 6.407851  [ 4758/ 7851]
loss: 6.083035  [ 5226/ 7851]
loss: 3.858483  [ 5694/ 7851]
loss: 7.976315  [ 6162/ 7851]
loss: 6.012439  [ 6630/ 7851]
loss: 5.753696  [ 7098/ 7851]
loss: 5.684449  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.878306 
Epoch 40
-------------------------------
loss: 5.257000  [   79/ 7851]
loss: 6.503271  [  547/ 7851]
loss: 4.981925  [ 1015/ 7851]
loss: 6.382969  [ 1483/ 7851]
loss: 6.983655  [ 1951/ 7851]
loss: 5.393663  [ 2419/ 7851]
loss: 5.104320  [ 2887/ 7851]
loss: 5.575825  [ 3355/ 7851]
loss: 6.310156  [ 3823/ 7851]
loss: 6.240987  [ 4290/ 7851]
loss: 6.501348  [ 4758/ 7851]
loss: 6.807508  [ 5226/ 7851]
loss: 4.051264  [ 5694/ 7851]
loss: 8.318859  [ 6162/ 7851]
loss: 6.163888  [ 6630/ 7851]
loss: 5.092748  [ 7098/ 7851]
loss: 5.099557  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.2%, Avg loss: 5.194945 
Epoch 41
-------------------------------
loss: 6.444043  [   79/ 7851]
loss: 6.428668  [  547/ 7851]
loss: 5.300399  [ 1015/ 7851]
loss: 6.380238  [ 1483/ 7851]
loss: 6.775052  [ 1951/ 7851]
loss: 5.625778  [ 2419/ 7851]
loss: 3.779502  [ 2887/ 7851]
loss: 5.285590  [ 3355/ 7851]
loss: 6.140099  [ 3823/ 7851]
loss: 6.018767  [ 4290/ 7851]
loss: 6.517059  [ 4758/ 7851]
loss: 5.928481  [ 5226/ 7851]
loss: 3.819599  [ 5694/ 7851]
loss: 8.087819  [ 6162/ 7851]
loss: 6.246400  [ 6630/ 7851]
loss: 6.269326  [ 7098/ 7851]
loss: 4.104546  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 5.410143 
Epoch 42
-------------------------------
loss: 6.098213  [   79/ 7851]
loss: 5.884382  [  547/ 7851]
loss: 4.365299  [ 1015/ 7851]
loss: 6.090576  [ 1483/ 7851]
loss: 6.813685  [ 1951/ 7851]
loss: 6.128301  [ 2419/ 7851]
loss: 3.745961  [ 2887/ 7851]
loss: 5.470438  [ 3355/ 7851]
loss: 5.782575  [ 3823/ 7851]
loss: 5.606503  [ 4290/ 7851]
loss: 6.752948  [ 4758/ 7851]
loss: 6.934174  [ 5226/ 7851]
loss: 3.351061  [ 5694/ 7851]
loss: 8.487409  [ 6162/ 7851]
loss: 5.324615  [ 6630/ 7851]
loss: 5.403606  [ 7098/ 7851]
loss: 4.493265  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 5.581811 
Epoch 43
-------------------------------
loss: 6.150215  [   79/ 7851]
loss: 6.843287  [  547/ 7851]
loss: 4.959057  [ 1015/ 7851]
loss: 6.132885  [ 1483/ 7851]
loss: 6.814904  [ 1951/ 7851]
loss: 5.723848  [ 2419/ 7851]
loss: 4.410151  [ 2887/ 7851]
loss: 5.781423  [ 3355/ 7851]
loss: 7.049671  [ 3823/ 7851]
loss: 5.236675  [ 4290/ 7851]
loss: 6.600906  [ 4758/ 7851]
loss: 6.168894  [ 5226/ 7851]
loss: 4.082218  [ 5694/ 7851]
loss: 8.837425  [ 6162/ 7851]
loss: 6.538579  [ 6630/ 7851]
loss: 5.402918  [ 7098/ 7851]
loss: 4.287812  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.7%, Avg loss: 5.615284 
Epoch 44
-------------------------------
loss: 6.495626  [   79/ 7851]
loss: 6.312436  [  547/ 7851]
loss: 5.572645  [ 1015/ 7851]
loss: 6.386650  [ 1483/ 7851]
loss: 7.434587  [ 1951/ 7851]
loss: 5.584033  [ 2419/ 7851]
loss: 5.332983  [ 2887/ 7851]
loss: 5.426613  [ 3355/ 7851]
loss: 6.251617  [ 3823/ 7851]
loss: 5.540049  [ 4290/ 7851]
loss: 6.692757  [ 4758/ 7851]
loss: 6.187450  [ 5226/ 7851]
loss: 4.222045  [ 5694/ 7851]
loss: 7.891931  [ 6162/ 7851]
loss: 5.582483  [ 6630/ 7851]
loss: 5.854342  [ 7098/ 7851]
loss: 4.293695  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 5.881932 
Epoch 45
-------------------------------
loss: 5.878236  [   79/ 7851]
loss: 6.747778  [  547/ 7851]
loss: 4.454402  [ 1015/ 7851]
loss: 5.325564  [ 1483/ 7851]
loss: 7.335276  [ 1951/ 7851]
loss: 5.505958  [ 2419/ 7851]
loss: 4.454038  [ 2887/ 7851]
loss: 5.571291  [ 3355/ 7851]
loss: 6.530071  [ 3823/ 7851]
loss: 5.928353  [ 4290/ 7851]
loss: 6.811097  [ 4758/ 7851]
loss: 6.050328  [ 5226/ 7851]
loss: 3.719998  [ 5694/ 7851]
loss: 8.244458  [ 6162/ 7851]
loss: 6.076820  [ 6630/ 7851]
loss: 4.818501  [ 7098/ 7851]
loss: 4.563616  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 5.626711 
Epoch 46
-------------------------------
loss: 6.182014  [   79/ 7851]
loss: 6.066849  [  547/ 7851]
loss: 4.982267  [ 1015/ 7851]
loss: 6.523189  [ 1483/ 7851]
loss: 6.190677  [ 1951/ 7851]
loss: 4.838307  [ 2419/ 7851]
loss: 4.706009  [ 2887/ 7851]
loss: 5.467565  [ 3355/ 7851]
loss: 6.272811  [ 3823/ 7851]
loss: 5.800248  [ 4290/ 7851]
loss: 6.957480  [ 4758/ 7851]
loss: 6.230738  [ 5226/ 7851]
loss: 3.850175  [ 5694/ 7851]
loss: 8.364171  [ 6162/ 7851]
loss: 5.334681  [ 6630/ 7851]
loss: 5.978605  [ 7098/ 7851]
loss: 4.668563  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.991402 
Epoch 47
-------------------------------
loss: 5.329825  [   79/ 7851]
loss: 6.526175  [  547/ 7851]
loss: 5.049541  [ 1015/ 7851]
loss: 5.994240  [ 1483/ 7851]
loss: 7.009641  [ 1951/ 7851]
loss: 5.041396  [ 2419/ 7851]
loss: 5.183823  [ 2887/ 7851]
loss: 5.286930  [ 3355/ 7851]
loss: 6.389184  [ 3823/ 7851]
loss: 4.956166  [ 4290/ 7851]
loss: 6.706854  [ 4758/ 7851]
loss: 6.014816  [ 5226/ 7851]
loss: 3.985201  [ 5694/ 7851]
loss: 9.225182  [ 6162/ 7851]
loss: 5.647174  [ 6630/ 7851]
loss: 5.700145  [ 7098/ 7851]
loss: 4.326559  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 5.400130 
Epoch 48
-------------------------------
loss: 5.366107  [   79/ 7851]
loss: 6.626649  [  547/ 7851]
loss: 5.207811  [ 1015/ 7851]
loss: 5.840992  [ 1483/ 7851]
loss: 6.459718  [ 1951/ 7851]
loss: 5.429245  [ 2419/ 7851]
loss: 3.610964  [ 2887/ 7851]
loss: 5.240339  [ 3355/ 7851]
loss: 6.959800  [ 3823/ 7851]
loss: 5.183942  [ 4290/ 7851]
loss: 6.433949  [ 4758/ 7851]
loss: 6.606604  [ 5226/ 7851]
loss: 3.350221  [ 5694/ 7851]
loss: 7.921052  [ 6162/ 7851]
loss: 5.719094  [ 6630/ 7851]
loss: 4.560344  [ 7098/ 7851]
loss: 4.671370  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 5.530053 
Epoch 49
-------------------------------
loss: 5.786663  [   79/ 7851]
loss: 6.666967  [  547/ 7851]
loss: 4.529939  [ 1015/ 7851]
loss: 5.951662  [ 1483/ 7851]
loss: 7.376869  [ 1951/ 7851]
loss: 4.998831  [ 2419/ 7851]
loss: 4.000274  [ 2887/ 7851]
loss: 5.782012  [ 3355/ 7851]
loss: 5.827393  [ 3823/ 7851]
loss: 5.971994  [ 4290/ 7851]
loss: 6.431121  [ 4758/ 7851]
loss: 5.904802  [ 5226/ 7851]
loss: 3.818101  [ 5694/ 7851]
loss: 7.102701  [ 6162/ 7851]
loss: 6.200563  [ 6630/ 7851]
loss: 4.537915  [ 7098/ 7851]
loss: 4.850248  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.0%, Avg loss: 6.607236 
Epoch 50
-------------------------------
loss: 6.357591  [   79/ 7851]
loss: 7.222420  [  547/ 7851]
loss: 5.322006  [ 1015/ 7851]
loss: 5.814080  [ 1483/ 7851]
loss: 7.512497  [ 1951/ 7851]
loss: 5.369120  [ 2419/ 7851]
loss: 3.941817  [ 2887/ 7851]
loss: 5.136266  [ 3355/ 7851]
loss: 6.971471  [ 3823/ 7851]
loss: 5.777184  [ 4290/ 7851]
loss: 6.769744  [ 4758/ 7851]
loss: 6.982786  [ 5226/ 7851]
loss: 5.183794  [ 5694/ 7851]
loss: 8.325659  [ 6162/ 7851]
loss: 6.082881  [ 6630/ 7851]
loss: 5.077040  [ 7098/ 7851]
loss: 4.723511  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.500021 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 8000]               648,000
│    └─ReLU: 2-2                         [100, 8000]               --
│    └─Linear: 2-3                       [100, 80]                 640,080
==========================================================================================
Total params: 1,288,080
Trainable params: 1,288,080
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 128.81
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 6.46
Params size (MB): 5.15
Estimated Total Size (MB): 11.65
==========================================================================================
Epoch 1
-------------------------------
loss: 12.683240  [   79/ 7851]
loss: 7.427610  [  547/ 7851]
loss: 7.310735  [ 1015/ 7851]
loss: 8.290323  [ 1483/ 7851]
loss: 9.996055  [ 1951/ 7851]
loss: 8.233928  [ 2419/ 7851]
loss: 6.301847  [ 2887/ 7851]
loss: 9.032722  [ 3355/ 7851]
loss: 10.483517  [ 3823/ 7851]
loss: 7.883005  [ 4290/ 7851]
loss: 6.078550  [ 4758/ 7851]
loss: 7.464874  [ 5226/ 7851]
loss: 4.742761  [ 5694/ 7851]
loss: 5.470297  [ 6162/ 7851]
loss: 9.219149  [ 6630/ 7851]
loss: 7.945700  [ 7098/ 7851]
loss: 4.643304  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.6%, Avg loss: 7.381726 
Epoch 2
-------------------------------
loss: 7.915567  [   79/ 7851]
loss: 6.099165  [  547/ 7851]
loss: 6.091648  [ 1015/ 7851]
loss: 5.911949  [ 1483/ 7851]
loss: 6.312941  [ 1951/ 7851]
loss: 5.437837  [ 2419/ 7851]
loss: 6.495729  [ 2887/ 7851]
loss: 9.162746  [ 3355/ 7851]
loss: 5.453351  [ 3823/ 7851]
loss: 7.114589  [ 4290/ 7851]
loss: 5.799115  [ 4758/ 7851]
loss: 7.335339  [ 5226/ 7851]
loss: 5.280659  [ 5694/ 7851]
loss: 5.443394  [ 6162/ 7851]
loss: 5.958774  [ 6630/ 7851]
loss: 10.501857  [ 7098/ 7851]
loss: 4.956204  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.120841 
Epoch 3
-------------------------------
loss: 6.557414  [   79/ 7851]
loss: 5.999766  [  547/ 7851]
loss: 5.993182  [ 1015/ 7851]
loss: 8.239155  [ 1483/ 7851]
loss: 6.151397  [ 1951/ 7851]
loss: 4.669622  [ 2419/ 7851]
loss: 6.426065  [ 2887/ 7851]
loss: 8.172269  [ 3355/ 7851]
loss: 5.268640  [ 3823/ 7851]
loss: 6.782283  [ 4290/ 7851]
loss: 6.645618  [ 4758/ 7851]
loss: 6.856641  [ 5226/ 7851]
loss: 4.163553  [ 5694/ 7851]
loss: 5.833422  [ 6162/ 7851]
loss: 5.750986  [ 6630/ 7851]
loss: 7.197001  [ 7098/ 7851]
loss: 4.910429  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 5.800533 
Epoch 4
-------------------------------
loss: 6.492899  [   79/ 7851]
loss: 6.104462  [  547/ 7851]
loss: 5.735085  [ 1015/ 7851]
loss: 5.587428  [ 1483/ 7851]
loss: 5.413320  [ 1951/ 7851]
loss: 4.780503  [ 2419/ 7851]
loss: 5.721331  [ 2887/ 7851]
loss: 8.186464  [ 3355/ 7851]
loss: 5.004257  [ 3823/ 7851]
loss: 7.641536  [ 4290/ 7851]
loss: 5.655214  [ 4758/ 7851]
loss: 6.990421  [ 5226/ 7851]
loss: 5.071561  [ 5694/ 7851]
loss: 6.534178  [ 6162/ 7851]
loss: 5.635360  [ 6630/ 7851]
loss: 6.925194  [ 7098/ 7851]
loss: 4.702815  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 10.714264 
Epoch 5
-------------------------------
loss: 11.453577  [   79/ 7851]
loss: 7.291481  [  547/ 7851]
loss: 7.526305  [ 1015/ 7851]
loss: 6.196798  [ 1483/ 7851]
loss: 5.331481  [ 1951/ 7851]
loss: 5.547355  [ 2419/ 7851]
loss: 6.054011  [ 2887/ 7851]
loss: 7.702246  [ 3355/ 7851]
loss: 4.777483  [ 3823/ 7851]
loss: 6.826169  [ 4290/ 7851]
loss: 5.217750  [ 4758/ 7851]
loss: 7.191484  [ 5226/ 7851]
loss: 4.726578  [ 5694/ 7851]
loss: 5.415655  [ 6162/ 7851]
loss: 6.163358  [ 6630/ 7851]
loss: 7.061043  [ 7098/ 7851]
loss: 5.168761  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.108731 
Epoch 6
-------------------------------
loss: 6.644558  [   79/ 7851]
loss: 5.914152  [  547/ 7851]
loss: 6.332430  [ 1015/ 7851]
loss: 5.849699  [ 1483/ 7851]
loss: 6.233638  [ 1951/ 7851]
loss: 5.033070  [ 2419/ 7851]
loss: 5.680028  [ 2887/ 7851]
loss: 8.363880  [ 3355/ 7851]
loss: 6.025090  [ 3823/ 7851]
loss: 7.878373  [ 4290/ 7851]
loss: 6.122159  [ 4758/ 7851]
loss: 6.790108  [ 5226/ 7851]
loss: 4.835910  [ 5694/ 7851]
loss: 6.607695  [ 6162/ 7851]
loss: 5.945164  [ 6630/ 7851]
loss: 6.774096  [ 7098/ 7851]
loss: 5.309124  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.971960 
Epoch 7
-------------------------------
loss: 7.759534  [   79/ 7851]
loss: 5.639402  [  547/ 7851]
loss: 5.805747  [ 1015/ 7851]
loss: 6.038142  [ 1483/ 7851]
loss: 5.826982  [ 1951/ 7851]
loss: 5.344968  [ 2419/ 7851]
loss: 6.009822  [ 2887/ 7851]
loss: 8.634756  [ 3355/ 7851]
loss: 4.924600  [ 3823/ 7851]
loss: 7.033837  [ 4290/ 7851]
loss: 5.419524  [ 4758/ 7851]
loss: 6.627890  [ 5226/ 7851]
loss: 5.209786  [ 5694/ 7851]
loss: 6.270678  [ 6162/ 7851]
loss: 5.404683  [ 6630/ 7851]
loss: 7.299705  [ 7098/ 7851]
loss: 4.466711  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 5.246021 
Epoch 8
-------------------------------
loss: 5.946391  [   79/ 7851]
loss: 5.091176  [  547/ 7851]
loss: 5.504645  [ 1015/ 7851]
loss: 6.774313  [ 1483/ 7851]
loss: 6.382089  [ 1951/ 7851]
loss: 5.026949  [ 2419/ 7851]
loss: 6.003090  [ 2887/ 7851]
loss: 7.839200  [ 3355/ 7851]
loss: 5.387074  [ 3823/ 7851]
loss: 6.865276  [ 4290/ 7851]
loss: 5.924191  [ 4758/ 7851]
loss: 6.669278  [ 5226/ 7851]
loss: 4.577307  [ 5694/ 7851]
loss: 6.191482  [ 6162/ 7851]
loss: 5.480752  [ 6630/ 7851]
loss: 6.874070  [ 7098/ 7851]
loss: 4.675249  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.910636 
Epoch 9
-------------------------------
loss: 6.666113  [   79/ 7851]
loss: 5.322266  [  547/ 7851]
loss: 6.071587  [ 1015/ 7851]
loss: 5.625200  [ 1483/ 7851]
loss: 5.455182  [ 1951/ 7851]
loss: 4.710447  [ 2419/ 7851]
loss: 5.487907  [ 2887/ 7851]
loss: 8.770579  [ 3355/ 7851]
loss: 5.963776  [ 3823/ 7851]
loss: 7.483290  [ 4290/ 7851]
loss: 5.860643  [ 4758/ 7851]
loss: 6.374864  [ 5226/ 7851]
loss: 4.864306  [ 5694/ 7851]
loss: 5.582399  [ 6162/ 7851]
loss: 4.927518  [ 6630/ 7851]
loss: 7.903683  [ 7098/ 7851]
loss: 4.107342  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.511282 
Epoch 10
-------------------------------
loss: 5.797822  [   79/ 7851]
loss: 6.048392  [  547/ 7851]
loss: 5.601963  [ 1015/ 7851]
loss: 6.339188  [ 1483/ 7851]
loss: 5.199041  [ 1951/ 7851]
loss: 4.258441  [ 2419/ 7851]
loss: 5.623863  [ 2887/ 7851]
loss: 7.930453  [ 3355/ 7851]
loss: 5.180666  [ 3823/ 7851]
loss: 7.486799  [ 4290/ 7851]
loss: 5.881776  [ 4758/ 7851]
loss: 6.836504  [ 5226/ 7851]
loss: 4.176264  [ 5694/ 7851]
loss: 6.090860  [ 6162/ 7851]
loss: 5.414989  [ 6630/ 7851]
loss: 7.651455  [ 7098/ 7851]
loss: 4.022017  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 6.497226 
Epoch 11
-------------------------------
loss: 6.235363  [   79/ 7851]
loss: 5.949687  [  547/ 7851]
loss: 6.092521  [ 1015/ 7851]
loss: 8.559101  [ 1483/ 7851]
loss: 6.183697  [ 1951/ 7851]
loss: 4.962936  [ 2419/ 7851]
loss: 5.515707  [ 2887/ 7851]
loss: 7.618189  [ 3355/ 7851]
loss: 5.235508  [ 3823/ 7851]
loss: 6.472146  [ 4290/ 7851]
loss: 5.364659  [ 4758/ 7851]
loss: 5.620582  [ 5226/ 7851]
loss: 4.945570  [ 5694/ 7851]
loss: 6.324190  [ 6162/ 7851]
loss: 4.649234  [ 6630/ 7851]
loss: 6.056933  [ 7098/ 7851]
loss: 4.955498  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.799423 
Epoch 12
-------------------------------
loss: 6.311112  [   79/ 7851]
loss: 5.678635  [  547/ 7851]
loss: 5.289113  [ 1015/ 7851]
loss: 5.609633  [ 1483/ 7851]
loss: 5.798236  [ 1951/ 7851]
loss: 4.215691  [ 2419/ 7851]
loss: 5.594713  [ 2887/ 7851]
loss: 9.583357  [ 3355/ 7851]
loss: 7.407562  [ 3823/ 7851]
loss: 7.343601  [ 4290/ 7851]
loss: 6.146794  [ 4758/ 7851]
loss: 4.783751  [ 5226/ 7851]
loss: 4.464584  [ 5694/ 7851]
loss: 5.568297  [ 6162/ 7851]
loss: 4.062382  [ 6630/ 7851]
loss: 5.716989  [ 7098/ 7851]
loss: 4.532821  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 5.763380 
Epoch 13
-------------------------------
loss: 6.418954  [   79/ 7851]
loss: 3.513761  [  547/ 7851]
loss: 5.716946  [ 1015/ 7851]
loss: 5.443981  [ 1483/ 7851]
loss: 6.190188  [ 1951/ 7851]
loss: 4.573075  [ 2419/ 7851]
loss: 5.194098  [ 2887/ 7851]
loss: 6.804018  [ 3355/ 7851]
loss: 5.738315  [ 3823/ 7851]
loss: 7.438791  [ 4290/ 7851]
loss: 5.627998  [ 4758/ 7851]
loss: 5.122761  [ 5226/ 7851]
loss: 4.553253  [ 5694/ 7851]
loss: 5.960167  [ 6162/ 7851]
loss: 4.323033  [ 6630/ 7851]
loss: 6.279171  [ 7098/ 7851]
loss: 4.528385  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.900866 
Epoch 14
-------------------------------
loss: 5.842504  [   79/ 7851]
loss: 3.362600  [  547/ 7851]
loss: 5.882717  [ 1015/ 7851]
loss: 5.570784  [ 1483/ 7851]
loss: 5.707202  [ 1951/ 7851]
loss: 4.719707  [ 2419/ 7851]
loss: 5.477402  [ 2887/ 7851]
loss: 6.879186  [ 3355/ 7851]
loss: 5.026215  [ 3823/ 7851]
loss: 6.627974  [ 4290/ 7851]
loss: 5.094846  [ 4758/ 7851]
loss: 4.458606  [ 5226/ 7851]
loss: 4.320181  [ 5694/ 7851]
loss: 5.835029  [ 6162/ 7851]
loss: 3.925621  [ 6630/ 7851]
loss: 5.448938  [ 7098/ 7851]
loss: 4.340143  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.300187 
Epoch 15
-------------------------------
loss: 7.643592  [   79/ 7851]
loss: 3.879753  [  547/ 7851]
loss: 5.502355  [ 1015/ 7851]
loss: 5.810705  [ 1483/ 7851]
loss: 5.800742  [ 1951/ 7851]
loss: 4.664278  [ 2419/ 7851]
loss: 5.115186  [ 2887/ 7851]
loss: 6.177877  [ 3355/ 7851]
loss: 5.279495  [ 3823/ 7851]
loss: 8.036544  [ 4290/ 7851]
loss: 5.805549  [ 4758/ 7851]
loss: 4.419521  [ 5226/ 7851]
loss: 4.774654  [ 5694/ 7851]
loss: 5.303737  [ 6162/ 7851]
loss: 4.082818  [ 6630/ 7851]
loss: 7.083516  [ 7098/ 7851]
loss: 4.837839  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.888329 
Epoch 16
-------------------------------
loss: 6.511853  [   79/ 7851]
loss: 4.149623  [  547/ 7851]
loss: 5.660725  [ 1015/ 7851]
loss: 5.058896  [ 1483/ 7851]
loss: 5.426901  [ 1951/ 7851]
loss: 4.592428  [ 2419/ 7851]
loss: 6.390137  [ 2887/ 7851]
loss: 7.127944  [ 3355/ 7851]
loss: 6.251955  [ 3823/ 7851]
loss: 7.503043  [ 4290/ 7851]
loss: 5.545336  [ 4758/ 7851]
loss: 4.289991  [ 5226/ 7851]
loss: 4.595697  [ 5694/ 7851]
loss: 5.232012  [ 6162/ 7851]
loss: 4.237112  [ 6630/ 7851]
loss: 5.803514  [ 7098/ 7851]
loss: 5.109747  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 5.607841 
Epoch 17
-------------------------------
loss: 6.298584  [   79/ 7851]
loss: 3.974775  [  547/ 7851]
loss: 5.551919  [ 1015/ 7851]
loss: 5.065788  [ 1483/ 7851]
loss: 5.461441  [ 1951/ 7851]
loss: 4.691815  [ 2419/ 7851]
loss: 5.797276  [ 2887/ 7851]
loss: 7.388247  [ 3355/ 7851]
loss: 5.903472  [ 3823/ 7851]
loss: 7.447826  [ 4290/ 7851]
loss: 5.150254  [ 4758/ 7851]
loss: 3.667859  [ 5226/ 7851]
loss: 4.377407  [ 5694/ 7851]
loss: 5.672513  [ 6162/ 7851]
loss: 4.219582  [ 6630/ 7851]
loss: 5.762904  [ 7098/ 7851]
loss: 4.496266  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.8%, Avg loss: 5.700589 
Epoch 18
-------------------------------
loss: 6.462980  [   79/ 7851]
loss: 3.866926  [  547/ 7851]
loss: 5.724837  [ 1015/ 7851]
loss: 5.588888  [ 1483/ 7851]
loss: 5.495210  [ 1951/ 7851]
loss: 4.619524  [ 2419/ 7851]
loss: 5.028199  [ 2887/ 7851]
loss: 6.868154  [ 3355/ 7851]
loss: 7.235511  [ 3823/ 7851]
loss: 7.092598  [ 4290/ 7851]
loss: 5.613736  [ 4758/ 7851]
loss: 4.318406  [ 5226/ 7851]
loss: 5.202826  [ 5694/ 7851]
loss: 5.489753  [ 6162/ 7851]
loss: 4.276186  [ 6630/ 7851]
loss: 6.013453  [ 7098/ 7851]
loss: 4.622797  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.655739 
Epoch 19
-------------------------------
loss: 6.581727  [   79/ 7851]
loss: 3.756864  [  547/ 7851]
loss: 5.407492  [ 1015/ 7851]
loss: 5.198174  [ 1483/ 7851]
loss: 5.481983  [ 1951/ 7851]
loss: 4.580559  [ 2419/ 7851]
loss: 5.515541  [ 2887/ 7851]
loss: 6.934405  [ 3355/ 7851]
loss: 5.970140  [ 3823/ 7851]
loss: 6.373315  [ 4290/ 7851]
loss: 5.516397  [ 4758/ 7851]
loss: 4.402329  [ 5226/ 7851]
loss: 4.526497  [ 5694/ 7851]
loss: 5.882601  [ 6162/ 7851]
loss: 4.187047  [ 6630/ 7851]
loss: 6.390576  [ 7098/ 7851]
loss: 4.754406  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 5.369527 
Epoch 20
-------------------------------
loss: 6.609256  [   79/ 7851]
loss: 3.425914  [  547/ 7851]
loss: 5.908074  [ 1015/ 7851]
loss: 5.608828  [ 1483/ 7851]
loss: 5.397400  [ 1951/ 7851]
loss: 4.731575  [ 2419/ 7851]
loss: 5.094285  [ 2887/ 7851]
loss: 6.817925  [ 3355/ 7851]
loss: 5.173722  [ 3823/ 7851]
loss: 6.727329  [ 4290/ 7851]
loss: 5.723201  [ 4758/ 7851]
loss: 5.324973  [ 5226/ 7851]
loss: 4.695345  [ 5694/ 7851]
loss: 5.786783  [ 6162/ 7851]
loss: 3.681957  [ 6630/ 7851]
loss: 6.412732  [ 7098/ 7851]
loss: 4.330742  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.350356 
Epoch 21
-------------------------------
loss: 5.917202  [   79/ 7851]
loss: 4.072923  [  547/ 7851]
loss: 5.281108  [ 1015/ 7851]
loss: 5.601016  [ 1483/ 7851]
loss: 5.763159  [ 1951/ 7851]
loss: 4.595400  [ 2419/ 7851]
loss: 6.006949  [ 2887/ 7851]
loss: 6.813349  [ 3355/ 7851]
loss: 6.225217  [ 3823/ 7851]
loss: 6.979384  [ 4290/ 7851]
loss: 5.559580  [ 4758/ 7851]
loss: 5.130487  [ 5226/ 7851]
loss: 4.905725  [ 5694/ 7851]
loss: 6.048366  [ 6162/ 7851]
loss: 3.784488  [ 6630/ 7851]
loss: 5.310445  [ 7098/ 7851]
loss: 5.039375  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 5.363860 
Epoch 22
-------------------------------
loss: 5.822705  [   79/ 7851]
loss: 4.642172  [  547/ 7851]
loss: 5.686096  [ 1015/ 7851]
loss: 6.406508  [ 1483/ 7851]
loss: 5.393198  [ 1951/ 7851]
loss: 5.235525  [ 2419/ 7851]
loss: 6.036914  [ 2887/ 7851]
loss: 6.893457  [ 3355/ 7851]
loss: 5.848120  [ 3823/ 7851]
loss: 7.239020  [ 4290/ 7851]
loss: 5.971360  [ 4758/ 7851]
loss: 4.246315  [ 5226/ 7851]
loss: 5.334960  [ 5694/ 7851]
loss: 5.701442  [ 6162/ 7851]
loss: 3.977442  [ 6630/ 7851]
loss: 7.306198  [ 7098/ 7851]
loss: 4.488153  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 5.377760 
Epoch 23
-------------------------------
loss: 6.143677  [   79/ 7851]
loss: 3.498897  [  547/ 7851]
loss: 6.248776  [ 1015/ 7851]
loss: 6.090340  [ 1483/ 7851]
loss: 5.565938  [ 1951/ 7851]
loss: 4.509013  [ 2419/ 7851]
loss: 5.857204  [ 2887/ 7851]
loss: 6.624561  [ 3355/ 7851]
loss: 5.514990  [ 3823/ 7851]
loss: 8.276472  [ 4290/ 7851]
loss: 5.338465  [ 4758/ 7851]
loss: 5.164675  [ 5226/ 7851]
loss: 4.688496  [ 5694/ 7851]
loss: 5.326667  [ 6162/ 7851]
loss: 4.010276  [ 6630/ 7851]
loss: 5.087673  [ 7098/ 7851]
loss: 4.057668  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 5.486385 
Epoch 24
-------------------------------
loss: 6.204029  [   79/ 7851]
loss: 3.232429  [  547/ 7851]
loss: 5.556780  [ 1015/ 7851]
loss: 5.760334  [ 1483/ 7851]
loss: 6.647072  [ 1951/ 7851]
loss: 3.978452  [ 2419/ 7851]
loss: 5.950927  [ 2887/ 7851]
loss: 7.079750  [ 3355/ 7851]
loss: 5.345148  [ 3823/ 7851]
loss: 6.962600  [ 4290/ 7851]
loss: 5.397281  [ 4758/ 7851]
loss: 4.843687  [ 5226/ 7851]
loss: 4.479250  [ 5694/ 7851]
loss: 5.307583  [ 6162/ 7851]
loss: 4.207119  [ 6630/ 7851]
loss: 5.413092  [ 7098/ 7851]
loss: 4.544276  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 5.681176 
Epoch 25
-------------------------------
loss: 6.231145  [   79/ 7851]
loss: 3.622793  [  547/ 7851]
loss: 5.829890  [ 1015/ 7851]
loss: 5.405090  [ 1483/ 7851]
loss: 6.195740  [ 1951/ 7851]
loss: 4.897745  [ 2419/ 7851]
loss: 5.666358  [ 2887/ 7851]
loss: 6.810395  [ 3355/ 7851]
loss: 4.990709  [ 3823/ 7851]
loss: 6.976516  [ 4290/ 7851]
loss: 5.470018  [ 4758/ 7851]
loss: 5.932764  [ 5226/ 7851]
loss: 4.942003  [ 5694/ 7851]
loss: 5.581124  [ 6162/ 7851]
loss: 3.991527  [ 6630/ 7851]
loss: 5.924551  [ 7098/ 7851]
loss: 4.520022  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.089467 
Epoch 26
-------------------------------
loss: 6.445011  [   79/ 7851]
loss: 4.660962  [  547/ 7851]
loss: 6.159837  [ 1015/ 7851]
loss: 5.757973  [ 1483/ 7851]
loss: 6.270948  [ 1951/ 7851]
loss: 5.050225  [ 2419/ 7851]
loss: 6.420492  [ 2887/ 7851]
loss: 6.952939  [ 3355/ 7851]
loss: 4.709011  [ 3823/ 7851]
loss: 7.168979  [ 4290/ 7851]
loss: 5.557119  [ 4758/ 7851]
loss: 5.847482  [ 5226/ 7851]
loss: 4.465086  [ 5694/ 7851]
loss: 6.351436  [ 6162/ 7851]
loss: 3.745576  [ 6630/ 7851]
loss: 5.732019  [ 7098/ 7851]
loss: 5.323225  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 5.207835 
Epoch 27
-------------------------------
loss: 5.943607  [   79/ 7851]
loss: 4.428306  [  547/ 7851]
loss: 5.930315  [ 1015/ 7851]
loss: 5.180347  [ 1483/ 7851]
loss: 5.703436  [ 1951/ 7851]
loss: 5.154603  [ 2419/ 7851]
loss: 5.056515  [ 2887/ 7851]
loss: 7.013937  [ 3355/ 7851]
loss: 5.604791  [ 3823/ 7851]
loss: 6.494268  [ 4290/ 7851]
loss: 5.184159  [ 4758/ 7851]
loss: 5.104070  [ 5226/ 7851]
loss: 4.468368  [ 5694/ 7851]
loss: 5.557391  [ 6162/ 7851]
loss: 4.120530  [ 6630/ 7851]
loss: 5.804114  [ 7098/ 7851]
loss: 4.257238  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 5.574658 
Epoch 28
-------------------------------
loss: 6.466063  [   79/ 7851]
loss: 3.351591  [  547/ 7851]
loss: 5.619636  [ 1015/ 7851]
loss: 5.857176  [ 1483/ 7851]
loss: 5.550354  [ 1951/ 7851]
loss: 4.647830  [ 2419/ 7851]
loss: 5.008606  [ 2887/ 7851]
loss: 6.206888  [ 3355/ 7851]
loss: 5.216234  [ 3823/ 7851]
loss: 7.046935  [ 4290/ 7851]
loss: 5.715086  [ 4758/ 7851]
loss: 4.329188  [ 5226/ 7851]
loss: 4.495253  [ 5694/ 7851]
loss: 5.648812  [ 6162/ 7851]
loss: 3.642017  [ 6630/ 7851]
loss: 5.576175  [ 7098/ 7851]
loss: 4.716672  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.398298 
Epoch 29
-------------------------------
loss: 6.646442  [   79/ 7851]
loss: 3.655638  [  547/ 7851]
loss: 5.144268  [ 1015/ 7851]
loss: 4.910822  [ 1483/ 7851]
loss: 5.522159  [ 1951/ 7851]
loss: 4.871119  [ 2419/ 7851]
loss: 5.174090  [ 2887/ 7851]
loss: 7.045909  [ 3355/ 7851]
loss: 4.959066  [ 3823/ 7851]
loss: 6.895774  [ 4290/ 7851]
loss: 5.109113  [ 4758/ 7851]
loss: 4.256877  [ 5226/ 7851]
loss: 4.173294  [ 5694/ 7851]
loss: 5.486390  [ 6162/ 7851]
loss: 3.979473  [ 6630/ 7851]
loss: 6.777535  [ 7098/ 7851]
loss: 4.472604  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 5.442260 
Epoch 30
-------------------------------
loss: 6.604068  [   79/ 7851]
loss: 3.768190  [  547/ 7851]
loss: 5.994301  [ 1015/ 7851]
loss: 6.116089  [ 1483/ 7851]
loss: 5.738540  [ 1951/ 7851]
loss: 4.946647  [ 2419/ 7851]
loss: 5.413996  [ 2887/ 7851]
loss: 6.839877  [ 3355/ 7851]
loss: 5.678346  [ 3823/ 7851]
loss: 6.649198  [ 4290/ 7851]
loss: 5.948121  [ 4758/ 7851]
loss: 4.326941  [ 5226/ 7851]
loss: 4.824473  [ 5694/ 7851]
loss: 5.345704  [ 6162/ 7851]
loss: 3.569732  [ 6630/ 7851]
loss: 5.610070  [ 7098/ 7851]
loss: 4.719331  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.655618 
Epoch 31
-------------------------------
loss: 6.589990  [   79/ 7851]
loss: 3.528860  [  547/ 7851]
loss: 5.477561  [ 1015/ 7851]
loss: 5.505023  [ 1483/ 7851]
loss: 5.681785  [ 1951/ 7851]
loss: 4.415513  [ 2419/ 7851]
loss: 4.736475  [ 2887/ 7851]
loss: 6.658733  [ 3355/ 7851]
loss: 5.120815  [ 3823/ 7851]
loss: 7.074708  [ 4290/ 7851]
loss: 6.441946  [ 4758/ 7851]
loss: 4.824691  [ 5226/ 7851]
loss: 4.412705  [ 5694/ 7851]
loss: 5.616929  [ 6162/ 7851]
loss: 3.931483  [ 6630/ 7851]
loss: 6.037702  [ 7098/ 7851]
loss: 4.237409  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 6.059515 
Epoch 32
-------------------------------
loss: 6.669020  [   79/ 7851]
loss: 3.608423  [  547/ 7851]
loss: 5.881490  [ 1015/ 7851]
loss: 5.863443  [ 1483/ 7851]
loss: 5.612775  [ 1951/ 7851]
loss: 4.353563  [ 2419/ 7851]
loss: 5.806634  [ 2887/ 7851]
loss: 6.465119  [ 3355/ 7851]
loss: 5.614047  [ 3823/ 7851]
loss: 7.800560  [ 4290/ 7851]
loss: 6.292862  [ 4758/ 7851]
loss: 4.794150  [ 5226/ 7851]
loss: 4.307773  [ 5694/ 7851]
loss: 5.302288  [ 6162/ 7851]
loss: 3.770208  [ 6630/ 7851]
loss: 5.188897  [ 7098/ 7851]
loss: 4.139878  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 5.780950 
Epoch 33
-------------------------------
loss: 6.926294  [   79/ 7851]
loss: 4.028576  [  547/ 7851]
loss: 5.621032  [ 1015/ 7851]
loss: 5.807652  [ 1483/ 7851]
loss: 5.299544  [ 1951/ 7851]
loss: 5.014155  [ 2419/ 7851]
loss: 5.619230  [ 2887/ 7851]
loss: 6.879430  [ 3355/ 7851]
loss: 6.372088  [ 3823/ 7851]
loss: 7.052372  [ 4290/ 7851]
loss: 6.128870  [ 4758/ 7851]
loss: 4.245234  [ 5226/ 7851]
loss: 4.539936  [ 5694/ 7851]
loss: 5.455739  [ 6162/ 7851]
loss: 3.942878  [ 6630/ 7851]
loss: 5.071156  [ 7098/ 7851]
loss: 4.326271  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 4.990746 
Epoch 34
-------------------------------
loss: 6.414175  [   79/ 7851]
loss: 3.607736  [  547/ 7851]
loss: 4.941001  [ 1015/ 7851]
loss: 5.213917  [ 1483/ 7851]
loss: 5.935007  [ 1951/ 7851]
loss: 5.907942  [ 2419/ 7851]
loss: 6.181102  [ 2887/ 7851]
loss: 8.146195  [ 3355/ 7851]
loss: 5.283268  [ 3823/ 7851]
loss: 6.718337  [ 4290/ 7851]
loss: 6.001784  [ 4758/ 7851]
loss: 4.259864  [ 5226/ 7851]
loss: 4.429063  [ 5694/ 7851]
loss: 5.694245  [ 6162/ 7851]
loss: 4.245663  [ 6630/ 7851]
loss: 5.869818  [ 7098/ 7851]
loss: 4.840706  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.790474 
Epoch 35
-------------------------------
loss: 6.402033  [   79/ 7851]
loss: 3.430805  [  547/ 7851]
loss: 5.821397  [ 1015/ 7851]
loss: 5.237797  [ 1483/ 7851]
loss: 5.653718  [ 1951/ 7851]
loss: 4.848453  [ 2419/ 7851]
loss: 5.450163  [ 2887/ 7851]
loss: 6.062570  [ 3355/ 7851]
loss: 4.439503  [ 3823/ 7851]
loss: 6.784215  [ 4290/ 7851]
loss: 6.206040  [ 4758/ 7851]
loss: 4.964809  [ 5226/ 7851]
loss: 4.673059  [ 5694/ 7851]
loss: 5.368439  [ 6162/ 7851]
loss: 4.058996  [ 6630/ 7851]
loss: 6.145456  [ 7098/ 7851]
loss: 4.515656  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.569735 
Epoch 36
-------------------------------
loss: 6.181096  [   79/ 7851]
loss: 3.754270  [  547/ 7851]
loss: 5.546272  [ 1015/ 7851]
loss: 5.694163  [ 1483/ 7851]
loss: 5.203564  [ 1951/ 7851]
loss: 4.923285  [ 2419/ 7851]
loss: 5.183831  [ 2887/ 7851]
loss: 6.781144  [ 3355/ 7851]
loss: 4.920504  [ 3823/ 7851]
loss: 6.807527  [ 4290/ 7851]
loss: 5.773695  [ 4758/ 7851]
loss: 5.224238  [ 5226/ 7851]
loss: 4.727077  [ 5694/ 7851]
loss: 5.418705  [ 6162/ 7851]
loss: 4.597919  [ 6630/ 7851]
loss: 5.165640  [ 7098/ 7851]
loss: 4.607305  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 5.366080 
Epoch 37
-------------------------------
loss: 5.688500  [   79/ 7851]
loss: 4.577084  [  547/ 7851]
loss: 5.693142  [ 1015/ 7851]
loss: 5.063812  [ 1483/ 7851]
loss: 4.509937  [ 1951/ 7851]
loss: 4.437101  [ 2419/ 7851]
loss: 5.846336  [ 2887/ 7851]
loss: 6.557167  [ 3355/ 7851]
loss: 5.199330  [ 3823/ 7851]
loss: 6.812586  [ 4290/ 7851]
loss: 5.701838  [ 4758/ 7851]
loss: 4.788223  [ 5226/ 7851]
loss: 4.690467  [ 5694/ 7851]
loss: 5.774607  [ 6162/ 7851]
loss: 4.027920  [ 6630/ 7851]
loss: 5.977385  [ 7098/ 7851]
loss: 4.596034  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.7%, Avg loss: 5.790327 
Epoch 38
-------------------------------
loss: 6.641107  [   79/ 7851]
loss: 3.935384  [  547/ 7851]
loss: 6.001861  [ 1015/ 7851]
loss: 5.171897  [ 1483/ 7851]
loss: 5.625420  [ 1951/ 7851]
loss: 4.691822  [ 2419/ 7851]
loss: 5.338233  [ 2887/ 7851]
loss: 6.245412  [ 3355/ 7851]
loss: 5.338991  [ 3823/ 7851]
loss: 6.974322  [ 4290/ 7851]
loss: 5.545664  [ 4758/ 7851]
loss: 4.421729  [ 5226/ 7851]
loss: 4.664392  [ 5694/ 7851]
loss: 5.461038  [ 6162/ 7851]
loss: 4.069672  [ 6630/ 7851]
loss: 5.765720  [ 7098/ 7851]
loss: 4.193830  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.182614 
Epoch 39
-------------------------------
loss: 7.003320  [   79/ 7851]
loss: 4.199647  [  547/ 7851]
loss: 5.640508  [ 1015/ 7851]
loss: 5.661519  [ 1483/ 7851]
loss: 5.666018  [ 1951/ 7851]
loss: 4.494587  [ 2419/ 7851]
loss: 5.557539  [ 2887/ 7851]
loss: 6.735462  [ 3355/ 7851]
loss: 5.664917  [ 3823/ 7851]
loss: 7.462708  [ 4290/ 7851]
loss: 5.906167  [ 4758/ 7851]
loss: 5.110860  [ 5226/ 7851]
loss: 4.924124  [ 5694/ 7851]
loss: 5.899343  [ 6162/ 7851]
loss: 3.886021  [ 6630/ 7851]
loss: 6.435915  [ 7098/ 7851]
loss: 4.473832  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.062953 
Epoch 40
-------------------------------
loss: 6.442477  [   79/ 7851]
loss: 3.366572  [  547/ 7851]
loss: 5.839491  [ 1015/ 7851]
loss: 5.544774  [ 1483/ 7851]
loss: 5.952227  [ 1951/ 7851]
loss: 5.314438  [ 2419/ 7851]
loss: 5.692760  [ 2887/ 7851]
loss: 7.094291  [ 3355/ 7851]
loss: 5.290388  [ 3823/ 7851]
loss: 6.678354  [ 4290/ 7851]
loss: 5.639370  [ 4758/ 7851]
loss: 5.429034  [ 5226/ 7851]
loss: 4.941370  [ 5694/ 7851]
loss: 5.744659  [ 6162/ 7851]
loss: 3.886031  [ 6630/ 7851]
loss: 5.554449  [ 7098/ 7851]
loss: 4.843414  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 5.531370 
Epoch 41
-------------------------------
loss: 6.950482  [   79/ 7851]
loss: 3.402081  [  547/ 7851]
loss: 5.543804  [ 1015/ 7851]
loss: 5.361908  [ 1483/ 7851]
loss: 5.331121  [ 1951/ 7851]
loss: 5.131631  [ 2419/ 7851]
loss: 5.627489  [ 2887/ 7851]
loss: 6.380486  [ 3355/ 7851]
loss: 5.374433  [ 3823/ 7851]
loss: 7.149767  [ 4290/ 7851]
loss: 5.850223  [ 4758/ 7851]
loss: 4.622450  [ 5226/ 7851]
loss: 4.792850  [ 5694/ 7851]
loss: 5.378984  [ 6162/ 7851]
loss: 3.872444  [ 6630/ 7851]
loss: 6.352351  [ 7098/ 7851]
loss: 4.794612  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 5.208349 
Epoch 42
-------------------------------
loss: 5.708169  [   79/ 7851]
loss: 3.716877  [  547/ 7851]
loss: 4.973122  [ 1015/ 7851]
loss: 5.990299  [ 1483/ 7851]
loss: 5.750684  [ 1951/ 7851]
loss: 5.246171  [ 2419/ 7851]
loss: 5.898082  [ 2887/ 7851]
loss: 6.667941  [ 3355/ 7851]
loss: 5.533412  [ 3823/ 7851]
loss: 8.500768  [ 4290/ 7851]
loss: 5.557145  [ 4758/ 7851]
loss: 4.423100  [ 5226/ 7851]
loss: 4.660445  [ 5694/ 7851]
loss: 5.445945  [ 6162/ 7851]
loss: 3.791419  [ 6630/ 7851]
loss: 5.821650  [ 7098/ 7851]
loss: 4.567064  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.602641 
Epoch 43
-------------------------------
loss: 5.728841  [   79/ 7851]
loss: 3.624421  [  547/ 7851]
loss: 4.955589  [ 1015/ 7851]
loss: 5.417742  [ 1483/ 7851]
loss: 5.632916  [ 1951/ 7851]
loss: 4.261258  [ 2419/ 7851]
loss: 5.734551  [ 2887/ 7851]
loss: 6.067497  [ 3355/ 7851]
loss: 5.881510  [ 3823/ 7851]
loss: 7.118064  [ 4290/ 7851]
loss: 6.312480  [ 4758/ 7851]
loss: 4.346399  [ 5226/ 7851]
loss: 4.768853  [ 5694/ 7851]
loss: 5.416134  [ 6162/ 7851]
loss: 3.976724  [ 6630/ 7851]
loss: 5.330730  [ 7098/ 7851]
loss: 4.871388  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 4.982869 
Epoch 44
-------------------------------
loss: 5.725238  [   79/ 7851]
loss: 3.739577  [  547/ 7851]
loss: 5.451456  [ 1015/ 7851]
loss: 5.477057  [ 1483/ 7851]
loss: 5.612593  [ 1951/ 7851]
loss: 4.946973  [ 2419/ 7851]
loss: 5.204962  [ 2887/ 7851]
loss: 7.031830  [ 3355/ 7851]
loss: 5.749407  [ 3823/ 7851]
loss: 7.390275  [ 4290/ 7851]
loss: 5.111135  [ 4758/ 7851]
loss: 4.055747  [ 5226/ 7851]
loss: 4.598145  [ 5694/ 7851]
loss: 5.852039  [ 6162/ 7851]
loss: 3.304985  [ 6630/ 7851]
loss: 5.434036  [ 7098/ 7851]
loss: 4.592997  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.409824 
Epoch 45
-------------------------------
loss: 6.108496  [   79/ 7851]
loss: 4.093974  [  547/ 7851]
loss: 5.137205  [ 1015/ 7851]
loss: 5.046754  [ 1483/ 7851]
loss: 5.516510  [ 1951/ 7851]
loss: 4.481940  [ 2419/ 7851]
loss: 5.555399  [ 2887/ 7851]
loss: 6.038507  [ 3355/ 7851]
loss: 4.666876  [ 3823/ 7851]
loss: 5.928246  [ 4290/ 7851]
loss: 5.501653  [ 4758/ 7851]
loss: 4.943241  [ 5226/ 7851]
loss: 5.325612  [ 5694/ 7851]
loss: 5.458912  [ 6162/ 7851]
loss: 4.190491  [ 6630/ 7851]
loss: 6.797184  [ 7098/ 7851]
loss: 4.934515  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 5.258788 
Epoch 46
-------------------------------
loss: 5.879566  [   79/ 7851]
loss: 3.452982  [  547/ 7851]
loss: 5.662456  [ 1015/ 7851]
loss: 6.215317  [ 1483/ 7851]
loss: 5.579684  [ 1951/ 7851]
loss: 4.519232  [ 2419/ 7851]
loss: 6.031348  [ 2887/ 7851]
loss: 6.540508  [ 3355/ 7851]
loss: 6.082705  [ 3823/ 7851]
loss: 7.520340  [ 4290/ 7851]
loss: 5.342081  [ 4758/ 7851]
loss: 4.962457  [ 5226/ 7851]
loss: 4.778679  [ 5694/ 7851]
loss: 5.397845  [ 6162/ 7851]
loss: 4.286164  [ 6630/ 7851]
loss: 6.271234  [ 7098/ 7851]
loss: 4.611476  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 5.707511 
Epoch 47
-------------------------------
loss: 5.772042  [   79/ 7851]
loss: 3.252221  [  547/ 7851]
loss: 5.284725  [ 1015/ 7851]
loss: 5.450278  [ 1483/ 7851]
loss: 5.942504  [ 1951/ 7851]
loss: 4.361551  [ 2419/ 7851]
loss: 5.465066  [ 2887/ 7851]
loss: 7.046111  [ 3355/ 7851]
loss: 5.796810  [ 3823/ 7851]
loss: 6.848096  [ 4290/ 7851]
loss: 5.071944  [ 4758/ 7851]
loss: 5.141174  [ 5226/ 7851]
loss: 4.918019  [ 5694/ 7851]
loss: 5.444718  [ 6162/ 7851]
loss: 3.793765  [ 6630/ 7851]
loss: 5.775145  [ 7098/ 7851]
loss: 4.541718  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 5.529640 
Epoch 48
-------------------------------
loss: 6.864249  [   79/ 7851]
loss: 3.274042  [  547/ 7851]
loss: 5.372619  [ 1015/ 7851]
loss: 5.496084  [ 1483/ 7851]
loss: 5.847006  [ 1951/ 7851]
loss: 4.769026  [ 2419/ 7851]
loss: 5.048463  [ 2887/ 7851]
loss: 6.548033  [ 3355/ 7851]
loss: 6.321534  [ 3823/ 7851]
loss: 7.257463  [ 4290/ 7851]
loss: 4.996150  [ 4758/ 7851]
loss: 5.741577  [ 5226/ 7851]
loss: 4.419502  [ 5694/ 7851]
loss: 5.977379  [ 6162/ 7851]
loss: 3.756827  [ 6630/ 7851]
loss: 5.675473  [ 7098/ 7851]
loss: 4.373736  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 5.853004 
Epoch 49
-------------------------------
loss: 6.600118  [   79/ 7851]
loss: 3.805052  [  547/ 7851]
loss: 5.298322  [ 1015/ 7851]
loss: 5.589568  [ 1483/ 7851]
loss: 5.163795  [ 1951/ 7851]
loss: 4.529259  [ 2419/ 7851]
loss: 5.467761  [ 2887/ 7851]
loss: 6.750463  [ 3355/ 7851]
loss: 6.495193  [ 3823/ 7851]
loss: 6.975557  [ 4290/ 7851]
loss: 5.465954  [ 4758/ 7851]
loss: 4.517729  [ 5226/ 7851]
loss: 4.263058  [ 5694/ 7851]
loss: 4.836572  [ 6162/ 7851]
loss: 3.964504  [ 6630/ 7851]
loss: 5.899887  [ 7098/ 7851]
loss: 4.359931  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 4.790973 
Epoch 50
-------------------------------
loss: 5.479447  [   79/ 7851]
loss: 4.522182  [  547/ 7851]
loss: 5.467958  [ 1015/ 7851]
loss: 5.915290  [ 1483/ 7851]
loss: 6.067384  [ 1951/ 7851]
loss: 4.725275  [ 2419/ 7851]
loss: 5.539349  [ 2887/ 7851]
loss: 6.176661  [ 3355/ 7851]
loss: 5.022980  [ 3823/ 7851]
loss: 7.172876  [ 4290/ 7851]
loss: 5.954715  [ 4758/ 7851]
loss: 4.878019  [ 5226/ 7851]
loss: 4.982438  [ 5694/ 7851]
loss: 5.171918  [ 6162/ 7851]
loss: 4.003927  [ 6630/ 7851]
loss: 5.213048  [ 7098/ 7851]
loss: 4.949510  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 5.773529 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 8000]               648,000
│    └─ReLU: 2-2                         [100, 8000]               --
│    └─Linear: 2-3                       [100, 80]                 640,080
==========================================================================================
Total params: 1,288,080
Trainable params: 1,288,080
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 128.81
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 6.46
Params size (MB): 5.15
Estimated Total Size (MB): 11.65
==========================================================================================
Epoch 1
-------------------------------
loss: 16.303938  [   79/ 7851]
loss: 20.771729  [  547/ 7851]
loss: 7.430428  [ 1015/ 7851]
loss: 14.786282  [ 1483/ 7851]
loss: 5.884799  [ 1951/ 7851]
loss: 6.735942  [ 2419/ 7851]
loss: 7.360583  [ 2887/ 7851]
loss: 7.800790  [ 3355/ 7851]
loss: 18.432461  [ 3823/ 7851]
loss: 14.794606  [ 4290/ 7851]
loss: 5.902158  [ 4758/ 7851]
loss: 4.685821  [ 5226/ 7851]
loss: 9.126728  [ 5694/ 7851]
loss: 6.634730  [ 6162/ 7851]
loss: 8.946729  [ 6630/ 7851]
loss: 7.116567  [ 7098/ 7851]
loss: 10.368812  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 10.372380 
Epoch 2
-------------------------------
loss: 10.168994  [   79/ 7851]
loss: 10.254820  [  547/ 7851]
loss: 5.790874  [ 1015/ 7851]
loss: 7.229877  [ 1483/ 7851]
loss: 4.943707  [ 1951/ 7851]
loss: 6.242013  [ 2419/ 7851]
loss: 8.415395  [ 2887/ 7851]
loss: 5.367135  [ 3355/ 7851]
loss: 9.331903  [ 3823/ 7851]
loss: 9.797595  [ 4290/ 7851]
loss: 6.322189  [ 4758/ 7851]
loss: 4.861716  [ 5226/ 7851]
loss: 12.629211  [ 5694/ 7851]
loss: 13.199492  [ 6162/ 7851]
loss: 7.817825  [ 6630/ 7851]
loss: 7.179473  [ 7098/ 7851]
loss: 8.886759  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 8.889852 
Epoch 3
-------------------------------
loss: 8.500861  [   79/ 7851]
loss: 12.442892  [  547/ 7851]
loss: 4.910016  [ 1015/ 7851]
loss: 7.306205  [ 1483/ 7851]
loss: 6.654982  [ 1951/ 7851]
loss: 7.284156  [ 2419/ 7851]
loss: 6.334260  [ 2887/ 7851]
loss: 5.850225  [ 3355/ 7851]
loss: 8.122660  [ 3823/ 7851]
loss: 9.701471  [ 4290/ 7851]
loss: 5.813868  [ 4758/ 7851]
loss: 5.469358  [ 5226/ 7851]
loss: 7.650023  [ 5694/ 7851]
loss: 7.263857  [ 6162/ 7851]
loss: 7.272553  [ 6630/ 7851]
loss: 5.766199  [ 7098/ 7851]
loss: 7.122360  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 7.875383 
Epoch 4
-------------------------------
loss: 6.469229  [   79/ 7851]
loss: 9.089776  [  547/ 7851]
loss: 4.734632  [ 1015/ 7851]
loss: 5.606162  [ 1483/ 7851]
loss: 5.264336  [ 1951/ 7851]
loss: 8.075903  [ 2419/ 7851]
loss: 55.684841  [ 2887/ 7851]
loss: 7.579114  [ 3355/ 7851]
loss: 10.115558  [ 3823/ 7851]
loss: 7.098779  [ 4290/ 7851]
loss: 6.288032  [ 4758/ 7851]
loss: 4.941630  [ 5226/ 7851]
loss: 5.410845  [ 5694/ 7851]
loss: 7.207916  [ 6162/ 7851]
loss: 7.119421  [ 6630/ 7851]
loss: 5.802900  [ 7098/ 7851]
loss: 8.588904  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.1%, Avg loss: 8.817366 
Epoch 5
-------------------------------
loss: 8.078171  [   79/ 7851]
loss: 9.418685  [  547/ 7851]
loss: 4.680486  [ 1015/ 7851]
loss: 5.634336  [ 1483/ 7851]
loss: 5.731686  [ 1951/ 7851]
loss: 6.088530  [ 2419/ 7851]
loss: 6.203919  [ 2887/ 7851]
loss: 4.150940  [ 3355/ 7851]
loss: 6.990023  [ 3823/ 7851]
loss: 5.722694  [ 4290/ 7851]
loss: 6.246993  [ 4758/ 7851]
loss: 4.051953  [ 5226/ 7851]
loss: 6.441342  [ 5694/ 7851]
loss: 7.685705  [ 6162/ 7851]
loss: 6.847208  [ 6630/ 7851]
loss: 7.100268  [ 7098/ 7851]
loss: 6.872542  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 6.512527 
Epoch 6
-------------------------------
loss: 6.894830  [   79/ 7851]
loss: 8.350801  [  547/ 7851]
loss: 4.101534  [ 1015/ 7851]
loss: 5.901593  [ 1483/ 7851]
loss: 5.351135  [ 1951/ 7851]
loss: 13.139647  [ 2419/ 7851]
loss: 8.251698  [ 2887/ 7851]
loss: 4.218704  [ 3355/ 7851]
loss: 8.873326  [ 3823/ 7851]
loss: 7.015673  [ 4290/ 7851]
loss: 6.116770  [ 4758/ 7851]
loss: 3.857141  [ 5226/ 7851]
loss: 4.678219  [ 5694/ 7851]
loss: 7.270344  [ 6162/ 7851]
loss: 6.090226  [ 6630/ 7851]
loss: 6.649030  [ 7098/ 7851]
loss: 6.901018  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 7.920738 
Epoch 7
-------------------------------
loss: 8.925997  [   79/ 7851]
loss: 8.329468  [  547/ 7851]
loss: 6.780737  [ 1015/ 7851]
loss: 5.217524  [ 1483/ 7851]
loss: 6.555572  [ 1951/ 7851]
loss: 5.787827  [ 2419/ 7851]
loss: 6.061361  [ 2887/ 7851]
loss: 3.138345  [ 3355/ 7851]
loss: 8.081960  [ 3823/ 7851]
loss: 5.887166  [ 4290/ 7851]
loss: 13.976758  [ 4758/ 7851]
loss: 5.099580  [ 5226/ 7851]
loss: 6.565244  [ 5694/ 7851]
loss: 6.398034  [ 6162/ 7851]
loss: 6.390645  [ 6630/ 7851]
loss: 19.345861  [ 7098/ 7851]
loss: 6.546392  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 7.850735 
Epoch 8
-------------------------------
loss: 7.878108  [   79/ 7851]
loss: 9.823086  [  547/ 7851]
loss: 5.257050  [ 1015/ 7851]
loss: 10.263239  [ 1483/ 7851]
loss: 5.948240  [ 1951/ 7851]
loss: 6.940943  [ 2419/ 7851]
loss: 12.315467  [ 2887/ 7851]
loss: 4.153578  [ 3355/ 7851]
loss: 8.557012  [ 3823/ 7851]
loss: 5.668523  [ 4290/ 7851]
loss: 6.614788  [ 4758/ 7851]
loss: 3.737373  [ 5226/ 7851]
loss: 6.561091  [ 5694/ 7851]
loss: 7.499966  [ 6162/ 7851]
loss: 6.041059  [ 6630/ 7851]
loss: 6.038531  [ 7098/ 7851]
loss: 6.407845  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 7.237781 
Epoch 9
-------------------------------
loss: 6.708514  [   79/ 7851]
loss: 7.963650  [  547/ 7851]
loss: 5.637374  [ 1015/ 7851]
loss: 7.431447  [ 1483/ 7851]
loss: 7.431735  [ 1951/ 7851]
loss: 6.263645  [ 2419/ 7851]
loss: 7.799123  [ 2887/ 7851]
loss: 5.143220  [ 3355/ 7851]
loss: 8.349907  [ 3823/ 7851]
loss: 6.702777  [ 4290/ 7851]
loss: 6.365354  [ 4758/ 7851]
loss: 3.889021  [ 5226/ 7851]
loss: 6.461288  [ 5694/ 7851]
loss: 7.437791  [ 6162/ 7851]
loss: 7.352664  [ 6630/ 7851]
loss: 6.460114  [ 7098/ 7851]
loss: 7.439973  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.0%, Avg loss: 32.264343 
Epoch 10
-------------------------------
loss: 29.796415  [   79/ 7851]
loss: 10.490325  [  547/ 7851]
loss: 5.103312  [ 1015/ 7851]
loss: 5.451931  [ 1483/ 7851]
loss: 5.304611  [ 1951/ 7851]
loss: 5.915373  [ 2419/ 7851]
loss: 7.421076  [ 2887/ 7851]
loss: 3.321733  [ 3355/ 7851]
loss: 8.776655  [ 3823/ 7851]
loss: 4.839488  [ 4290/ 7851]
loss: 6.165074  [ 4758/ 7851]
loss: 13.426560  [ 5226/ 7851]
loss: 5.371832  [ 5694/ 7851]
loss: 7.698460  [ 6162/ 7851]
loss: 17.322439  [ 6630/ 7851]
loss: 6.705851  [ 7098/ 7851]
loss: 6.798802  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 8.710900 
Epoch 11
-------------------------------
loss: 9.341352  [   79/ 7851]
loss: 8.488453  [  547/ 7851]
loss: 5.094751  [ 1015/ 7851]
loss: 7.592422  [ 1483/ 7851]
loss: 5.247615  [ 1951/ 7851]
loss: 6.052987  [ 2419/ 7851]
loss: 7.105728  [ 2887/ 7851]
loss: 3.887054  [ 3355/ 7851]
loss: 8.713962  [ 3823/ 7851]
loss: 5.877152  [ 4290/ 7851]
loss: 6.271100  [ 4758/ 7851]
loss: 4.648374  [ 5226/ 7851]
loss: 5.715272  [ 5694/ 7851]
loss: 7.079208  [ 6162/ 7851]
loss: 6.709040  [ 6630/ 7851]
loss: 6.629260  [ 7098/ 7851]
loss: 6.462491  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 7.105297 
Epoch 12
-------------------------------
loss: 7.226476  [   79/ 7851]
loss: 8.796054  [  547/ 7851]
loss: 4.139541  [ 1015/ 7851]
loss: 5.349296  [ 1483/ 7851]
loss: 6.155704  [ 1951/ 7851]
loss: 5.738911  [ 2419/ 7851]
loss: 5.784745  [ 2887/ 7851]
loss: 3.795515  [ 3355/ 7851]
loss: 10.480205  [ 3823/ 7851]
loss: 6.750370  [ 4290/ 7851]
loss: 6.614777  [ 4758/ 7851]
loss: 4.934764  [ 5226/ 7851]
loss: 5.924241  [ 5694/ 7851]
loss: 6.133219  [ 6162/ 7851]
loss: 6.488522  [ 6630/ 7851]
loss: 5.877903  [ 7098/ 7851]
loss: 6.942253  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 7.273560 
Epoch 13
-------------------------------
loss: 6.765031  [   79/ 7851]
loss: 8.979026  [  547/ 7851]
loss: 4.587543  [ 1015/ 7851]
loss: 5.544237  [ 1483/ 7851]
loss: 5.455101  [ 1951/ 7851]
loss: 5.310659  [ 2419/ 7851]
loss: 5.612933  [ 2887/ 7851]
loss: 3.545269  [ 3355/ 7851]
loss: 7.531611  [ 3823/ 7851]
loss: 7.282414  [ 4290/ 7851]
loss: 7.647437  [ 4758/ 7851]
loss: 4.086982  [ 5226/ 7851]
loss: 5.030064  [ 5694/ 7851]
loss: 6.312942  [ 6162/ 7851]
loss: 6.679103  [ 6630/ 7851]
loss: 6.561994  [ 7098/ 7851]
loss: 7.519104  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.9%, Avg loss: 6.939489 
Epoch 14
-------------------------------
loss: 6.623391  [   79/ 7851]
loss: 9.196628  [  547/ 7851]
loss: 5.617985  [ 1015/ 7851]
loss: 6.559860  [ 1483/ 7851]
loss: 5.135000  [ 1951/ 7851]
loss: 6.168105  [ 2419/ 7851]
loss: 6.459997  [ 2887/ 7851]
loss: 4.376470  [ 3355/ 7851]
loss: 7.582733  [ 3823/ 7851]
loss: 6.163992  [ 4290/ 7851]
loss: 6.712678  [ 4758/ 7851]
loss: 4.549032  [ 5226/ 7851]
loss: 5.590277  [ 5694/ 7851]
loss: 6.431905  [ 6162/ 7851]
loss: 7.285492  [ 6630/ 7851]
loss: 5.820875  [ 7098/ 7851]
loss: 7.372957  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 7.663556 
Epoch 15
-------------------------------
loss: 7.241257  [   79/ 7851]
loss: 9.223507  [  547/ 7851]
loss: 4.761543  [ 1015/ 7851]
loss: 20.057909  [ 1483/ 7851]
loss: 5.583774  [ 1951/ 7851]
loss: 6.763140  [ 2419/ 7851]
loss: 8.155613  [ 2887/ 7851]
loss: 5.124231  [ 3355/ 7851]
loss: 10.091305  [ 3823/ 7851]
loss: 6.208539  [ 4290/ 7851]
loss: 6.820428  [ 4758/ 7851]
loss: 4.008614  [ 5226/ 7851]
loss: 5.325037  [ 5694/ 7851]
loss: 6.626051  [ 6162/ 7851]
loss: 5.839592  [ 6630/ 7851]
loss: 6.207269  [ 7098/ 7851]
loss: 6.434080  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 7.274763 
Epoch 16
-------------------------------
loss: 6.459337  [   79/ 7851]
loss: 8.111079  [  547/ 7851]
loss: 4.951711  [ 1015/ 7851]
loss: 5.753443  [ 1483/ 7851]
loss: 5.664252  [ 1951/ 7851]
loss: 6.224650  [ 2419/ 7851]
loss: 6.075049  [ 2887/ 7851]
loss: 3.326741  [ 3355/ 7851]
loss: 8.306185  [ 3823/ 7851]
loss: 6.876067  [ 4290/ 7851]
loss: 5.866447  [ 4758/ 7851]
loss: 4.148929  [ 5226/ 7851]
loss: 5.939915  [ 5694/ 7851]
loss: 8.025946  [ 6162/ 7851]
loss: 6.687773  [ 6630/ 7851]
loss: 5.282617  [ 7098/ 7851]
loss: 7.653603  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.152986 
Epoch 17
-------------------------------
loss: 6.238926  [   79/ 7851]
loss: 8.139325  [  547/ 7851]
loss: 4.923520  [ 1015/ 7851]
loss: 5.766792  [ 1483/ 7851]
loss: 6.407793  [ 1951/ 7851]
loss: 5.957526  [ 2419/ 7851]
loss: 5.712811  [ 2887/ 7851]
loss: 2.925073  [ 3355/ 7851]
loss: 7.263148  [ 3823/ 7851]
loss: 5.323595  [ 4290/ 7851]
loss: 6.717299  [ 4758/ 7851]
loss: 4.279902  [ 5226/ 7851]
loss: 6.682184  [ 5694/ 7851]
loss: 6.586251  [ 6162/ 7851]
loss: 6.499358  [ 6630/ 7851]
loss: 5.974748  [ 7098/ 7851]
loss: 6.876435  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.099466 
Epoch 18
-------------------------------
loss: 5.835461  [   79/ 7851]
loss: 7.807780  [  547/ 7851]
loss: 4.658007  [ 1015/ 7851]
loss: 6.106089  [ 1483/ 7851]
loss: 5.797287  [ 1951/ 7851]
loss: 5.178317  [ 2419/ 7851]
loss: 6.797491  [ 2887/ 7851]
loss: 3.161739  [ 3355/ 7851]
loss: 7.444261  [ 3823/ 7851]
loss: 6.307622  [ 4290/ 7851]
loss: 6.405519  [ 4758/ 7851]
loss: 3.685416  [ 5226/ 7851]
loss: 5.754794  [ 5694/ 7851]
loss: 7.947528  [ 6162/ 7851]
loss: 5.761586  [ 6630/ 7851]
loss: 5.350264  [ 7098/ 7851]
loss: 5.569504  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 8.633672 
Epoch 19
-------------------------------
loss: 7.058010  [   79/ 7851]
loss: 158.636444  [  547/ 7851]
loss: 3.576407  [ 1015/ 7851]
loss: 6.622598  [ 1483/ 7851]
loss: 4.482163  [ 1951/ 7851]
loss: 6.516552  [ 2419/ 7851]
loss: 6.351359  [ 2887/ 7851]
loss: 5.226899  [ 3355/ 7851]
loss: 7.394945  [ 3823/ 7851]
loss: 4.963330  [ 4290/ 7851]
loss: 5.943021  [ 4758/ 7851]
loss: 4.366433  [ 5226/ 7851]
loss: 6.334514  [ 5694/ 7851]
loss: 7.224425  [ 6162/ 7851]
loss: 6.262281  [ 6630/ 7851]
loss: 6.424689  [ 7098/ 7851]
loss: 6.584629  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.568854 
Epoch 20
-------------------------------
loss: 6.728094  [   79/ 7851]
loss: 7.521508  [  547/ 7851]
loss: 4.828254  [ 1015/ 7851]
loss: 5.729179  [ 1483/ 7851]
loss: 7.713370  [ 1951/ 7851]
loss: 5.714091  [ 2419/ 7851]
loss: 6.295998  [ 2887/ 7851]
loss: 3.937914  [ 3355/ 7851]
loss: 7.595956  [ 3823/ 7851]
loss: 5.895820  [ 4290/ 7851]
loss: 6.845278  [ 4758/ 7851]
loss: 4.485054  [ 5226/ 7851]
loss: 5.137500  [ 5694/ 7851]
loss: 6.986082  [ 6162/ 7851]
loss: 5.640443  [ 6630/ 7851]
loss: 5.628692  [ 7098/ 7851]
loss: 5.963356  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.485969 
Epoch 21
-------------------------------
loss: 6.806596  [   79/ 7851]
loss: 8.524643  [  547/ 7851]
loss: 3.870079  [ 1015/ 7851]
loss: 5.976562  [ 1483/ 7851]
loss: 5.298450  [ 1951/ 7851]
loss: 6.389598  [ 2419/ 7851]
loss: 5.698204  [ 2887/ 7851]
loss: 3.847622  [ 3355/ 7851]
loss: 7.123649  [ 3823/ 7851]
loss: 6.107183  [ 4290/ 7851]
loss: 5.561064  [ 4758/ 7851]
loss: 4.043516  [ 5226/ 7851]
loss: 6.448500  [ 5694/ 7851]
loss: 7.645972  [ 6162/ 7851]
loss: 5.888948  [ 6630/ 7851]
loss: 6.384510  [ 7098/ 7851]
loss: 6.298678  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.2%, Avg loss: 7.180519 
Epoch 22
-------------------------------
loss: 6.142709  [   79/ 7851]
loss: 6.855161  [  547/ 7851]
loss: 4.306893  [ 1015/ 7851]
loss: 4.598746  [ 1483/ 7851]
loss: 5.634691  [ 1951/ 7851]
loss: 4.990869  [ 2419/ 7851]
loss: 6.911283  [ 2887/ 7851]
loss: 3.238826  [ 3355/ 7851]
loss: 8.572705  [ 3823/ 7851]
loss: 7.404609  [ 4290/ 7851]
loss: 6.285464  [ 4758/ 7851]
loss: 4.275319  [ 5226/ 7851]
loss: 7.361472  [ 5694/ 7851]
loss: 8.666409  [ 6162/ 7851]
loss: 5.223816  [ 6630/ 7851]
loss: 6.184964  [ 7098/ 7851]
loss: 7.287440  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 7.015407 
Epoch 23
-------------------------------
loss: 6.542043  [   79/ 7851]
loss: 29.339291  [  547/ 7851]
loss: 3.950802  [ 1015/ 7851]
loss: 6.337400  [ 1483/ 7851]
loss: 6.108912  [ 1951/ 7851]
loss: 5.798734  [ 2419/ 7851]
loss: 7.548170  [ 2887/ 7851]
loss: 4.034416  [ 3355/ 7851]
loss: 7.197875  [ 3823/ 7851]
loss: 4.983621  [ 4290/ 7851]
loss: 7.143919  [ 4758/ 7851]
loss: 4.075750  [ 5226/ 7851]
loss: 5.701835  [ 5694/ 7851]
loss: 6.696259  [ 6162/ 7851]
loss: 5.306087  [ 6630/ 7851]
loss: 6.319920  [ 7098/ 7851]
loss: 6.874092  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 6.462555 
Epoch 24
-------------------------------
loss: 6.404944  [   79/ 7851]
loss: 8.289530  [  547/ 7851]
loss: 4.959948  [ 1015/ 7851]
loss: 5.261633  [ 1483/ 7851]
loss: 6.101676  [ 1951/ 7851]
loss: 5.112859  [ 2419/ 7851]
loss: 8.229901  [ 2887/ 7851]
loss: 3.355009  [ 3355/ 7851]
loss: 8.581624  [ 3823/ 7851]
loss: 5.245777  [ 4290/ 7851]
loss: 6.891861  [ 4758/ 7851]
loss: 4.048062  [ 5226/ 7851]
loss: 5.044316  [ 5694/ 7851]
loss: 6.511854  [ 6162/ 7851]
loss: 6.084964  [ 6630/ 7851]
loss: 6.041144  [ 7098/ 7851]
loss: 7.513256  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.688809 
Epoch 25
-------------------------------
loss: 6.393590  [   79/ 7851]
loss: 7.519951  [  547/ 7851]
loss: 4.268345  [ 1015/ 7851]
loss: 4.805960  [ 1483/ 7851]
loss: 5.017271  [ 1951/ 7851]
loss: 5.247594  [ 2419/ 7851]
loss: 8.104942  [ 2887/ 7851]
loss: 3.969086  [ 3355/ 7851]
loss: 6.512570  [ 3823/ 7851]
loss: 6.629480  [ 4290/ 7851]
loss: 6.236139  [ 4758/ 7851]
loss: 4.416324  [ 5226/ 7851]
loss: 5.190482  [ 5694/ 7851]
loss: 6.587703  [ 6162/ 7851]
loss: 5.827322  [ 6630/ 7851]
loss: 6.764224  [ 7098/ 7851]
loss: 6.112131  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 8.013779 
Epoch 26
-------------------------------
loss: 7.266294  [   79/ 7851]
loss: 12.036348  [  547/ 7851]
loss: 4.394749  [ 1015/ 7851]
loss: 5.211542  [ 1483/ 7851]
loss: 5.689206  [ 1951/ 7851]
loss: 5.519437  [ 2419/ 7851]
loss: 6.115217  [ 2887/ 7851]
loss: 3.977354  [ 3355/ 7851]
loss: 7.948379  [ 3823/ 7851]
loss: 5.932845  [ 4290/ 7851]
loss: 7.012948  [ 4758/ 7851]
loss: 3.877178  [ 5226/ 7851]
loss: 5.789263  [ 5694/ 7851]
loss: 7.042583  [ 6162/ 7851]
loss: 6.451839  [ 6630/ 7851]
loss: 6.278905  [ 7098/ 7851]
loss: 6.476893  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.414234 
Epoch 27
-------------------------------
loss: 6.284321  [   79/ 7851]
loss: 8.083588  [  547/ 7851]
loss: 4.345298  [ 1015/ 7851]
loss: 5.517153  [ 1483/ 7851]
loss: 5.092075  [ 1951/ 7851]
loss: 5.222381  [ 2419/ 7851]
loss: 5.261902  [ 2887/ 7851]
loss: 3.727953  [ 3355/ 7851]
loss: 7.316241  [ 3823/ 7851]
loss: 5.758284  [ 4290/ 7851]
loss: 6.336527  [ 4758/ 7851]
loss: 3.782993  [ 5226/ 7851]
loss: 5.898523  [ 5694/ 7851]
loss: 7.461105  [ 6162/ 7851]
loss: 7.038342  [ 6630/ 7851]
loss: 6.250776  [ 7098/ 7851]
loss: 6.968390  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 7.159444 
Epoch 28
-------------------------------
loss: 6.387307  [   79/ 7851]
loss: 11.864400  [  547/ 7851]
loss: 3.819065  [ 1015/ 7851]
loss: 5.685347  [ 1483/ 7851]
loss: 4.747466  [ 1951/ 7851]
loss: 5.339053  [ 2419/ 7851]
loss: 6.951454  [ 2887/ 7851]
loss: 4.231916  [ 3355/ 7851]
loss: 8.073278  [ 3823/ 7851]
loss: 5.878415  [ 4290/ 7851]
loss: 6.599783  [ 4758/ 7851]
loss: 31.371294  [ 5226/ 7851]
loss: 4.863378  [ 5694/ 7851]
loss: 6.365182  [ 6162/ 7851]
loss: 5.814763  [ 6630/ 7851]
loss: 6.129455  [ 7098/ 7851]
loss: 6.129814  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.667062 
Epoch 29
-------------------------------
loss: 6.146196  [   79/ 7851]
loss: 8.019403  [  547/ 7851]
loss: 4.244322  [ 1015/ 7851]
loss: 9.161805  [ 1483/ 7851]
loss: 4.922146  [ 1951/ 7851]
loss: 5.858542  [ 2419/ 7851]
loss: 5.474941  [ 2887/ 7851]
loss: 3.599808  [ 3355/ 7851]
loss: 8.019707  [ 3823/ 7851]
loss: 6.543633  [ 4290/ 7851]
loss: 6.280176  [ 4758/ 7851]
loss: 4.297139  [ 5226/ 7851]
loss: 5.249953  [ 5694/ 7851]
loss: 7.219539  [ 6162/ 7851]
loss: 6.162725  [ 6630/ 7851]
loss: 5.908490  [ 7098/ 7851]
loss: 6.383645  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.7%, Avg loss: 6.745163 
Epoch 30
-------------------------------
loss: 6.701351  [   79/ 7851]
loss: 7.132825  [  547/ 7851]
loss: 4.176593  [ 1015/ 7851]
loss: 5.118852  [ 1483/ 7851]
loss: 5.424836  [ 1951/ 7851]
loss: 5.006041  [ 2419/ 7851]
loss: 6.131539  [ 2887/ 7851]
loss: 4.378680  [ 3355/ 7851]
loss: 6.870011  [ 3823/ 7851]
loss: 5.798969  [ 4290/ 7851]
loss: 5.842103  [ 4758/ 7851]
loss: 4.723084  [ 5226/ 7851]
loss: 6.282435  [ 5694/ 7851]
loss: 7.925356  [ 6162/ 7851]
loss: 18.543915  [ 6630/ 7851]
loss: 6.523314  [ 7098/ 7851]
loss: 6.467691  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 8.427559 
Epoch 31
-------------------------------
loss: 7.778805  [   79/ 7851]
loss: 12.395801  [  547/ 7851]
loss: 4.781767  [ 1015/ 7851]
loss: 4.970585  [ 1483/ 7851]
loss: 5.046541  [ 1951/ 7851]
loss: 6.245214  [ 2419/ 7851]
loss: 6.641792  [ 2887/ 7851]
loss: 4.841786  [ 3355/ 7851]
loss: 7.360137  [ 3823/ 7851]
loss: 6.796715  [ 4290/ 7851]
loss: 6.512035  [ 4758/ 7851]
loss: 4.200206  [ 5226/ 7851]
loss: 5.741065  [ 5694/ 7851]
loss: 6.308834  [ 6162/ 7851]
loss: 6.278370  [ 6630/ 7851]
loss: 7.245716  [ 7098/ 7851]
loss: 6.398832  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 6.941625 
Epoch 32
-------------------------------
loss: 7.159465  [   79/ 7851]
loss: 9.105234  [  547/ 7851]
loss: 4.773921  [ 1015/ 7851]
loss: 5.266245  [ 1483/ 7851]
loss: 5.030580  [ 1951/ 7851]
loss: 5.470225  [ 2419/ 7851]
loss: 4.380313  [ 2887/ 7851]
loss: 4.697845  [ 3355/ 7851]
loss: 7.593921  [ 3823/ 7851]
loss: 5.475601  [ 4290/ 7851]
loss: 6.746679  [ 4758/ 7851]
loss: 3.098228  [ 5226/ 7851]
loss: 5.171563  [ 5694/ 7851]
loss: 7.469521  [ 6162/ 7851]
loss: 6.209231  [ 6630/ 7851]
loss: 6.210332  [ 7098/ 7851]
loss: 6.549175  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.8%, Avg loss: 6.470591 
Epoch 33
-------------------------------
loss: 6.512518  [   79/ 7851]
loss: 9.071063  [  547/ 7851]
loss: 3.776958  [ 1015/ 7851]
loss: 5.817549  [ 1483/ 7851]
loss: 5.461697  [ 1951/ 7851]
loss: 5.299612  [ 2419/ 7851]
loss: 6.017644  [ 2887/ 7851]
loss: 4.545456  [ 3355/ 7851]
loss: 8.091367  [ 3823/ 7851]
loss: 5.291086  [ 4290/ 7851]
loss: 12.109887  [ 4758/ 7851]
loss: 5.558959  [ 5226/ 7851]
loss: 5.988691  [ 5694/ 7851]
loss: 7.085895  [ 6162/ 7851]
loss: 5.087186  [ 6630/ 7851]
loss: 5.491599  [ 7098/ 7851]
loss: 6.323628  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 7.220255 
Epoch 34
-------------------------------
loss: 7.124292  [   79/ 7851]
loss: 9.844347  [  547/ 7851]
loss: 4.129997  [ 1015/ 7851]
loss: 6.830356  [ 1483/ 7851]
loss: 6.867024  [ 1951/ 7851]
loss: 5.142715  [ 2419/ 7851]
loss: 7.158143  [ 2887/ 7851]
loss: 3.511326  [ 3355/ 7851]
loss: 8.288382  [ 3823/ 7851]
loss: 4.959169  [ 4290/ 7851]
loss: 6.758436  [ 4758/ 7851]
loss: 3.247962  [ 5226/ 7851]
loss: 4.569643  [ 5694/ 7851]
loss: 7.011909  [ 6162/ 7851]
loss: 5.895055  [ 6630/ 7851]
loss: 5.747002  [ 7098/ 7851]
loss: 7.943684  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 6.587133 
Epoch 35
-------------------------------
loss: 6.863607  [   79/ 7851]
loss: 7.514251  [  547/ 7851]
loss: 4.172710  [ 1015/ 7851]
loss: 4.950676  [ 1483/ 7851]
loss: 4.263690  [ 1951/ 7851]
loss: 5.119548  [ 2419/ 7851]
loss: 5.970903  [ 2887/ 7851]
loss: 3.620781  [ 3355/ 7851]
loss: 7.206686  [ 3823/ 7851]
loss: 5.078762  [ 4290/ 7851]
loss: 6.848629  [ 4758/ 7851]
loss: 4.584678  [ 5226/ 7851]
loss: 5.466498  [ 5694/ 7851]
loss: 6.548898  [ 6162/ 7851]
loss: 6.388742  [ 6630/ 7851]
loss: 6.346235  [ 7098/ 7851]
loss: 6.716396  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 6.364146 
Epoch 36
-------------------------------
loss: 6.389642  [   79/ 7851]
loss: 9.045722  [  547/ 7851]
loss: 4.071244  [ 1015/ 7851]
loss: 5.837186  [ 1483/ 7851]
loss: 5.478549  [ 1951/ 7851]
loss: 5.249748  [ 2419/ 7851]
loss: 6.352642  [ 2887/ 7851]
loss: 3.941862  [ 3355/ 7851]
loss: 7.618273  [ 3823/ 7851]
loss: 5.673758  [ 4290/ 7851]
loss: 7.752900  [ 4758/ 7851]
loss: 5.502744  [ 5226/ 7851]
loss: 4.899890  [ 5694/ 7851]
loss: 6.941890  [ 6162/ 7851]
loss: 6.121061  [ 6630/ 7851]
loss: 6.282471  [ 7098/ 7851]
loss: 6.977425  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 6.225198 
Epoch 37
-------------------------------
loss: 5.707575  [   79/ 7851]
loss: 8.367790  [  547/ 7851]
loss: 4.791049  [ 1015/ 7851]
loss: 6.416558  [ 1483/ 7851]
loss: 5.041882  [ 1951/ 7851]
loss: 5.384003  [ 2419/ 7851]
loss: 5.617130  [ 2887/ 7851]
loss: 3.512902  [ 3355/ 7851]
loss: 6.753559  [ 3823/ 7851]
loss: 4.787546  [ 4290/ 7851]
loss: 5.410837  [ 4758/ 7851]
loss: 4.460729  [ 5226/ 7851]
loss: 5.675839  [ 5694/ 7851]
loss: 6.688587  [ 6162/ 7851]
loss: 4.817301  [ 6630/ 7851]
loss: 6.726295  [ 7098/ 7851]
loss: 6.584941  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 7.342981 
Epoch 38
-------------------------------
loss: 6.727895  [   79/ 7851]
loss: 7.902320  [  547/ 7851]
loss: 4.961273  [ 1015/ 7851]
loss: 5.470642  [ 1483/ 7851]
loss: 4.482158  [ 1951/ 7851]
loss: 5.435937  [ 2419/ 7851]
loss: 6.953872  [ 2887/ 7851]
loss: 4.157239  [ 3355/ 7851]
loss: 7.018806  [ 3823/ 7851]
loss: 4.931945  [ 4290/ 7851]
loss: 5.570122  [ 4758/ 7851]
loss: 3.289255  [ 5226/ 7851]
loss: 4.941679  [ 5694/ 7851]
loss: 5.980195  [ 6162/ 7851]
loss: 5.356681  [ 6630/ 7851]
loss: 6.124077  [ 7098/ 7851]
loss: 6.727079  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.7%, Avg loss: 6.871573 
Epoch 39
-------------------------------
loss: 7.405557  [   79/ 7851]
loss: 10.386094  [  547/ 7851]
loss: 4.123827  [ 1015/ 7851]
loss: 5.860999  [ 1483/ 7851]
loss: 4.834770  [ 1951/ 7851]
loss: 6.292822  [ 2419/ 7851]
loss: 8.635670  [ 2887/ 7851]
loss: 4.243246  [ 3355/ 7851]
loss: 6.014616  [ 3823/ 7851]
loss: 5.546063  [ 4290/ 7851]
loss: 6.990284  [ 4758/ 7851]
loss: 6.343272  [ 5226/ 7851]
loss: 6.111360  [ 5694/ 7851]
loss: 6.281554  [ 6162/ 7851]
loss: 5.834369  [ 6630/ 7851]
loss: 6.266279  [ 7098/ 7851]
loss: 7.164873  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.801139 
Epoch 40
-------------------------------
loss: 7.100911  [   79/ 7851]
loss: 7.745078  [  547/ 7851]
loss: 4.840761  [ 1015/ 7851]
loss: 6.110345  [ 1483/ 7851]
loss: 6.662730  [ 1951/ 7851]
loss: 5.813282  [ 2419/ 7851]
loss: 6.093352  [ 2887/ 7851]
loss: 3.933519  [ 3355/ 7851]
loss: 7.670519  [ 3823/ 7851]
loss: 7.377219  [ 4290/ 7851]
loss: 7.138908  [ 4758/ 7851]
loss: 4.155351  [ 5226/ 7851]
loss: 5.218024  [ 5694/ 7851]
loss: 6.506364  [ 6162/ 7851]
loss: 6.970817  [ 6630/ 7851]
loss: 7.095833  [ 7098/ 7851]
loss: 7.368935  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 6.410594 
Epoch 41
-------------------------------
loss: 6.922860  [   79/ 7851]
loss: 8.219237  [  547/ 7851]
loss: 5.284502  [ 1015/ 7851]
loss: 5.659662  [ 1483/ 7851]
loss: 4.494844  [ 1951/ 7851]
loss: 6.199705  [ 2419/ 7851]
loss: 6.381006  [ 2887/ 7851]
loss: 3.339030  [ 3355/ 7851]
loss: 7.326009  [ 3823/ 7851]
loss: 6.602991  [ 4290/ 7851]
loss: 6.898965  [ 4758/ 7851]
loss: 3.944807  [ 5226/ 7851]
loss: 4.905128  [ 5694/ 7851]
loss: 7.174587  [ 6162/ 7851]
loss: 7.044840  [ 6630/ 7851]
loss: 5.751105  [ 7098/ 7851]
loss: 6.750288  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.075156 
Epoch 42
-------------------------------
loss: 6.761186  [   79/ 7851]
loss: 8.499187  [  547/ 7851]
loss: 5.129865  [ 1015/ 7851]
loss: 7.327631  [ 1483/ 7851]
loss: 4.766172  [ 1951/ 7851]
loss: 5.783433  [ 2419/ 7851]
loss: 5.606204  [ 2887/ 7851]
loss: 4.099236  [ 3355/ 7851]
loss: 8.338235  [ 3823/ 7851]
loss: 5.577663  [ 4290/ 7851]
loss: 7.066422  [ 4758/ 7851]
loss: 3.342151  [ 5226/ 7851]
loss: 5.527135  [ 5694/ 7851]
loss: 7.225968  [ 6162/ 7851]
loss: 6.079546  [ 6630/ 7851]
loss: 6.586553  [ 7098/ 7851]
loss: 7.575777  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.9%, Avg loss: 6.637536 
Epoch 43
-------------------------------
loss: 6.624028  [   79/ 7851]
loss: 7.861443  [  547/ 7851]
loss: 4.226721  [ 1015/ 7851]
loss: 5.339636  [ 1483/ 7851]
loss: 5.523337  [ 1951/ 7851]
loss: 5.583782  [ 2419/ 7851]
loss: 6.243097  [ 2887/ 7851]
loss: 3.253725  [ 3355/ 7851]
loss: 8.154591  [ 3823/ 7851]
loss: 5.402054  [ 4290/ 7851]
loss: 5.995571  [ 4758/ 7851]
loss: 4.149592  [ 5226/ 7851]
loss: 6.285526  [ 5694/ 7851]
loss: 7.129770  [ 6162/ 7851]
loss: 6.387815  [ 6630/ 7851]
loss: 6.022271  [ 7098/ 7851]
loss: 6.677119  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.594807 
Epoch 44
-------------------------------
loss: 6.257996  [   79/ 7851]
loss: 8.121368  [  547/ 7851]
loss: 4.648544  [ 1015/ 7851]
loss: 5.383335  [ 1483/ 7851]
loss: 4.964291  [ 1951/ 7851]
loss: 6.879244  [ 2419/ 7851]
loss: 6.624599  [ 2887/ 7851]
loss: 4.128062  [ 3355/ 7851]
loss: 8.508767  [ 3823/ 7851]
loss: 7.019570  [ 4290/ 7851]
loss: 6.873357  [ 4758/ 7851]
loss: 4.088345  [ 5226/ 7851]
loss: 6.036551  [ 5694/ 7851]
loss: 6.021429  [ 6162/ 7851]
loss: 5.999648  [ 6630/ 7851]
loss: 6.690210  [ 7098/ 7851]
loss: 6.649140  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 6.237533 
Epoch 45
-------------------------------
loss: 6.277288  [   79/ 7851]
loss: 7.355977  [  547/ 7851]
loss: 6.073518  [ 1015/ 7851]
loss: 4.889847  [ 1483/ 7851]
loss: 4.748897  [ 1951/ 7851]
loss: 4.584754  [ 2419/ 7851]
loss: 5.848203  [ 2887/ 7851]
loss: 3.769181  [ 3355/ 7851]
loss: 7.927103  [ 3823/ 7851]
loss: 5.640155  [ 4290/ 7851]
loss: 5.844939  [ 4758/ 7851]
loss: 4.786873  [ 5226/ 7851]
loss: 5.593837  [ 5694/ 7851]
loss: 6.913261  [ 6162/ 7851]
loss: 6.588819  [ 6630/ 7851]
loss: 5.834499  [ 7098/ 7851]
loss: 7.084381  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 6.630604 
Epoch 46
-------------------------------
loss: 6.254810  [   79/ 7851]
loss: 8.337420  [  547/ 7851]
loss: 3.764218  [ 1015/ 7851]
loss: 4.139676  [ 1483/ 7851]
loss: 5.631997  [ 1951/ 7851]
loss: 6.013756  [ 2419/ 7851]
loss: 5.393517  [ 2887/ 7851]
loss: 4.098047  [ 3355/ 7851]
loss: 8.384715  [ 3823/ 7851]
loss: 6.107680  [ 4290/ 7851]
loss: 5.966663  [ 4758/ 7851]
loss: 4.587436  [ 5226/ 7851]
loss: 5.105247  [ 5694/ 7851]
loss: 7.901726  [ 6162/ 7851]
loss: 5.945695  [ 6630/ 7851]
loss: 6.535914  [ 7098/ 7851]
loss: 6.067131  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 6.947954 
Epoch 47
-------------------------------
loss: 6.276675  [   79/ 7851]
loss: 7.828660  [  547/ 7851]
loss: 6.140848  [ 1015/ 7851]
loss: 6.486114  [ 1483/ 7851]
loss: 4.848879  [ 1951/ 7851]
loss: 5.300727  [ 2419/ 7851]
loss: 4.832016  [ 2887/ 7851]
loss: 3.577883  [ 3355/ 7851]
loss: 8.719947  [ 3823/ 7851]
loss: 5.714499  [ 4290/ 7851]
loss: 7.028300  [ 4758/ 7851]
loss: 3.165236  [ 5226/ 7851]
loss: 4.177636  [ 5694/ 7851]
loss: 7.261068  [ 6162/ 7851]
loss: 5.398099  [ 6630/ 7851]
loss: 6.267340  [ 7098/ 7851]
loss: 6.185362  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.3%, Avg loss: 6.942985 
Epoch 48
-------------------------------
loss: 6.220908  [   79/ 7851]
loss: 10.689201  [  547/ 7851]
loss: 4.229561  [ 1015/ 7851]
loss: 4.574617  [ 1483/ 7851]
loss: 5.594919  [ 1951/ 7851]
loss: 5.179007  [ 2419/ 7851]
loss: 7.329009  [ 2887/ 7851]
loss: 2.981376  [ 3355/ 7851]
loss: 6.726063  [ 3823/ 7851]
loss: 5.371406  [ 4290/ 7851]
loss: 5.812630  [ 4758/ 7851]
loss: 36.892235  [ 5226/ 7851]
loss: 4.592206  [ 5694/ 7851]
loss: 5.793557  [ 6162/ 7851]
loss: 6.143189  [ 6630/ 7851]
loss: 7.038740  [ 7098/ 7851]
loss: 6.621148  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.391306 
Epoch 49
-------------------------------
loss: 8.075234  [   79/ 7851]
loss: 7.897599  [  547/ 7851]
loss: 4.385355  [ 1015/ 7851]
loss: 5.520265  [ 1483/ 7851]
loss: 5.414507  [ 1951/ 7851]
loss: 5.058681  [ 2419/ 7851]
loss: 6.665764  [ 2887/ 7851]
loss: 3.733715  [ 3355/ 7851]
loss: 8.513806  [ 3823/ 7851]
loss: 6.053305  [ 4290/ 7851]
loss: 6.964004  [ 4758/ 7851]
loss: 4.300718  [ 5226/ 7851]
loss: 4.753019  [ 5694/ 7851]
loss: 6.628208  [ 6162/ 7851]
loss: 7.081885  [ 6630/ 7851]
loss: 5.760730  [ 7098/ 7851]
loss: 6.453157  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.573591 
Epoch 50
-------------------------------
loss: 6.396433  [   79/ 7851]
loss: 8.603586  [  547/ 7851]
loss: 5.757882  [ 1015/ 7851]
loss: 5.493721  [ 1483/ 7851]
loss: 5.712245  [ 1951/ 7851]
loss: 5.228330  [ 2419/ 7851]
loss: 5.843832  [ 2887/ 7851]
loss: 3.606127  [ 3355/ 7851]
loss: 6.831702  [ 3823/ 7851]
loss: 4.962258  [ 4290/ 7851]
loss: 7.086845  [ 4758/ 7851]
loss: 4.066154  [ 5226/ 7851]
loss: 4.965494  [ 5694/ 7851]
loss: 5.941967  [ 6162/ 7851]
loss: 4.808928  [ 6630/ 7851]
loss: 5.906995  [ 7098/ 7851]
loss: 7.165698  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.410136 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 8000]               648,000
│    └─ELU: 2-2                          [100, 8000]               --
│    └─Linear: 2-3                       [100, 80]                 640,080
==========================================================================================
Total params: 1,288,080
Trainable params: 1,288,080
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 128.81
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 6.46
Params size (MB): 5.15
Estimated Total Size (MB): 11.65
==========================================================================================
Epoch 1
-------------------------------
loss: 12.459057  [   79/ 7851]
loss: 118757.257812  [  547/ 7851]
loss: 54390.371094  [ 1015/ 7851]
loss: 12737.096680  [ 1483/ 7851]
loss: 2112.201172  [ 1951/ 7851]
loss: 2817.127930  [ 2419/ 7851]
loss: 1572.465210  [ 2887/ 7851]
loss: 1109.413818  [ 3355/ 7851]
loss: 1441.595581  [ 3823/ 7851]
loss: 667.007507  [ 4290/ 7851]
loss: 528.115295  [ 4758/ 7851]
loss: 497.755371  [ 5226/ 7851]
loss: 583.151611  [ 5694/ 7851]
loss: 284.003387  [ 6162/ 7851]
loss: 249.959137  [ 6630/ 7851]
loss: 228.111465  [ 7098/ 7851]
loss: 307.965271  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 174.245737 
Epoch 2
-------------------------------
loss: 172.862381  [   79/ 7851]
loss: 427.129578  [  547/ 7851]
loss: 342.454590  [ 1015/ 7851]
loss: 222.459793  [ 1483/ 7851]
loss: 219.001587  [ 1951/ 7851]
loss: 370.881104  [ 2419/ 7851]
loss: 240.126953  [ 2887/ 7851]
loss: 238.261169  [ 3355/ 7851]
loss: 139.449097  [ 3823/ 7851]
loss: 176.919998  [ 4290/ 7851]
loss: 150.090775  [ 4758/ 7851]
loss: 167.474380  [ 5226/ 7851]
loss: 182.036133  [ 5694/ 7851]
loss: 187.272308  [ 6162/ 7851]
loss: 118.050003  [ 6630/ 7851]
loss: 170.026520  [ 7098/ 7851]
loss: 497.700409  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.6%, Avg loss: 833.119312 
Epoch 3
-------------------------------
loss: 825.670898  [   79/ 7851]
loss: 1936.268311  [  547/ 7851]
loss: 483.353149  [ 1015/ 7851]
loss: 551.201660  [ 1483/ 7851]
loss: 375.873535  [ 1951/ 7851]
loss: 328.479309  [ 2419/ 7851]
loss: 501.145020  [ 2887/ 7851]
loss: 345.774414  [ 3355/ 7851]
loss: 270.244659  [ 3823/ 7851]
loss: 310.457214  [ 4290/ 7851]
loss: 490.220642  [ 4758/ 7851]
loss: 187.750443  [ 5226/ 7851]
loss: 247.282028  [ 5694/ 7851]
loss: 229.571213  [ 6162/ 7851]
loss: 247.219452  [ 6630/ 7851]
loss: 214.071518  [ 7098/ 7851]
loss: 175.054565  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 410.474347 
Epoch 4
-------------------------------
loss: 406.978546  [   79/ 7851]
loss: 347.672516  [  547/ 7851]
loss: 196.536072  [ 1015/ 7851]
loss: 287.341461  [ 1483/ 7851]
loss: 227.342560  [ 1951/ 7851]
loss: 417.758789  [ 2419/ 7851]
loss: 375.150726  [ 2887/ 7851]
loss: 472.881409  [ 3355/ 7851]
loss: 313.582886  [ 3823/ 7851]
loss: 266.601074  [ 4290/ 7851]
loss: 439.268433  [ 4758/ 7851]
loss: 409.329285  [ 5226/ 7851]
loss: 317.584137  [ 5694/ 7851]
loss: 177.798355  [ 6162/ 7851]
loss: 213.185013  [ 6630/ 7851]
loss: 383.439972  [ 7098/ 7851]
loss: 391.229553  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 272.967859 
Epoch 5
-------------------------------
loss: 271.123230  [   79/ 7851]
loss: 191.938126  [  547/ 7851]
loss: 269.639832  [ 1015/ 7851]
loss: 185.921432  [ 1483/ 7851]
loss: 259.678436  [ 1951/ 7851]
loss: 653.700562  [ 2419/ 7851]
loss: 1145.374878  [ 2887/ 7851]
loss: 1337.426270  [ 3355/ 7851]
loss: 1179.648682  [ 3823/ 7851]
loss: 1145.647949  [ 4290/ 7851]
loss: 556.880554  [ 4758/ 7851]
loss: 313.306305  [ 5226/ 7851]
loss: 840.485413  [ 5694/ 7851]
loss: 492.407928  [ 6162/ 7851]
loss: 400.263214  [ 6630/ 7851]
loss: 214.636322  [ 7098/ 7851]
loss: 201.499023  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 323.442120 
Epoch 6
-------------------------------
loss: 319.004517  [   79/ 7851]
loss: 164.067429  [  547/ 7851]
loss: 327.563049  [ 1015/ 7851]
loss: 262.687805  [ 1483/ 7851]
loss: 412.577423  [ 1951/ 7851]
loss: 461.903473  [ 2419/ 7851]
loss: 251.573196  [ 2887/ 7851]
loss: 371.822906  [ 3355/ 7851]
loss: 530.366089  [ 3823/ 7851]
loss: 609.894287  [ 4290/ 7851]
loss: 567.068542  [ 4758/ 7851]
loss: 261.732605  [ 5226/ 7851]
loss: 187.593155  [ 5694/ 7851]
loss: 384.593658  [ 6162/ 7851]
loss: 326.718353  [ 6630/ 7851]
loss: 152.067795  [ 7098/ 7851]
loss: 269.275848  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 312.049200 
Epoch 7
-------------------------------
loss: 307.945374  [   79/ 7851]
loss: 356.275208  [  547/ 7851]
loss: 171.645096  [ 1015/ 7851]
loss: 151.698898  [ 1483/ 7851]
loss: 261.565002  [ 1951/ 7851]
loss: 265.436005  [ 2419/ 7851]
loss: 157.042831  [ 2887/ 7851]
loss: 118.443504  [ 3355/ 7851]
loss: 189.239105  [ 3823/ 7851]
loss: 510.954315  [ 4290/ 7851]
loss: 932.710083  [ 4758/ 7851]
loss: 306.065430  [ 5226/ 7851]
loss: 521.215454  [ 5694/ 7851]
loss: 364.391815  [ 6162/ 7851]
loss: 760.032837  [ 6630/ 7851]
loss: 264.531647  [ 7098/ 7851]
loss: 207.133148  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 227.016037 
Epoch 8
-------------------------------
loss: 223.431412  [   79/ 7851]
loss: 195.834381  [  547/ 7851]
loss: 457.008240  [ 1015/ 7851]
loss: 255.907700  [ 1483/ 7851]
loss: 260.952606  [ 1951/ 7851]
loss: 316.095612  [ 2419/ 7851]
loss: 148.886337  [ 2887/ 7851]
loss: 148.123611  [ 3355/ 7851]
loss: 199.503067  [ 3823/ 7851]
loss: 455.564056  [ 4290/ 7851]
loss: 416.626282  [ 4758/ 7851]
loss: 751.169495  [ 5226/ 7851]
loss: 657.222778  [ 5694/ 7851]
loss: 282.891632  [ 6162/ 7851]
loss: 492.436249  [ 6630/ 7851]
loss: 217.771133  [ 7098/ 7851]
loss: 640.877869  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 307.944238 
Epoch 9
-------------------------------
loss: 303.711853  [   79/ 7851]
loss: 559.810303  [  547/ 7851]
loss: 416.315216  [ 1015/ 7851]
loss: 235.845505  [ 1483/ 7851]
loss: 475.248413  [ 1951/ 7851]
loss: 203.354233  [ 2419/ 7851]
loss: 331.878296  [ 2887/ 7851]
loss: 223.832855  [ 3355/ 7851]
loss: 328.859192  [ 3823/ 7851]
loss: 279.749329  [ 4290/ 7851]
loss: 269.345367  [ 4758/ 7851]
loss: 216.918304  [ 5226/ 7851]
loss: 267.968414  [ 5694/ 7851]
loss: 309.847351  [ 6162/ 7851]
loss: 208.020477  [ 6630/ 7851]
loss: 409.516998  [ 7098/ 7851]
loss: 360.706329  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 549.849536 
Epoch 10
-------------------------------
loss: 544.028748  [   79/ 7851]
loss: 755.866638  [  547/ 7851]
loss: 215.572159  [ 1015/ 7851]
loss: 464.325714  [ 1483/ 7851]
loss: 238.940018  [ 1951/ 7851]
loss: 520.563904  [ 2419/ 7851]
loss: 631.955688  [ 2887/ 7851]
loss: 357.118500  [ 3355/ 7851]
loss: 377.183807  [ 3823/ 7851]
loss: 358.488464  [ 4290/ 7851]
loss: 463.935822  [ 4758/ 7851]
loss: 243.113342  [ 5226/ 7851]
loss: 445.469910  [ 5694/ 7851]
loss: 420.194763  [ 6162/ 7851]
loss: 344.736328  [ 6630/ 7851]
loss: 213.508453  [ 7098/ 7851]
loss: 316.763611  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.5%, Avg loss: 156.456821 
Epoch 11
-------------------------------
loss: 150.134125  [   79/ 7851]
loss: 140.785614  [  547/ 7851]
loss: 172.430420  [ 1015/ 7851]
loss: 303.756592  [ 1483/ 7851]
loss: 205.814056  [ 1951/ 7851]
loss: 237.336670  [ 2419/ 7851]
loss: 102.774727  [ 2887/ 7851]
loss: 143.998169  [ 3355/ 7851]
loss: 240.745255  [ 3823/ 7851]
loss: 159.083405  [ 4290/ 7851]
loss: 185.261597  [ 4758/ 7851]
loss: 148.647339  [ 5226/ 7851]
loss: 118.636856  [ 5694/ 7851]
loss: 160.286713  [ 6162/ 7851]
loss: 617.108643  [ 6630/ 7851]
loss: 591.799377  [ 7098/ 7851]
loss: 540.774780  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 685.234131 
Epoch 12
-------------------------------
loss: 678.301453  [   79/ 7851]
loss: 567.676514  [  547/ 7851]
loss: 861.001526  [ 1015/ 7851]
loss: 1187.519287  [ 1483/ 7851]
loss: 725.109009  [ 1951/ 7851]
loss: 474.258392  [ 2419/ 7851]
loss: 560.136047  [ 2887/ 7851]
loss: 645.021973  [ 3355/ 7851]
loss: 276.084290  [ 3823/ 7851]
loss: 427.579102  [ 4290/ 7851]
loss: 283.712952  [ 4758/ 7851]
loss: 268.650330  [ 5226/ 7851]
loss: 190.999557  [ 5694/ 7851]
loss: 252.844635  [ 6162/ 7851]
loss: 270.365601  [ 6630/ 7851]
loss: 369.630768  [ 7098/ 7851]
loss: 162.568604  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 180.378638 
Epoch 13
-------------------------------
loss: 177.543533  [   79/ 7851]
loss: 124.397270  [  547/ 7851]
loss: 224.653732  [ 1015/ 7851]
loss: 288.077026  [ 1483/ 7851]
loss: 358.855225  [ 1951/ 7851]
loss: 235.959885  [ 2419/ 7851]
loss: 304.749573  [ 2887/ 7851]
loss: 175.513229  [ 3355/ 7851]
loss: 191.121185  [ 3823/ 7851]
loss: 264.918182  [ 4290/ 7851]
loss: 237.335022  [ 4758/ 7851]
loss: 252.934433  [ 5226/ 7851]
loss: 336.462616  [ 5694/ 7851]
loss: 202.284500  [ 6162/ 7851]
loss: 193.427963  [ 6630/ 7851]
loss: 97.412025  [ 7098/ 7851]
loss: 136.838135  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 230.785742 
Epoch 14
-------------------------------
loss: 226.526306  [   79/ 7851]
loss: 300.370026  [  547/ 7851]
loss: 115.965370  [ 1015/ 7851]
loss: 190.371445  [ 1483/ 7851]
loss: 244.134705  [ 1951/ 7851]
loss: 198.165939  [ 2419/ 7851]
loss: 238.346268  [ 2887/ 7851]
loss: 265.819885  [ 3355/ 7851]
loss: 234.473892  [ 3823/ 7851]
loss: 287.324707  [ 4290/ 7851]
loss: 154.783707  [ 4758/ 7851]
loss: 135.554825  [ 5226/ 7851]
loss: 90.872269  [ 5694/ 7851]
loss: 187.140289  [ 6162/ 7851]
loss: 361.161377  [ 6630/ 7851]
loss: 181.274887  [ 7098/ 7851]
loss: 177.909180  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 186.948532 
Epoch 15
-------------------------------
loss: 183.671600  [   79/ 7851]
loss: 237.278625  [  547/ 7851]
loss: 150.927795  [ 1015/ 7851]
loss: 241.212448  [ 1483/ 7851]
loss: 230.071167  [ 1951/ 7851]
loss: 345.658508  [ 2419/ 7851]
loss: 411.246155  [ 2887/ 7851]
loss: 529.414062  [ 3355/ 7851]
loss: 424.842377  [ 3823/ 7851]
loss: 255.083817  [ 4290/ 7851]
loss: 475.190155  [ 4758/ 7851]
loss: 415.262451  [ 5226/ 7851]
loss: 495.441193  [ 5694/ 7851]
loss: 137.261124  [ 6162/ 7851]
loss: 296.817322  [ 6630/ 7851]
loss: 228.711243  [ 7098/ 7851]
loss: 143.814835  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 102.711209 
Epoch 16
-------------------------------
loss: 98.863220  [   79/ 7851]
loss: 154.400864  [  547/ 7851]
loss: 425.530579  [ 1015/ 7851]
loss: 190.266342  [ 1483/ 7851]
loss: 155.499420  [ 1951/ 7851]
loss: 150.257355  [ 2419/ 7851]
loss: 139.742920  [ 2887/ 7851]
loss: 81.876770  [ 3355/ 7851]
loss: 112.580460  [ 3823/ 7851]
loss: 457.473145  [ 4290/ 7851]
loss: 442.638062  [ 4758/ 7851]
loss: 407.550842  [ 5226/ 7851]
loss: 178.134598  [ 5694/ 7851]
loss: 316.085754  [ 6162/ 7851]
loss: 328.947906  [ 6630/ 7851]
loss: 294.243195  [ 7098/ 7851]
loss: 483.176605  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 766.763904 
Epoch 17
-------------------------------
loss: 761.803101  [   79/ 7851]
loss: 612.746521  [  547/ 7851]
loss: 580.717773  [ 1015/ 7851]
loss: 896.367981  [ 1483/ 7851]
loss: 520.653381  [ 1951/ 7851]
loss: 456.604431  [ 2419/ 7851]
loss: 686.489502  [ 2887/ 7851]
loss: 376.058990  [ 3355/ 7851]
loss: 453.568512  [ 3823/ 7851]
loss: 196.276642  [ 4290/ 7851]
loss: 190.551117  [ 4758/ 7851]
loss: 228.411362  [ 5226/ 7851]
loss: 180.112442  [ 5694/ 7851]
loss: 399.645508  [ 6162/ 7851]
loss: 267.126373  [ 6630/ 7851]
loss: 214.823532  [ 7098/ 7851]
loss: 176.910599  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 245.948184 
Epoch 18
-------------------------------
loss: 245.758133  [   79/ 7851]
loss: 195.211395  [  547/ 7851]
loss: 398.458771  [ 1015/ 7851]
loss: 287.673584  [ 1483/ 7851]
loss: 301.343201  [ 1951/ 7851]
loss: 316.028229  [ 2419/ 7851]
loss: 184.338333  [ 2887/ 7851]
loss: 104.944176  [ 3355/ 7851]
loss: 135.510193  [ 3823/ 7851]
loss: 243.469208  [ 4290/ 7851]
loss: 247.759338  [ 4758/ 7851]
loss: 215.793396  [ 5226/ 7851]
loss: 515.003540  [ 5694/ 7851]
loss: 675.581665  [ 6162/ 7851]
loss: 231.419067  [ 6630/ 7851]
loss: 468.716797  [ 7098/ 7851]
loss: 458.056000  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 418.368311 
Epoch 19
-------------------------------
loss: 415.106995  [   79/ 7851]
loss: 257.127716  [  547/ 7851]
loss: 136.149750  [ 1015/ 7851]
loss: 99.298668  [ 1483/ 7851]
loss: 113.977272  [ 1951/ 7851]
loss: 196.304016  [ 2419/ 7851]
loss: 440.715820  [ 2887/ 7851]
loss: 243.431274  [ 3355/ 7851]
loss: 167.543076  [ 3823/ 7851]
loss: 600.810486  [ 4290/ 7851]
loss: 503.342102  [ 4758/ 7851]
loss: 718.783508  [ 5226/ 7851]
loss: 258.472504  [ 5694/ 7851]
loss: 337.865387  [ 6162/ 7851]
loss: 471.860413  [ 6630/ 7851]
loss: 315.234772  [ 7098/ 7851]
loss: 195.678879  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 173.574802 
Epoch 20
-------------------------------
loss: 174.188095  [   79/ 7851]
loss: 178.040665  [  547/ 7851]
loss: 218.154846  [ 1015/ 7851]
loss: 183.159363  [ 1483/ 7851]
loss: 452.229431  [ 1951/ 7851]
loss: 1356.935425  [ 2419/ 7851]
loss: 563.209106  [ 2887/ 7851]
loss: 684.740845  [ 3355/ 7851]
loss: 294.727997  [ 3823/ 7851]
loss: 360.532959  [ 4290/ 7851]
loss: 516.571716  [ 4758/ 7851]
loss: 510.534668  [ 5226/ 7851]
loss: 280.498444  [ 5694/ 7851]
loss: 168.002243  [ 6162/ 7851]
loss: 239.719208  [ 6630/ 7851]
loss: 156.428146  [ 7098/ 7851]
loss: 318.216797  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 150.600940 
Epoch 21
-------------------------------
loss: 149.336060  [   79/ 7851]
loss: 241.783737  [  547/ 7851]
loss: 229.276581  [ 1015/ 7851]
loss: 276.586823  [ 1483/ 7851]
loss: 973.330200  [ 1951/ 7851]
loss: 1123.518066  [ 2419/ 7851]
loss: 569.964417  [ 2887/ 7851]
loss: 906.859192  [ 3355/ 7851]
loss: 868.645752  [ 3823/ 7851]
loss: 388.066559  [ 4290/ 7851]
loss: 506.980682  [ 4758/ 7851]
loss: 631.361755  [ 5226/ 7851]
loss: 273.076477  [ 5694/ 7851]
loss: 606.872742  [ 6162/ 7851]
loss: 315.679413  [ 6630/ 7851]
loss: 292.646271  [ 7098/ 7851]
loss: 239.620529  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 355.862006 
Epoch 22
-------------------------------
loss: 353.371643  [   79/ 7851]
loss: 239.933365  [  547/ 7851]
loss: 308.445221  [ 1015/ 7851]
loss: 239.382187  [ 1483/ 7851]
loss: 341.163605  [ 1951/ 7851]
loss: 171.745514  [ 2419/ 7851]
loss: 231.293625  [ 2887/ 7851]
loss: 159.742294  [ 3355/ 7851]
loss: 224.866455  [ 3823/ 7851]
loss: 370.243347  [ 4290/ 7851]
loss: 191.558594  [ 4758/ 7851]
loss: 199.965302  [ 5226/ 7851]
loss: 354.036621  [ 5694/ 7851]
loss: 359.370422  [ 6162/ 7851]
loss: 282.164032  [ 6630/ 7851]
loss: 306.933441  [ 7098/ 7851]
loss: 403.904938  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 358.407599 
Epoch 23
-------------------------------
loss: 348.591187  [   79/ 7851]
loss: 319.925537  [  547/ 7851]
loss: 353.178802  [ 1015/ 7851]
loss: 245.981171  [ 1483/ 7851]
loss: 475.931061  [ 1951/ 7851]
loss: 233.894440  [ 2419/ 7851]
loss: 189.000732  [ 2887/ 7851]
loss: 243.120392  [ 3355/ 7851]
loss: 286.304199  [ 3823/ 7851]
loss: 313.430695  [ 4290/ 7851]
loss: 175.684769  [ 4758/ 7851]
loss: 159.535324  [ 5226/ 7851]
loss: 248.057510  [ 5694/ 7851]
loss: 284.442596  [ 6162/ 7851]
loss: 333.924011  [ 6630/ 7851]
loss: 260.901154  [ 7098/ 7851]
loss: 731.564453  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 229.460428 
Epoch 24
-------------------------------
loss: 224.681335  [   79/ 7851]
loss: 119.593117  [  547/ 7851]
loss: 152.137604  [ 1015/ 7851]
loss: 166.893707  [ 1483/ 7851]
loss: 144.022339  [ 1951/ 7851]
loss: 175.451538  [ 2419/ 7851]
loss: 128.771881  [ 2887/ 7851]
loss: 219.229507  [ 3355/ 7851]
loss: 194.173965  [ 3823/ 7851]
loss: 131.424545  [ 4290/ 7851]
loss: 124.512520  [ 4758/ 7851]
loss: 163.469345  [ 5226/ 7851]
loss: 174.313660  [ 5694/ 7851]
loss: 272.594086  [ 6162/ 7851]
loss: 887.479431  [ 6630/ 7851]
loss: 537.655701  [ 7098/ 7851]
loss: 845.785156  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 863.468420 
Epoch 25
-------------------------------
loss: 864.369385  [   79/ 7851]
loss: 1633.160278  [  547/ 7851]
loss: 759.516479  [ 1015/ 7851]
loss: 351.039398  [ 1483/ 7851]
loss: 666.585449  [ 1951/ 7851]
loss: 572.478333  [ 2419/ 7851]
loss: 798.387268  [ 2887/ 7851]
loss: 342.229126  [ 3355/ 7851]
loss: 229.328400  [ 3823/ 7851]
loss: 189.357178  [ 4290/ 7851]
loss: 166.637756  [ 4758/ 7851]
loss: 186.509079  [ 5226/ 7851]
loss: 215.647522  [ 5694/ 7851]
loss: 282.964752  [ 6162/ 7851]
loss: 466.245087  [ 6630/ 7851]
loss: 231.648941  [ 7098/ 7851]
loss: 230.374939  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 178.876877 
Epoch 26
-------------------------------
loss: 174.879654  [   79/ 7851]
loss: 167.951279  [  547/ 7851]
loss: 145.240631  [ 1015/ 7851]
loss: 177.502457  [ 1483/ 7851]
loss: 277.798462  [ 1951/ 7851]
loss: 338.378326  [ 2419/ 7851]
loss: 410.145477  [ 2887/ 7851]
loss: 437.231079  [ 3355/ 7851]
loss: 334.349182  [ 3823/ 7851]
loss: 324.045258  [ 4290/ 7851]
loss: 108.465302  [ 4758/ 7851]
loss: 310.655060  [ 5226/ 7851]
loss: 213.877960  [ 5694/ 7851]
loss: 123.287010  [ 6162/ 7851]
loss: 278.435455  [ 6630/ 7851]
loss: 263.249573  [ 7098/ 7851]
loss: 141.203781  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 428.656354 
Epoch 27
-------------------------------
loss: 427.598511  [   79/ 7851]
loss: 359.829193  [  547/ 7851]
loss: 311.067871  [ 1015/ 7851]
loss: 139.062180  [ 1483/ 7851]
loss: 131.426300  [ 1951/ 7851]
loss: 241.401566  [ 2419/ 7851]
loss: 179.289749  [ 2887/ 7851]
loss: 175.233902  [ 3355/ 7851]
loss: 252.285660  [ 3823/ 7851]
loss: 642.818726  [ 4290/ 7851]
loss: 919.139038  [ 4758/ 7851]
loss: 801.507690  [ 5226/ 7851]
loss: 448.034882  [ 5694/ 7851]
loss: 204.165909  [ 6162/ 7851]
loss: 364.120239  [ 6630/ 7851]
loss: 586.499390  [ 7098/ 7851]
loss: 458.463196  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 409.195410 
Epoch 28
-------------------------------
loss: 396.894623  [   79/ 7851]
loss: 215.623398  [  547/ 7851]
loss: 146.006027  [ 1015/ 7851]
loss: 166.030563  [ 1483/ 7851]
loss: 235.915543  [ 1951/ 7851]
loss: 217.775696  [ 2419/ 7851]
loss: 206.622803  [ 2887/ 7851]
loss: 210.755585  [ 3355/ 7851]
loss: 342.585907  [ 3823/ 7851]
loss: 251.115311  [ 4290/ 7851]
loss: 214.506836  [ 4758/ 7851]
loss: 180.593124  [ 5226/ 7851]
loss: 119.042351  [ 5694/ 7851]
loss: 229.963547  [ 6162/ 7851]
loss: 282.378815  [ 6630/ 7851]
loss: 190.780350  [ 7098/ 7851]
loss: 183.856308  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 137.906934 
Epoch 29
-------------------------------
loss: 134.379059  [   79/ 7851]
loss: 232.732590  [  547/ 7851]
loss: 260.622253  [ 1015/ 7851]
loss: 538.979004  [ 1483/ 7851]
loss: 327.744141  [ 1951/ 7851]
loss: 285.607147  [ 2419/ 7851]
loss: 360.203613  [ 2887/ 7851]
loss: 250.996643  [ 3355/ 7851]
loss: 181.047226  [ 3823/ 7851]
loss: 230.955765  [ 4290/ 7851]
loss: 270.250305  [ 4758/ 7851]
loss: 200.679642  [ 5226/ 7851]
loss: 314.372925  [ 5694/ 7851]
loss: 259.288422  [ 6162/ 7851]
loss: 192.957489  [ 6630/ 7851]
loss: 137.719788  [ 7098/ 7851]
loss: 143.295868  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 99.706329 
Epoch 30
-------------------------------
loss: 96.297279  [   79/ 7851]
loss: 356.077698  [  547/ 7851]
loss: 237.594864  [ 1015/ 7851]
loss: 140.816406  [ 1483/ 7851]
loss: 258.207367  [ 1951/ 7851]
loss: 304.246246  [ 2419/ 7851]
loss: 345.758698  [ 2887/ 7851]
loss: 247.360245  [ 3355/ 7851]
loss: 278.766968  [ 3823/ 7851]
loss: 202.277908  [ 4290/ 7851]
loss: 159.019363  [ 4758/ 7851]
loss: 153.503098  [ 5226/ 7851]
loss: 134.421997  [ 5694/ 7851]
loss: 167.557373  [ 6162/ 7851]
loss: 413.055359  [ 6630/ 7851]
loss: 433.161896  [ 7098/ 7851]
loss: 337.593018  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 978.017419 
Epoch 31
-------------------------------
loss: 973.492432  [   79/ 7851]
loss: 223.864136  [  547/ 7851]
loss: 383.382904  [ 1015/ 7851]
loss: 340.633911  [ 1483/ 7851]
loss: 282.521576  [ 1951/ 7851]
loss: 222.647018  [ 2419/ 7851]
loss: 225.862259  [ 2887/ 7851]
loss: 282.240356  [ 3355/ 7851]
loss: 259.538086  [ 3823/ 7851]
loss: 476.949158  [ 4290/ 7851]
loss: 817.128845  [ 4758/ 7851]
loss: 1152.161743  [ 5226/ 7851]
loss: 799.371643  [ 5694/ 7851]
loss: 884.252747  [ 6162/ 7851]
loss: 1370.336670  [ 6630/ 7851]
loss: 599.660645  [ 7098/ 7851]
loss: 744.435669  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.1%, Avg loss: 533.709424 
Epoch 32
-------------------------------
loss: 534.804138  [   79/ 7851]
loss: 394.624298  [  547/ 7851]
loss: 342.348267  [ 1015/ 7851]
loss: 379.541046  [ 1483/ 7851]
loss: 265.879517  [ 1951/ 7851]
loss: 320.074097  [ 2419/ 7851]
loss: 348.257599  [ 2887/ 7851]
loss: 187.461288  [ 3355/ 7851]
loss: 177.764359  [ 3823/ 7851]
loss: 100.279831  [ 4290/ 7851]
loss: 87.232208  [ 4758/ 7851]
loss: 336.919861  [ 5226/ 7851]
loss: 522.049011  [ 5694/ 7851]
loss: 601.543518  [ 6162/ 7851]
loss: 569.855164  [ 6630/ 7851]
loss: 395.504700  [ 7098/ 7851]
loss: 226.186798  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 315.952844 
Epoch 33
-------------------------------
loss: 310.047607  [   79/ 7851]
loss: 232.139709  [  547/ 7851]
loss: 323.931732  [ 1015/ 7851]
loss: 387.810089  [ 1483/ 7851]
loss: 542.078613  [ 1951/ 7851]
loss: 439.442322  [ 2419/ 7851]
loss: 381.745972  [ 2887/ 7851]
loss: 347.599213  [ 3355/ 7851]
loss: 170.451050  [ 3823/ 7851]
loss: 165.252563  [ 4290/ 7851]
loss: 229.029053  [ 4758/ 7851]
loss: 265.492645  [ 5226/ 7851]
loss: 307.233704  [ 5694/ 7851]
loss: 431.326294  [ 6162/ 7851]
loss: 205.877167  [ 6630/ 7851]
loss: 134.897354  [ 7098/ 7851]
loss: 139.376648  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 308.446478 
Epoch 34
-------------------------------
loss: 306.095581  [   79/ 7851]
loss: 287.817352  [  547/ 7851]
loss: 193.209824  [ 1015/ 7851]
loss: 151.472870  [ 1483/ 7851]
loss: 157.045456  [ 1951/ 7851]
loss: 170.993851  [ 2419/ 7851]
loss: 255.580063  [ 2887/ 7851]
loss: 377.926849  [ 3355/ 7851]
loss: 545.844360  [ 3823/ 7851]
loss: 546.061096  [ 4290/ 7851]
loss: 498.050323  [ 4758/ 7851]
loss: 388.241791  [ 5226/ 7851]
loss: 460.502594  [ 5694/ 7851]
loss: 288.053192  [ 6162/ 7851]
loss: 273.237549  [ 6630/ 7851]
loss: 212.952362  [ 7098/ 7851]
loss: 234.911774  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 272.557751 
Epoch 35
-------------------------------
loss: 264.440002  [   79/ 7851]
loss: 378.907562  [  547/ 7851]
loss: 181.064423  [ 1015/ 7851]
loss: 213.475342  [ 1483/ 7851]
loss: 194.866867  [ 1951/ 7851]
loss: 269.269531  [ 2419/ 7851]
loss: 483.709808  [ 2887/ 7851]
loss: 168.000198  [ 3355/ 7851]
loss: 193.558304  [ 3823/ 7851]
loss: 128.058319  [ 4290/ 7851]
loss: 242.988281  [ 4758/ 7851]
loss: 193.718567  [ 5226/ 7851]
loss: 164.176361  [ 5694/ 7851]
loss: 121.866493  [ 6162/ 7851]
loss: 188.786011  [ 6630/ 7851]
loss: 228.566467  [ 7098/ 7851]
loss: 236.617706  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 235.361331 
Epoch 36
-------------------------------
loss: 233.630096  [   79/ 7851]
loss: 162.198914  [  547/ 7851]
loss: 234.926147  [ 1015/ 7851]
loss: 275.444214  [ 1483/ 7851]
loss: 126.665489  [ 1951/ 7851]
loss: 138.764145  [ 2419/ 7851]
loss: 126.442917  [ 2887/ 7851]
loss: 202.577988  [ 3355/ 7851]
loss: 253.408478  [ 3823/ 7851]
loss: 228.093811  [ 4290/ 7851]
loss: 285.466217  [ 4758/ 7851]
loss: 380.110779  [ 5226/ 7851]
loss: 642.615662  [ 5694/ 7851]
loss: 609.900940  [ 6162/ 7851]
loss: 604.753235  [ 6630/ 7851]
loss: 383.154846  [ 7098/ 7851]
loss: 201.915024  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 193.334821 
Epoch 37
-------------------------------
loss: 191.175323  [   79/ 7851]
loss: 242.911743  [  547/ 7851]
loss: 434.408966  [ 1015/ 7851]
loss: 675.080933  [ 1483/ 7851]
loss: 806.733154  [ 1951/ 7851]
loss: 504.405731  [ 2419/ 7851]
loss: 368.944305  [ 2887/ 7851]
loss: 604.944641  [ 3355/ 7851]
loss: 749.374390  [ 3823/ 7851]
loss: 323.785156  [ 4290/ 7851]
loss: 564.163269  [ 4758/ 7851]
loss: 183.326447  [ 5226/ 7851]
loss: 310.280243  [ 5694/ 7851]
loss: 111.730858  [ 6162/ 7851]
loss: 205.765732  [ 6630/ 7851]
loss: 147.074295  [ 7098/ 7851]
loss: 236.649567  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 121.307233 
Epoch 38
-------------------------------
loss: 116.497322  [   79/ 7851]
loss: 236.109283  [  547/ 7851]
loss: 287.175842  [ 1015/ 7851]
loss: 223.545135  [ 1483/ 7851]
loss: 253.135239  [ 1951/ 7851]
loss: 154.433182  [ 2419/ 7851]
loss: 148.392120  [ 2887/ 7851]
loss: 208.416718  [ 3355/ 7851]
loss: 141.819824  [ 3823/ 7851]
loss: 126.702431  [ 4290/ 7851]
loss: 120.868088  [ 4758/ 7851]
loss: 325.914276  [ 5226/ 7851]
loss: 205.104462  [ 5694/ 7851]
loss: 186.781570  [ 6162/ 7851]
loss: 228.639069  [ 6630/ 7851]
loss: 551.993896  [ 7098/ 7851]
loss: 789.373047  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 804.062451 
Epoch 39
-------------------------------
loss: 789.898010  [   79/ 7851]
loss: 475.437988  [  547/ 7851]
loss: 768.012207  [ 1015/ 7851]
loss: 1016.347656  [ 1483/ 7851]
loss: 748.183411  [ 1951/ 7851]
loss: 1564.529907  [ 2419/ 7851]
loss: 438.925232  [ 2887/ 7851]
loss: 667.182068  [ 3355/ 7851]
loss: 292.850739  [ 3823/ 7851]
loss: 522.545654  [ 4290/ 7851]
loss: 348.042603  [ 4758/ 7851]
loss: 333.116150  [ 5226/ 7851]
loss: 357.849030  [ 5694/ 7851]
loss: 151.505280  [ 6162/ 7851]
loss: 252.471909  [ 6630/ 7851]
loss: 152.766769  [ 7098/ 7851]
loss: 174.424454  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 277.371033 
Epoch 40
-------------------------------
loss: 278.997101  [   79/ 7851]
loss: 132.881226  [  547/ 7851]
loss: 124.159355  [ 1015/ 7851]
loss: 207.588699  [ 1483/ 7851]
loss: 137.008926  [ 1951/ 7851]
loss: 228.040375  [ 2419/ 7851]
loss: 217.106232  [ 2887/ 7851]
loss: 245.674011  [ 3355/ 7851]
loss: 201.838623  [ 3823/ 7851]
loss: 159.799286  [ 4290/ 7851]
loss: 134.295609  [ 4758/ 7851]
loss: 142.341812  [ 5226/ 7851]
loss: 99.999390  [ 5694/ 7851]
loss: 232.754227  [ 6162/ 7851]
loss: 254.112854  [ 6630/ 7851]
loss: 125.467751  [ 7098/ 7851]
loss: 496.871063  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 366.707025 
Epoch 41
-------------------------------
loss: 372.159882  [   79/ 7851]
loss: 397.958954  [  547/ 7851]
loss: 289.004974  [ 1015/ 7851]
loss: 226.813080  [ 1483/ 7851]
loss: 275.905426  [ 1951/ 7851]
loss: 323.302795  [ 2419/ 7851]
loss: 360.114471  [ 2887/ 7851]
loss: 236.891251  [ 3355/ 7851]
loss: 268.914642  [ 3823/ 7851]
loss: 191.856766  [ 4290/ 7851]
loss: 191.506165  [ 4758/ 7851]
loss: 144.918716  [ 5226/ 7851]
loss: 138.876770  [ 5694/ 7851]
loss: 198.195709  [ 6162/ 7851]
loss: 85.355553  [ 6630/ 7851]
loss: 108.485718  [ 7098/ 7851]
loss: 715.970032  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.2%, Avg loss: 1350.476318 
Epoch 42
-------------------------------
loss: 1332.217407  [   79/ 7851]
loss: 508.464325  [  547/ 7851]
loss: 827.137024  [ 1015/ 7851]
loss: 513.471069  [ 1483/ 7851]
loss: 281.591858  [ 1951/ 7851]
loss: 390.174988  [ 2419/ 7851]
loss: 261.308563  [ 2887/ 7851]
loss: 445.895050  [ 3355/ 7851]
loss: 555.566589  [ 3823/ 7851]
loss: 695.504822  [ 4290/ 7851]
loss: 909.094421  [ 4758/ 7851]
loss: 492.323792  [ 5226/ 7851]
loss: 485.379883  [ 5694/ 7851]
loss: 313.037567  [ 6162/ 7851]
loss: 325.029236  [ 6630/ 7851]
loss: 159.087784  [ 7098/ 7851]
loss: 272.800446  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 154.643704 
Epoch 43
-------------------------------
loss: 152.313766  [   79/ 7851]
loss: 317.357910  [  547/ 7851]
loss: 300.740936  [ 1015/ 7851]
loss: 164.452271  [ 1483/ 7851]
loss: 162.507462  [ 1951/ 7851]
loss: 166.888168  [ 2419/ 7851]
loss: 174.491058  [ 2887/ 7851]
loss: 206.134171  [ 3355/ 7851]
loss: 208.571594  [ 3823/ 7851]
loss: 180.577637  [ 4290/ 7851]
loss: 360.924286  [ 4758/ 7851]
loss: 462.261780  [ 5226/ 7851]
loss: 211.751175  [ 5694/ 7851]
loss: 236.302185  [ 6162/ 7851]
loss: 229.350601  [ 6630/ 7851]
loss: 276.539307  [ 7098/ 7851]
loss: 282.736176  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.5%, Avg loss: 190.250583 
Epoch 44
-------------------------------
loss: 187.500824  [   79/ 7851]
loss: 162.910049  [  547/ 7851]
loss: 342.490784  [ 1015/ 7851]
loss: 607.610413  [ 1483/ 7851]
loss: 616.602844  [ 1951/ 7851]
loss: 351.255463  [ 2419/ 7851]
loss: 769.281799  [ 2887/ 7851]
loss: 601.885193  [ 3355/ 7851]
loss: 511.123260  [ 3823/ 7851]
loss: 495.218903  [ 4290/ 7851]
loss: 252.368652  [ 4758/ 7851]
loss: 532.359192  [ 5226/ 7851]
loss: 284.354675  [ 5694/ 7851]
loss: 126.481133  [ 6162/ 7851]
loss: 138.047272  [ 6630/ 7851]
loss: 295.891022  [ 7098/ 7851]
loss: 99.916740  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 243.591162 
Epoch 45
-------------------------------
loss: 241.287994  [   79/ 7851]
loss: 116.694107  [  547/ 7851]
loss: 199.159103  [ 1015/ 7851]
loss: 253.841614  [ 1483/ 7851]
loss: 312.246338  [ 1951/ 7851]
loss: 402.957275  [ 2419/ 7851]
loss: 234.833557  [ 2887/ 7851]
loss: 179.180099  [ 3355/ 7851]
loss: 166.537247  [ 3823/ 7851]
loss: 165.673065  [ 4290/ 7851]
loss: 195.352371  [ 4758/ 7851]
loss: 194.755325  [ 5226/ 7851]
loss: 165.652206  [ 5694/ 7851]
loss: 123.948837  [ 6162/ 7851]
loss: 259.121460  [ 6630/ 7851]
loss: 275.372467  [ 7098/ 7851]
loss: 103.790192  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 238.107898 
Epoch 46
-------------------------------
loss: 235.299957  [   79/ 7851]
loss: 234.314636  [  547/ 7851]
loss: 196.103027  [ 1015/ 7851]
loss: 170.092545  [ 1483/ 7851]
loss: 128.976151  [ 1951/ 7851]
loss: 107.909058  [ 2419/ 7851]
loss: 191.794266  [ 2887/ 7851]
loss: 180.385361  [ 3355/ 7851]
loss: 176.663010  [ 3823/ 7851]
loss: 339.326324  [ 4290/ 7851]
loss: 401.188416  [ 4758/ 7851]
loss: 492.480316  [ 5226/ 7851]
loss: 330.492371  [ 5694/ 7851]
loss: 189.774155  [ 6162/ 7851]
loss: 224.788956  [ 6630/ 7851]
loss: 124.739685  [ 7098/ 7851]
loss: 164.421707  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 157.882782 
Epoch 47
-------------------------------
loss: 157.538300  [   79/ 7851]
loss: 159.988419  [  547/ 7851]
loss: 193.828033  [ 1015/ 7851]
loss: 335.531799  [ 1483/ 7851]
loss: 531.889587  [ 1951/ 7851]
loss: 759.688843  [ 2419/ 7851]
loss: 538.451660  [ 2887/ 7851]
loss: 178.470490  [ 3355/ 7851]
loss: 231.255356  [ 3823/ 7851]
loss: 198.258652  [ 4290/ 7851]
loss: 326.483765  [ 4758/ 7851]
loss: 515.774780  [ 5226/ 7851]
loss: 468.482758  [ 5694/ 7851]
loss: 509.423187  [ 6162/ 7851]
loss: 421.067841  [ 6630/ 7851]
loss: 206.597870  [ 7098/ 7851]
loss: 166.514099  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 269.346637 
Epoch 48
-------------------------------
loss: 262.613617  [   79/ 7851]
loss: 150.727692  [  547/ 7851]
loss: 175.015152  [ 1015/ 7851]
loss: 345.622467  [ 1483/ 7851]
loss: 388.963287  [ 1951/ 7851]
loss: 240.021301  [ 2419/ 7851]
loss: 279.343475  [ 2887/ 7851]
loss: 196.586182  [ 3355/ 7851]
loss: 221.973297  [ 3823/ 7851]
loss: 179.077744  [ 4290/ 7851]
loss: 306.354340  [ 4758/ 7851]
loss: 297.717804  [ 5226/ 7851]
loss: 121.633774  [ 5694/ 7851]
loss: 146.812042  [ 6162/ 7851]
loss: 248.234207  [ 6630/ 7851]
loss: 173.087540  [ 7098/ 7851]
loss: 178.053543  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.4%, Avg loss: 134.808591 
Epoch 49
-------------------------------
loss: 132.127594  [   79/ 7851]
loss: 199.522644  [  547/ 7851]
loss: 97.802887  [ 1015/ 7851]
loss: 153.237701  [ 1483/ 7851]
loss: 133.611237  [ 1951/ 7851]
loss: 700.229431  [ 2419/ 7851]
loss: 381.533936  [ 2887/ 7851]
loss: 800.353333  [ 3355/ 7851]
loss: 398.860931  [ 3823/ 7851]
loss: 202.672318  [ 4290/ 7851]
loss: 252.426804  [ 4758/ 7851]
loss: 284.100037  [ 5226/ 7851]
loss: 295.305878  [ 5694/ 7851]
loss: 177.162643  [ 6162/ 7851]
loss: 286.562286  [ 6630/ 7851]
loss: 211.245270  [ 7098/ 7851]
loss: 326.494995  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 328.401666 
Epoch 50
-------------------------------
loss: 326.414185  [   79/ 7851]
loss: 196.060318  [  547/ 7851]
loss: 158.054108  [ 1015/ 7851]
loss: 247.292786  [ 1483/ 7851]
loss: 212.032700  [ 1951/ 7851]
loss: 203.525284  [ 2419/ 7851]
loss: 174.159515  [ 2887/ 7851]
loss: 165.591019  [ 3355/ 7851]
loss: 197.584259  [ 3823/ 7851]
loss: 195.364578  [ 4290/ 7851]
loss: 132.040710  [ 4758/ 7851]
loss: 197.375977  [ 5226/ 7851]
loss: 213.100357  [ 5694/ 7851]
loss: 732.534790  [ 6162/ 7851]
loss: 826.668579  [ 6630/ 7851]
loss: 350.221558  [ 7098/ 7851]
loss: 146.838501  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.3%, Avg loss: 206.937268 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 8000]               648,000
│    └─ReLU: 2-2                         [100, 8000]               --
│    └─Linear: 2-3                       [100, 400]                3,200,400
│    └─ReLU: 2-4                         [100, 400]                --
│    └─Linear: 2-5                       [100, 80]                 32,080
==========================================================================================
Total params: 3,880,480
Trainable params: 3,880,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 388.05
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 6.78
Params size (MB): 15.52
Estimated Total Size (MB): 22.34
==========================================================================================
Epoch 1
-------------------------------
loss: 15.374728  [   79/ 7851]
loss: 114.482773  [  547/ 7851]
loss: 29.154558  [ 1015/ 7851]
loss: 35.160679  [ 1483/ 7851]
loss: 9.745580  [ 1951/ 7851]
loss: 5.780967  [ 2419/ 7851]
loss: 5.906369  [ 2887/ 7851]
loss: 7.508207  [ 3355/ 7851]
loss: 10.035720  [ 3823/ 7851]
loss: 4.197409  [ 4290/ 7851]
loss: 6.190444  [ 4758/ 7851]
loss: 5.340592  [ 5226/ 7851]
loss: 5.322500  [ 5694/ 7851]
loss: 6.102419  [ 6162/ 7851]
loss: 8.491018  [ 6630/ 7851]
loss: 5.927238  [ 7098/ 7851]
loss: 8.449256  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.9%, Avg loss: 6.635761 
Epoch 2
-------------------------------
loss: 8.009311  [   79/ 7851]
loss: 7.249250  [  547/ 7851]
loss: 7.577040  [ 1015/ 7851]
loss: 7.790071  [ 1483/ 7851]
loss: 7.802433  [ 1951/ 7851]
loss: 5.124102  [ 2419/ 7851]
loss: 6.725914  [ 2887/ 7851]
loss: 6.786902  [ 3355/ 7851]
loss: 10.501931  [ 3823/ 7851]
loss: 4.445635  [ 4290/ 7851]
loss: 6.316118  [ 4758/ 7851]
loss: 4.899976  [ 5226/ 7851]
loss: 5.542718  [ 5694/ 7851]
loss: 4.780910  [ 6162/ 7851]
loss: 8.792157  [ 6630/ 7851]
loss: 6.070988  [ 7098/ 7851]
loss: 8.607839  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.360648 
Epoch 3
-------------------------------
loss: 7.781586  [   79/ 7851]
loss: 7.854742  [  547/ 7851]
loss: 7.334285  [ 1015/ 7851]
loss: 8.074822  [ 1483/ 7851]
loss: 8.320698  [ 1951/ 7851]
loss: 5.554865  [ 2419/ 7851]
loss: 5.812856  [ 2887/ 7851]
loss: 6.382017  [ 3355/ 7851]
loss: 10.119040  [ 3823/ 7851]
loss: 3.718425  [ 4290/ 7851]
loss: 6.194882  [ 4758/ 7851]
loss: 5.163782  [ 5226/ 7851]
loss: 9.216210  [ 5694/ 7851]
loss: 4.316262  [ 6162/ 7851]
loss: 8.621905  [ 6630/ 7851]
loss: 5.160182  [ 7098/ 7851]
loss: 7.958910  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 5.929286 
Epoch 4
-------------------------------
loss: 7.049520  [   79/ 7851]
loss: 7.004943  [  547/ 7851]
loss: 7.560004  [ 1015/ 7851]
loss: 7.689223  [ 1483/ 7851]
loss: 8.046254  [ 1951/ 7851]
loss: 4.608111  [ 2419/ 7851]
loss: 6.015698  [ 2887/ 7851]
loss: 5.871505  [ 3355/ 7851]
loss: 8.537785  [ 3823/ 7851]
loss: 3.743613  [ 4290/ 7851]
loss: 6.223371  [ 4758/ 7851]
loss: 4.929336  [ 5226/ 7851]
loss: 4.280313  [ 5694/ 7851]
loss: 5.115110  [ 6162/ 7851]
loss: 8.637496  [ 6630/ 7851]
loss: 6.022371  [ 7098/ 7851]
loss: 8.327392  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.226720 
Epoch 5
-------------------------------
loss: 7.699960  [   79/ 7851]
loss: 9.175248  [  547/ 7851]
loss: 7.104071  [ 1015/ 7851]
loss: 7.472913  [ 1483/ 7851]
loss: 7.453804  [ 1951/ 7851]
loss: 5.182957  [ 2419/ 7851]
loss: 5.362689  [ 2887/ 7851]
loss: 6.557409  [ 3355/ 7851]
loss: 9.742844  [ 3823/ 7851]
loss: 3.202787  [ 4290/ 7851]
loss: 6.589155  [ 4758/ 7851]
loss: 5.020069  [ 5226/ 7851]
loss: 4.550998  [ 5694/ 7851]
loss: 5.025257  [ 6162/ 7851]
loss: 9.012278  [ 6630/ 7851]
loss: 6.272977  [ 7098/ 7851]
loss: 9.001504  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.754466 
Epoch 6
-------------------------------
loss: 7.704650  [   79/ 7851]
loss: 6.734179  [  547/ 7851]
loss: 7.061281  [ 1015/ 7851]
loss: 7.512261  [ 1483/ 7851]
loss: 8.456712  [ 1951/ 7851]
loss: 5.086453  [ 2419/ 7851]
loss: 6.780853  [ 2887/ 7851]
loss: 8.721213  [ 3355/ 7851]
loss: 9.556492  [ 3823/ 7851]
loss: 3.692906  [ 4290/ 7851]
loss: 6.181944  [ 4758/ 7851]
loss: 5.017200  [ 5226/ 7851]
loss: 4.409260  [ 5694/ 7851]
loss: 5.376523  [ 6162/ 7851]
loss: 8.750863  [ 6630/ 7851]
loss: 6.003034  [ 7098/ 7851]
loss: 9.235924  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 7.504695 
Epoch 7
-------------------------------
loss: 8.434331  [   79/ 7851]
loss: 7.093009  [  547/ 7851]
loss: 7.640481  [ 1015/ 7851]
loss: 7.852096  [ 1483/ 7851]
loss: 8.684664  [ 1951/ 7851]
loss: 5.483355  [ 2419/ 7851]
loss: 5.955669  [ 2887/ 7851]
loss: 7.343589  [ 3355/ 7851]
loss: 9.812494  [ 3823/ 7851]
loss: 4.251143  [ 4290/ 7851]
loss: 6.216962  [ 4758/ 7851]
loss: 5.676285  [ 5226/ 7851]
loss: 4.420188  [ 5694/ 7851]
loss: 5.849514  [ 6162/ 7851]
loss: 8.846780  [ 6630/ 7851]
loss: 5.907238  [ 7098/ 7851]
loss: 9.004234  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 6.777176 
Epoch 8
-------------------------------
loss: 7.769909  [   79/ 7851]
loss: 7.146829  [  547/ 7851]
loss: 7.891384  [ 1015/ 7851]
loss: 7.774092  [ 1483/ 7851]
loss: 8.725241  [ 1951/ 7851]
loss: 5.424100  [ 2419/ 7851]
loss: 5.949780  [ 2887/ 7851]
loss: 7.315312  [ 3355/ 7851]
loss: 9.821509  [ 3823/ 7851]
loss: 4.245775  [ 4290/ 7851]
loss: 6.215358  [ 4758/ 7851]
loss: 5.661797  [ 5226/ 7851]
loss: 4.422004  [ 5694/ 7851]
loss: 5.842371  [ 6162/ 7851]
loss: 8.839362  [ 6630/ 7851]
loss: 5.905691  [ 7098/ 7851]
loss: 9.004264  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.777689 
Epoch 9
-------------------------------
loss: 7.768818  [   79/ 7851]
loss: 7.143935  [  547/ 7851]
loss: 7.868872  [ 1015/ 7851]
loss: 7.772799  [ 1483/ 7851]
loss: 8.719064  [ 1951/ 7851]
loss: 5.424479  [ 2419/ 7851]
loss: 5.938081  [ 2887/ 7851]
loss: 7.319248  [ 3355/ 7851]
loss: 9.822003  [ 3823/ 7851]
loss: 4.252933  [ 4290/ 7851]
loss: 6.207272  [ 4758/ 7851]
loss: 5.648416  [ 5226/ 7851]
loss: 4.418851  [ 5694/ 7851]
loss: 5.838997  [ 6162/ 7851]
loss: 8.837154  [ 6630/ 7851]
loss: 5.905025  [ 7098/ 7851]
loss: 9.004011  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.778292 
Epoch 10
-------------------------------
loss: 7.768652  [   79/ 7851]
loss: 7.140903  [  547/ 7851]
loss: 7.856955  [ 1015/ 7851]
loss: 7.772282  [ 1483/ 7851]
loss: 8.715909  [ 1951/ 7851]
loss: 5.424984  [ 2419/ 7851]
loss: 5.931668  [ 2887/ 7851]
loss: 7.322188  [ 3355/ 7851]
loss: 9.821645  [ 3823/ 7851]
loss: 4.257678  [ 4290/ 7851]
loss: 6.201313  [ 4758/ 7851]
loss: 5.641607  [ 5226/ 7851]
loss: 4.416530  [ 5694/ 7851]
loss: 5.838231  [ 6162/ 7851]
loss: 8.835520  [ 6630/ 7851]
loss: 5.904673  [ 7098/ 7851]
loss: 9.003823  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.778816 
Epoch 11
-------------------------------
loss: 7.768659  [   79/ 7851]
loss: 7.138547  [  547/ 7851]
loss: 7.849269  [ 1015/ 7851]
loss: 7.772047  [ 1483/ 7851]
loss: 8.713932  [ 1951/ 7851]
loss: 5.425457  [ 2419/ 7851]
loss: 5.927619  [ 2887/ 7851]
loss: 7.324429  [ 3355/ 7851]
loss: 9.821095  [ 3823/ 7851]
loss: 4.260999  [ 4290/ 7851]
loss: 6.196896  [ 4758/ 7851]
loss: 5.637776  [ 5226/ 7851]
loss: 4.414855  [ 5694/ 7851]
loss: 5.838343  [ 6162/ 7851]
loss: 8.834218  [ 6630/ 7851]
loss: 5.904435  [ 7098/ 7851]
loss: 9.003689  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.779254 
Epoch 12
-------------------------------
loss: 7.768715  [   79/ 7851]
loss: 7.136656  [  547/ 7851]
loss: 7.843936  [ 1015/ 7851]
loss: 7.771937  [ 1483/ 7851]
loss: 8.712596  [ 1951/ 7851]
loss: 5.425860  [ 2419/ 7851]
loss: 5.924860  [ 2887/ 7851]
loss: 7.326165  [ 3355/ 7851]
loss: 9.820538  [ 3823/ 7851]
loss: 4.263412  [ 4290/ 7851]
loss: 6.193548  [ 4758/ 7851]
loss: 5.635474  [ 5226/ 7851]
loss: 4.413630  [ 5694/ 7851]
loss: 5.838751  [ 6162/ 7851]
loss: 8.833157  [ 6630/ 7851]
loss: 5.904251  [ 7098/ 7851]
loss: 9.003591  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.779617 
Epoch 13
-------------------------------
loss: 7.768786  [   79/ 7851]
loss: 7.135108  [  547/ 7851]
loss: 7.840053  [ 1015/ 7851]
loss: 7.771885  [ 1483/ 7851]
loss: 8.711643  [ 1951/ 7851]
loss: 5.426194  [ 2419/ 7851]
loss: 5.922879  [ 2887/ 7851]
loss: 7.327535  [ 3355/ 7851]
loss: 9.820029  [ 3823/ 7851]
loss: 4.265226  [ 4290/ 7851]
loss: 6.190956  [ 4758/ 7851]
loss: 5.634020  [ 5226/ 7851]
loss: 4.412714  [ 5694/ 7851]
loss: 5.839239  [ 6162/ 7851]
loss: 8.832280  [ 6630/ 7851]
loss: 5.904099  [ 7098/ 7851]
loss: 9.003518  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.779920 
Epoch 14
-------------------------------
loss: 7.768856  [   79/ 7851]
loss: 7.133822  [  547/ 7851]
loss: 7.837124  [ 1015/ 7851]
loss: 7.771864  [ 1483/ 7851]
loss: 8.710938  [ 1951/ 7851]
loss: 5.426470  [ 2419/ 7851]
loss: 5.921399  [ 2887/ 7851]
loss: 7.328632  [ 3355/ 7851]
loss: 9.819580  [ 3823/ 7851]
loss: 4.266624  [ 4290/ 7851]
loss: 6.188907  [ 4758/ 7851]
loss: 5.633068  [ 5226/ 7851]
loss: 4.412014  [ 5694/ 7851]
loss: 5.839722  [ 6162/ 7851]
loss: 8.831550  [ 6630/ 7851]
loss: 5.903970  [ 7098/ 7851]
loss: 9.003465  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.780173 
Epoch 15
-------------------------------
loss: 7.768922  [   79/ 7851]
loss: 7.132744  [  547/ 7851]
loss: 7.834854  [ 1015/ 7851]
loss: 7.771857  [ 1483/ 7851]
loss: 8.710400  [ 1951/ 7851]
loss: 5.426700  [ 2419/ 7851]
loss: 5.920258  [ 2887/ 7851]
loss: 7.329525  [ 3355/ 7851]
loss: 9.819191  [ 3823/ 7851]
loss: 4.267726  [ 4290/ 7851]
loss: 6.187260  [ 4758/ 7851]
loss: 5.632425  [ 5226/ 7851]
loss: 4.411467  [ 5694/ 7851]
loss: 5.840168  [ 6162/ 7851]
loss: 8.830937  [ 6630/ 7851]
loss: 5.903860  [ 7098/ 7851]
loss: 9.003422  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.780386 
Epoch 16
-------------------------------
loss: 7.768982  [   79/ 7851]
loss: 7.131833  [  547/ 7851]
loss: 7.833057  [ 1015/ 7851]
loss: 7.771859  [ 1483/ 7851]
loss: 8.709978  [ 1951/ 7851]
loss: 5.426891  [ 2419/ 7851]
loss: 5.919358  [ 2887/ 7851]
loss: 7.330258  [ 3355/ 7851]
loss: 9.818856  [ 3823/ 7851]
loss: 4.268610  [ 4290/ 7851]
loss: 6.185917  [ 4758/ 7851]
loss: 5.631981  [ 5226/ 7851]
loss: 4.411033  [ 5694/ 7851]
loss: 5.840569  [ 6162/ 7851]
loss: 8.830419  [ 6630/ 7851]
loss: 5.903763  [ 7098/ 7851]
loss: 9.003389  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.780567 
Epoch 17
-------------------------------
loss: 7.769035  [   79/ 7851]
loss: 7.131057  [  547/ 7851]
loss: 7.831609  [ 1015/ 7851]
loss: 7.771864  [ 1483/ 7851]
loss: 8.709642  [ 1951/ 7851]
loss: 5.427050  [ 2419/ 7851]
loss: 5.918634  [ 2887/ 7851]
loss: 7.330871  [ 3355/ 7851]
loss: 9.818567  [ 3823/ 7851]
loss: 4.269330  [ 4290/ 7851]
loss: 6.184807  [ 4758/ 7851]
loss: 5.631669  [ 5226/ 7851]
loss: 4.410684  [ 5694/ 7851]
loss: 5.840924  [ 6162/ 7851]
loss: 8.829977  [ 6630/ 7851]
loss: 5.903680  [ 7098/ 7851]
loss: 9.003363  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.780721 
Epoch 18
-------------------------------
loss: 7.769084  [   79/ 7851]
loss: 7.130394  [  547/ 7851]
loss: 7.830426  [ 1015/ 7851]
loss: 7.771871  [ 1483/ 7851]
loss: 8.709372  [ 1951/ 7851]
loss: 5.427186  [ 2419/ 7851]
loss: 5.918044  [ 2887/ 7851]
loss: 7.331384  [ 3355/ 7851]
loss: 9.818316  [ 3823/ 7851]
loss: 4.269923  [ 4290/ 7851]
loss: 6.183882  [ 4758/ 7851]
loss: 5.631446  [ 5226/ 7851]
loss: 4.410398  [ 5694/ 7851]
loss: 5.841235  [ 6162/ 7851]
loss: 8.829600  [ 6630/ 7851]
loss: 5.903606  [ 7098/ 7851]
loss: 9.003341  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.780853 
Epoch 19
-------------------------------
loss: 7.769125  [   79/ 7851]
loss: 7.129824  [  547/ 7851]
loss: 7.829447  [ 1015/ 7851]
loss: 7.771880  [ 1483/ 7851]
loss: 8.967778  [ 1951/ 7851]
loss: 5.439155  [ 2419/ 7851]
loss: 5.931774  [ 2887/ 7851]
loss: 7.334030  [ 3355/ 7851]
loss: 9.812926  [ 3823/ 7851]
loss: 4.267391  [ 4290/ 7851]
loss: 6.181992  [ 4758/ 7851]
loss: 5.634903  [ 5226/ 7851]
loss: 4.410917  [ 5694/ 7851]
loss: 5.842128  [ 6162/ 7851]
loss: 8.828966  [ 6630/ 7851]
loss: 5.903549  [ 7098/ 7851]
loss: 9.003213  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.780940 
Epoch 20
-------------------------------
loss: 7.769112  [   79/ 7851]
loss: 7.129411  [  547/ 7851]
loss: 7.828876  [ 1015/ 7851]
loss: 7.771908  [ 1483/ 7851]
loss: 8.709009  [ 1951/ 7851]
loss: 5.427359  [ 2419/ 7851]
loss: 5.917257  [ 2887/ 7851]
loss: 7.332060  [ 3355/ 7851]
loss: 9.818002  [ 3823/ 7851]
loss: 4.270703  [ 4290/ 7851]
loss: 6.182666  [ 4758/ 7851]
loss: 5.631172  [ 5226/ 7851]
loss: 4.410024  [ 5694/ 7851]
loss: 5.841655  [ 6162/ 7851]
loss: 8.829099  [ 6630/ 7851]
loss: 5.903508  [ 7098/ 7851]
loss: 9.003321  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.781025 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 8000]               3,208,000
│    └─ReLU: 2-4                         [100, 8000]               --
│    └─Linear: 2-5                       [100, 400]                3,200,400
│    └─ReLU: 2-6                         [100, 400]                --
│    └─Linear: 2-7                       [100, 80]                 32,080
==========================================================================================
Total params: 6,472,880
Trainable params: 6,472,880
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 647.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 7.10
Params size (MB): 25.89
Estimated Total Size (MB): 33.03
==========================================================================================
Epoch 1
-------------------------------
loss: 15.291500  [   79/ 7851]
loss: 66981.687500  [  547/ 7851]
loss: 107.318489  [ 1015/ 7851]
loss: 10.444069  [ 1483/ 7851]
loss: 5.410747  [ 1951/ 7851]
loss: 7.384027  [ 2419/ 7851]
loss: 10.530553  [ 2887/ 7851]
loss: 6.665397  [ 3355/ 7851]
loss: 5.946313  [ 3823/ 7851]
loss: 7.411909  [ 4290/ 7851]
loss: 10.229775  [ 4758/ 7851]
loss: 7.294303  [ 5226/ 7851]
loss: 7.664825  [ 5694/ 7851]
loss: 7.099777  [ 6162/ 7851]
loss: 9.868797  [ 6630/ 7851]
loss: 8.959696  [ 7098/ 7851]
loss: 8.249543  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.864235 
Epoch 2
-------------------------------
loss: 6.512275  [   79/ 7851]
loss: 6.096660  [  547/ 7851]
loss: 6.681699  [ 1015/ 7851]
loss: 8.524049  [ 1483/ 7851]
loss: 5.488415  [ 1951/ 7851]
loss: 6.421510  [ 2419/ 7851]
loss: 8.646503  [ 2887/ 7851]
loss: 7.721876  [ 3355/ 7851]
loss: 5.949882  [ 3823/ 7851]
loss: 7.353840  [ 4290/ 7851]
loss: 9.149307  [ 4758/ 7851]
loss: 7.373885  [ 5226/ 7851]
loss: 7.352339  [ 5694/ 7851]
loss: 6.976068  [ 6162/ 7851]
loss: 6.800790  [ 6630/ 7851]
loss: 8.871237  [ 7098/ 7851]
loss: 7.908363  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.807945 
Epoch 3
-------------------------------
loss: 6.645384  [   79/ 7851]
loss: 6.177060  [  547/ 7851]
loss: 6.668267  [ 1015/ 7851]
loss: 6.933574  [ 1483/ 7851]
loss: 5.202374  [ 1951/ 7851]
loss: 6.381654  [ 2419/ 7851]
loss: 8.614902  [ 2887/ 7851]
loss: 6.582238  [ 3355/ 7851]
loss: 6.064154  [ 3823/ 7851]
loss: 5.990211  [ 4290/ 7851]
loss: 8.892975  [ 4758/ 7851]
loss: 7.607374  [ 5226/ 7851]
loss: 7.348485  [ 5694/ 7851]
loss: 6.961064  [ 6162/ 7851]
loss: 6.037562  [ 6630/ 7851]
loss: 8.746751  [ 7098/ 7851]
loss: 7.910436  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.828730 
Epoch 4
-------------------------------
loss: 6.636463  [   79/ 7851]
loss: 6.093251  [  547/ 7851]
loss: 6.610056  [ 1015/ 7851]
loss: 7.010831  [ 1483/ 7851]
loss: 5.288022  [ 1951/ 7851]
loss: 6.344972  [ 2419/ 7851]
loss: 8.611197  [ 2887/ 7851]
loss: 6.593681  [ 3355/ 7851]
loss: 6.022056  [ 3823/ 7851]
loss: 6.012263  [ 4290/ 7851]
loss: 8.901224  [ 4758/ 7851]
loss: 7.589490  [ 5226/ 7851]
loss: 7.335330  [ 5694/ 7851]
loss: 6.958703  [ 6162/ 7851]
loss: 6.056868  [ 6630/ 7851]
loss: 8.737103  [ 7098/ 7851]
loss: 7.908265  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.825482 
Epoch 5
-------------------------------
loss: 6.635767  [   79/ 7851]
loss: 6.093738  [  547/ 7851]
loss: 6.610216  [ 1015/ 7851]
loss: 7.012348  [ 1483/ 7851]
loss: 5.287541  [ 1951/ 7851]
loss: 6.344810  [ 2419/ 7851]
loss: 8.611002  [ 2887/ 7851]
loss: 6.595743  [ 3355/ 7851]
loss: 6.019187  [ 3823/ 7851]
loss: 6.014143  [ 4290/ 7851]
loss: 8.902727  [ 4758/ 7851]
loss: 7.583387  [ 5226/ 7851]
loss: 7.335038  [ 5694/ 7851]
loss: 6.958660  [ 6162/ 7851]
loss: 6.055093  [ 6630/ 7851]
loss: 8.736368  [ 7098/ 7851]
loss: 7.908175  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.826163 
Epoch 6
-------------------------------
loss: 6.635738  [   79/ 7851]
loss: 6.092191  [  547/ 7851]
loss: 6.610528  [ 1015/ 7851]
loss: 7.014784  [ 1483/ 7851]
loss: 5.286150  [ 1951/ 7851]
loss: 6.344738  [ 2419/ 7851]
loss: 8.611055  [ 2887/ 7851]
loss: 6.596884  [ 3355/ 7851]
loss: 6.017330  [ 3823/ 7851]
loss: 6.014891  [ 4290/ 7851]
loss: 8.903612  [ 4758/ 7851]
loss: 7.579396  [ 5226/ 7851]
loss: 7.334918  [ 5694/ 7851]
loss: 6.958688  [ 6162/ 7851]
loss: 6.053594  [ 6630/ 7851]
loss: 8.736017  [ 7098/ 7851]
loss: 7.908105  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.826640 
Epoch 7
-------------------------------
loss: 6.635761  [   79/ 7851]
loss: 6.091173  [  547/ 7851]
loss: 6.610811  [ 1015/ 7851]
loss: 7.016290  [ 1483/ 7851]
loss: 5.285217  [ 1951/ 7851]
loss: 6.344707  [ 2419/ 7851]
loss: 8.611092  [ 2887/ 7851]
loss: 6.597602  [ 3355/ 7851]
loss: 6.016140  [ 3823/ 7851]
loss: 6.015307  [ 4290/ 7851]
loss: 8.904191  [ 4758/ 7851]
loss: 7.576720  [ 5226/ 7851]
loss: 7.334855  [ 5694/ 7851]
loss: 6.958728  [ 6162/ 7851]
loss: 6.052471  [ 6630/ 7851]
loss: 8.735816  [ 7098/ 7851]
loss: 7.908055  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.826976 
Epoch 8
-------------------------------
loss: 6.635794  [   79/ 7851]
loss: 6.090467  [  547/ 7851]
loss: 6.611045  [ 1015/ 7851]
loss: 7.017296  [ 1483/ 7851]
loss: 5.284559  [ 1951/ 7851]
loss: 6.344693  [ 2419/ 7851]
loss: 8.611117  [ 2887/ 7851]
loss: 6.598093  [ 3355/ 7851]
loss: 6.015323  [ 3823/ 7851]
loss: 6.015567  [ 4290/ 7851]
loss: 8.904593  [ 4758/ 7851]
loss: 7.574820  [ 5226/ 7851]
loss: 7.334816  [ 5694/ 7851]
loss: 6.958766  [ 6162/ 7851]
loss: 6.051624  [ 6630/ 7851]
loss: 8.735691  [ 7098/ 7851]
loss: 7.908017  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827221 
Epoch 9
-------------------------------
loss: 6.635824  [   79/ 7851]
loss: 6.089954  [  547/ 7851]
loss: 6.611237  [ 1015/ 7851]
loss: 7.018005  [ 1483/ 7851]
loss: 5.284077  [ 1951/ 7851]
loss: 6.344685  [ 2419/ 7851]
loss: 8.611134  [ 2887/ 7851]
loss: 6.598446  [ 3355/ 7851]
loss: 6.014731  [ 3823/ 7851]
loss: 6.015743  [ 4290/ 7851]
loss: 8.904889  [ 4758/ 7851]
loss: 7.573414  [ 5226/ 7851]
loss: 7.334791  [ 5694/ 7851]
loss: 6.958800  [ 6162/ 7851]
loss: 6.050972  [ 6630/ 7851]
loss: 8.735606  [ 7098/ 7851]
loss: 7.907989  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827406 
Epoch 10
-------------------------------
loss: 6.635851  [   79/ 7851]
loss: 6.089568  [  547/ 7851]
loss: 6.611394  [ 1015/ 7851]
loss: 7.018530  [ 1483/ 7851]
loss: 5.283710  [ 1951/ 7851]
loss: 6.344679  [ 2419/ 7851]
loss: 8.611146  [ 2887/ 7851]
loss: 6.598711  [ 3355/ 7851]
loss: 6.014286  [ 3823/ 7851]
loss: 6.015869  [ 4290/ 7851]
loss: 8.905113  [ 4758/ 7851]
loss: 7.572337  [ 5226/ 7851]
loss: 7.334773  [ 5694/ 7851]
loss: 6.958827  [ 6162/ 7851]
loss: 6.050461  [ 6630/ 7851]
loss: 8.735545  [ 7098/ 7851]
loss: 7.907965  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827549 
Epoch 11
-------------------------------
loss: 6.635876  [   79/ 7851]
loss: 6.089269  [  547/ 7851]
loss: 6.611522  [ 1015/ 7851]
loss: 7.018929  [ 1483/ 7851]
loss: 5.283426  [ 1951/ 7851]
loss: 6.344677  [ 2419/ 7851]
loss: 8.611156  [ 2887/ 7851]
loss: 6.598916  [ 3355/ 7851]
loss: 6.013941  [ 3823/ 7851]
loss: 6.015963  [ 4290/ 7851]
loss: 8.905289  [ 4758/ 7851]
loss: 7.571493  [ 5226/ 7851]
loss: 7.334760  [ 5694/ 7851]
loss: 6.958851  [ 6162/ 7851]
loss: 6.050052  [ 6630/ 7851]
loss: 8.735502  [ 7098/ 7851]
loss: 7.907947  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827662 
Epoch 12
-------------------------------
loss: 6.635895  [   79/ 7851]
loss: 6.089033  [  547/ 7851]
loss: 6.611628  [ 1015/ 7851]
loss: 7.019243  [ 1483/ 7851]
loss: 5.283199  [ 1951/ 7851]
loss: 6.344675  [ 2419/ 7851]
loss: 8.611162  [ 2887/ 7851]
loss: 6.599079  [ 3355/ 7851]
loss: 6.013668  [ 3823/ 7851]
loss: 6.016033  [ 4290/ 7851]
loss: 8.905427  [ 4758/ 7851]
loss: 7.570817  [ 5226/ 7851]
loss: 7.334750  [ 5694/ 7851]
loss: 6.958871  [ 6162/ 7851]
loss: 6.049721  [ 6630/ 7851]
loss: 8.735469  [ 7098/ 7851]
loss: 7.907932  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827753 
Epoch 13
-------------------------------
loss: 6.635912  [   79/ 7851]
loss: 6.088842  [  547/ 7851]
loss: 6.611717  [ 1015/ 7851]
loss: 7.019492  [ 1483/ 7851]
loss: 5.283015  [ 1951/ 7851]
loss: 6.344674  [ 2419/ 7851]
loss: 8.611169  [ 2887/ 7851]
loss: 6.599211  [ 3355/ 7851]
loss: 6.013447  [ 3823/ 7851]
loss: 6.016090  [ 4290/ 7851]
loss: 8.905540  [ 4758/ 7851]
loss: 7.570267  [ 5226/ 7851]
loss: 7.334742  [ 5694/ 7851]
loss: 6.958888  [ 6162/ 7851]
loss: 6.049448  [ 6630/ 7851]
loss: 8.735443  [ 7098/ 7851]
loss: 7.907919  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827827 
Epoch 14
-------------------------------
loss: 6.635927  [   79/ 7851]
loss: 6.088686  [  547/ 7851]
loss: 6.611792  [ 1015/ 7851]
loss: 7.019694  [ 1483/ 7851]
loss: 5.282866  [ 1951/ 7851]
loss: 6.344674  [ 2419/ 7851]
loss: 8.611173  [ 2887/ 7851]
loss: 6.599319  [ 3355/ 7851]
loss: 6.013266  [ 3823/ 7851]
loss: 6.016135  [ 4290/ 7851]
loss: 8.905633  [ 4758/ 7851]
loss: 7.569814  [ 5226/ 7851]
loss: 7.334736  [ 5694/ 7851]
loss: 6.958902  [ 6162/ 7851]
loss: 6.049222  [ 6630/ 7851]
loss: 8.735422  [ 7098/ 7851]
loss: 7.907909  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827889 
Epoch 15
-------------------------------
loss: 6.635939  [   79/ 7851]
loss: 6.088556  [  547/ 7851]
loss: 6.611855  [ 1015/ 7851]
loss: 7.019861  [ 1483/ 7851]
loss: 5.282740  [ 1951/ 7851]
loss: 6.344673  [ 2419/ 7851]
loss: 8.611176  [ 2887/ 7851]
loss: 6.599407  [ 3355/ 7851]
loss: 6.013116  [ 3823/ 7851]
loss: 6.016171  [ 4290/ 7851]
loss: 8.905710  [ 4758/ 7851]
loss: 7.569436  [ 5226/ 7851]
loss: 7.334731  [ 5694/ 7851]
loss: 6.958916  [ 6162/ 7851]
loss: 6.049032  [ 6630/ 7851]
loss: 8.735405  [ 7098/ 7851]
loss: 7.907901  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827940 
Epoch 16
-------------------------------
loss: 6.635951  [   79/ 7851]
loss: 6.088449  [  547/ 7851]
loss: 6.611908  [ 1015/ 7851]
loss: 7.020000  [ 1483/ 7851]
loss: 5.282636  [ 1951/ 7851]
loss: 6.344672  [ 2419/ 7851]
loss: 8.611179  [ 2887/ 7851]
loss: 6.599482  [ 3355/ 7851]
loss: 6.012991  [ 3823/ 7851]
loss: 6.016201  [ 4290/ 7851]
loss: 8.905774  [ 4758/ 7851]
loss: 7.569118  [ 5226/ 7851]
loss: 7.334728  [ 5694/ 7851]
loss: 6.958926  [ 6162/ 7851]
loss: 6.048872  [ 6630/ 7851]
loss: 8.735393  [ 7098/ 7851]
loss: 7.907894  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.827983 
Epoch 17
-------------------------------
loss: 6.635960  [   79/ 7851]
loss: 6.088357  [  547/ 7851]
loss: 6.611954  [ 1015/ 7851]
loss: 7.020117  [ 1483/ 7851]
loss: 5.282547  [ 1951/ 7851]
loss: 6.344672  [ 2419/ 7851]
loss: 8.611183  [ 2887/ 7851]
loss: 6.599545  [ 3355/ 7851]
loss: 6.012885  [ 3823/ 7851]
loss: 6.016226  [ 4290/ 7851]
loss: 8.905830  [ 4758/ 7851]
loss: 7.568848  [ 5226/ 7851]
loss: 7.334724  [ 5694/ 7851]
loss: 6.958934  [ 6162/ 7851]
loss: 6.048735  [ 6630/ 7851]
loss: 8.735380  [ 7098/ 7851]
loss: 7.907887  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.828020 
Epoch 18
-------------------------------
loss: 6.635968  [   79/ 7851]
loss: 6.088280  [  547/ 7851]
loss: 6.611994  [ 1015/ 7851]
loss: 7.020216  [ 1483/ 7851]
loss: 5.282471  [ 1951/ 7851]
loss: 6.344672  [ 2419/ 7851]
loss: 8.611183  [ 2887/ 7851]
loss: 6.599598  [ 3355/ 7851]
loss: 6.012795  [ 3823/ 7851]
loss: 6.016247  [ 4290/ 7851]
loss: 8.905875  [ 4758/ 7851]
loss: 7.568619  [ 5226/ 7851]
loss: 7.334721  [ 5694/ 7851]
loss: 6.958942  [ 6162/ 7851]
loss: 6.048618  [ 6630/ 7851]
loss: 8.735373  [ 7098/ 7851]
loss: 7.907882  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.828051 
Epoch 19
-------------------------------
loss: 6.635975  [   79/ 7851]
loss: 6.088213  [  547/ 7851]
loss: 6.612029  [ 1015/ 7851]
loss: 7.020300  [ 1483/ 7851]
loss: 5.282407  [ 1951/ 7851]
loss: 6.344672  [ 2419/ 7851]
loss: 8.611186  [ 2887/ 7851]
loss: 6.599645  [ 3355/ 7851]
loss: 6.012717  [ 3823/ 7851]
loss: 6.016265  [ 4290/ 7851]
loss: 8.905916  [ 4758/ 7851]
loss: 7.568420  [ 5226/ 7851]
loss: 7.334719  [ 5694/ 7851]
loss: 6.958949  [ 6162/ 7851]
loss: 6.048517  [ 6630/ 7851]
loss: 8.735365  [ 7098/ 7851]
loss: 7.907877  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.828079 
Epoch 20
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 8000]               3,208,000
│    └─ReLU: 2-4                         [100, 8000]               --
│    └─Linear: 2-5                       [100, 400]                3,200,400
│    └─ReLU: 2-6                         [100, 400]                --
│    └─Linear: 2-7                       [100, 80]                 32,080
==========================================================================================
Total params: 6,472,880
Trainable params: 6,472,880
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 647.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 7.10
Params size (MB): 25.89
Estimated Total Size (MB): 33.03
==========================================================================================
Epoch 1
-------------------------------
loss: 11.234149  [   79/ 7851]
loss: 60103864.000000  [  547/ 7851]
loss: 12696.011719  [ 1015/ 7851]
loss: 5.712062  [ 1483/ 7851]
loss: 55240.902344  [ 1951/ 7851]
loss: 5.937752  [ 2419/ 7851]
loss: 5.925828  [ 2887/ 7851]
loss: 2125820.000000  [ 3355/ 7851]
loss: 8.316717  [ 3823/ 7851]
loss: 8.168626  [ 4290/ 7851]
loss: 4.223629  [ 4758/ 7851]
loss: 7.184743  [ 5226/ 7851]
loss: 9.004725  [ 5694/ 7851]
loss: 4.116139  [ 6162/ 7851]
loss: 4.084005  [ 6630/ 7851]
loss: 7.310015  [ 7098/ 7851]
loss: 7.464678  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.907787 
Epoch 2
-------------------------------
loss: 5.437062  [   79/ 7851]
loss: 7.610301  [  547/ 7851]
loss: 5.948881  [ 1015/ 7851]
loss: 5.571356  [ 1483/ 7851]
loss: 5.780706  [ 1951/ 7851]
loss: 5.652739  [ 2419/ 7851]
loss: 5.868663  [ 2887/ 7851]
loss: 5.038670  [ 3355/ 7851]
loss: 8.412327  [ 3823/ 7851]
loss: 8.216588  [ 4290/ 7851]
loss: 4.245350  [ 4758/ 7851]
loss: 7.209034  [ 5226/ 7851]
loss: 8.622532  [ 5694/ 7851]
loss: 4.195910  [ 6162/ 7851]
loss: 4.354420  [ 6630/ 7851]
loss: 7.473371  [ 7098/ 7851]
loss: 7.465834  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.998321 
Epoch 3
-------------------------------
loss: 5.584114  [   79/ 7851]
loss: 7.619022  [  547/ 7851]
loss: 5.919513  [ 1015/ 7851]
loss: 5.564282  [ 1483/ 7851]
loss: 5.788445  [ 1951/ 7851]
loss: 5.675279  [ 2419/ 7851]
loss: 5.871458  [ 2887/ 7851]
loss: 5.041041  [ 3355/ 7851]
loss: 8.380604  [ 3823/ 7851]
loss: 8.243132  [ 4290/ 7851]
loss: 4.233392  [ 4758/ 7851]
loss: 7.143957  [ 5226/ 7851]
loss: 8.626454  [ 5694/ 7851]
loss: 4.199505  [ 6162/ 7851]
loss: 4.310096  [ 6630/ 7851]
loss: 7.423134  [ 7098/ 7851]
loss: 7.463841  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.963118 
Epoch 4
-------------------------------
loss: 5.528287  [   79/ 7851]
loss: 7.597997  [  547/ 7851]
loss: 5.914634  [ 1015/ 7851]
loss: 5.564873  [ 1483/ 7851]
loss: 5.785825  [ 1951/ 7851]
loss: 5.682757  [ 2419/ 7851]
loss: 5.868855  [ 2887/ 7851]
loss: 5.041753  [ 3355/ 7851]
loss: 8.370275  [ 3823/ 7851]
loss: 8.247057  [ 4290/ 7851]
loss: 4.228545  [ 4758/ 7851]
loss: 7.125706  [ 5226/ 7851]
loss: 8.628227  [ 5694/ 7851]
loss: 4.197680  [ 6162/ 7851]
loss: 4.295491  [ 6630/ 7851]
loss: 7.410538  [ 7098/ 7851]
loss: 7.464298  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.952652 
Epoch 5
-------------------------------
loss: 5.511484  [   79/ 7851]
loss: 7.593349  [  547/ 7851]
loss: 5.913493  [ 1015/ 7851]
loss: 5.565069  [ 1483/ 7851]
loss: 5.785494  [ 1951/ 7851]
loss: 5.684711  [ 2419/ 7851]
loss: 5.867457  [ 2887/ 7851]
loss: 5.041879  [ 3355/ 7851]
loss: 8.366681  [ 3823/ 7851]
loss: 8.247902  [ 4290/ 7851]
loss: 4.226561  [ 4758/ 7851]
loss: 7.118811  [ 5226/ 7851]
loss: 8.628963  [ 5694/ 7851]
loss: 4.196527  [ 6162/ 7851]
loss: 4.289543  [ 6630/ 7851]
loss: 7.405819  [ 7098/ 7851]
loss: 7.464732  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.948436 
Epoch 6
-------------------------------
loss: 5.504666  [   79/ 7851]
loss: 7.591751  [  547/ 7851]
loss: 5.913015  [ 1015/ 7851]
loss: 5.565130  [ 1483/ 7851]
loss: 5.785504  [ 1951/ 7851]
loss: 5.685468  [ 2419/ 7851]
loss: 5.866706  [ 2887/ 7851]
loss: 5.041874  [ 3355/ 7851]
loss: 8.364930  [ 3823/ 7851]
loss: 8.248210  [ 4290/ 7851]
loss: 4.225552  [ 4758/ 7851]
loss: 7.115442  [ 5226/ 7851]
loss: 8.629328  [ 5694/ 7851]
loss: 4.195823  [ 6162/ 7851]
loss: 4.286555  [ 6630/ 7851]
loss: 7.403578  [ 7098/ 7851]
loss: 7.465050  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.946344 
Epoch 7
-------------------------------
loss: 5.501275  [   79/ 7851]
loss: 7.591069  [  547/ 7851]
loss: 5.912773  [ 1015/ 7851]
loss: 5.565148  [ 1483/ 7851]
loss: 5.785573  [ 1951/ 7851]
loss: 5.685815  [ 2419/ 7851]
loss: 5.866258  [ 2887/ 7851]
loss: 5.041842  [ 3355/ 7851]
loss: 8.363927  [ 3823/ 7851]
loss: 8.248347  [ 4290/ 7851]
loss: 4.224964  [ 4758/ 7851]
loss: 7.113543  [ 5226/ 7851]
loss: 8.629531  [ 5694/ 7851]
loss: 4.195365  [ 6162/ 7851]
loss: 4.284856  [ 6630/ 7851]
loss: 7.402369  [ 7098/ 7851]
loss: 7.465278  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.945176 
Epoch 8
-------------------------------
loss: 5.499381  [   79/ 7851]
loss: 7.590752  [  547/ 7851]
loss: 5.912639  [ 1015/ 7851]
loss: 5.565149  [ 1483/ 7851]
loss: 5.785646  [ 1951/ 7851]
loss: 5.685985  [ 2419/ 7851]
loss: 5.865970  [ 2887/ 7851]
loss: 5.041807  [ 3355/ 7851]
loss: 8.363295  [ 3823/ 7851]
loss: 8.248415  [ 4290/ 7851]
loss: 4.224588  [ 4758/ 7851]
loss: 7.112371  [ 5226/ 7851]
loss: 8.629655  [ 5694/ 7851]
loss: 4.195049  [ 6162/ 7851]
loss: 4.283811  [ 6630/ 7851]
loss: 7.401666  [ 7098/ 7851]
loss: 7.465446  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.944475 
Epoch 9
-------------------------------
loss: 5.498243  [   79/ 7851]
loss: 7.590599  [  547/ 7851]
loss: 5.912561  [ 1015/ 7851]
loss: 5.565145  [ 1483/ 7851]
loss: 5.785711  [ 1951/ 7851]
loss: 5.686071  [ 2419/ 7851]
loss: 5.865771  [ 2887/ 7851]
loss: 5.041777  [ 3355/ 7851]
loss: 8.362871  [ 3823/ 7851]
loss: 8.248449  [ 4290/ 7851]
loss: 4.224335  [ 4758/ 7851]
loss: 7.111599  [ 5226/ 7851]
loss: 8.629733  [ 5694/ 7851]
loss: 4.194821  [ 6162/ 7851]
loss: 4.283131  [ 6630/ 7851]
loss: 7.401234  [ 7098/ 7851]
loss: 7.465574  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.944032 
Epoch 10
-------------------------------
loss: 5.497526  [   79/ 7851]
loss: 7.590530  [  547/ 7851]
loss: 5.912514  [ 1015/ 7851]
loss: 5.565140  [ 1483/ 7851]
loss: 5.785764  [ 1951/ 7851]
loss: 5.686110  [ 2419/ 7851]
loss: 5.865631  [ 2887/ 7851]
loss: 5.041751  [ 3355/ 7851]
loss: 8.362572  [ 3823/ 7851]
loss: 8.248467  [ 4290/ 7851]
loss: 4.224154  [ 4758/ 7851]
loss: 7.111068  [ 5226/ 7851]
loss: 8.629786  [ 5694/ 7851]
loss: 4.194652  [ 6162/ 7851]
loss: 4.282670  [ 6630/ 7851]
loss: 7.400959  [ 7098/ 7851]
loss: 7.465672  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943743 
Epoch 11
-------------------------------
loss: 5.497057  [   79/ 7851]
loss: 7.590503  [  547/ 7851]
loss: 5.912487  [ 1015/ 7851]
loss: 5.565134  [ 1483/ 7851]
loss: 5.785809  [ 1951/ 7851]
loss: 5.686127  [ 2419/ 7851]
loss: 5.865526  [ 2887/ 7851]
loss: 5.041729  [ 3355/ 7851]
loss: 8.362355  [ 3823/ 7851]
loss: 8.248474  [ 4290/ 7851]
loss: 4.224022  [ 4758/ 7851]
loss: 7.110689  [ 5226/ 7851]
loss: 8.629820  [ 5694/ 7851]
loss: 4.194521  [ 6162/ 7851]
loss: 4.282348  [ 6630/ 7851]
loss: 7.400782  [ 7098/ 7851]
loss: 7.465748  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943548 
Epoch 12
-------------------------------
loss: 5.496744  [   79/ 7851]
loss: 7.590501  [  547/ 7851]
loss: 5.912470  [ 1015/ 7851]
loss: 5.565128  [ 1483/ 7851]
loss: 5.785847  [ 1951/ 7851]
loss: 5.686128  [ 2419/ 7851]
loss: 5.865447  [ 2887/ 7851]
loss: 5.041712  [ 3355/ 7851]
loss: 8.362192  [ 3823/ 7851]
loss: 8.248478  [ 4290/ 7851]
loss: 4.223922  [ 4758/ 7851]
loss: 7.110410  [ 5226/ 7851]
loss: 8.629844  [ 5694/ 7851]
loss: 4.194419  [ 6162/ 7851]
loss: 4.282118  [ 6630/ 7851]
loss: 7.400667  [ 7098/ 7851]
loss: 7.465808  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943416 
Epoch 13
-------------------------------
loss: 5.496531  [   79/ 7851]
loss: 7.590512  [  547/ 7851]
loss: 5.912460  [ 1015/ 7851]
loss: 5.565123  [ 1483/ 7851]
loss: 5.785879  [ 1951/ 7851]
loss: 5.686122  [ 2419/ 7851]
loss: 5.865384  [ 2887/ 7851]
loss: 5.041698  [ 3355/ 7851]
loss: 8.362068  [ 3823/ 7851]
loss: 8.248476  [ 4290/ 7851]
loss: 4.223845  [ 4758/ 7851]
loss: 7.110201  [ 5226/ 7851]
loss: 8.629860  [ 5694/ 7851]
loss: 4.194338  [ 6162/ 7851]
loss: 4.281949  [ 6630/ 7851]
loss: 7.400591  [ 7098/ 7851]
loss: 7.465856  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943326 
Epoch 14
-------------------------------
loss: 5.496387  [   79/ 7851]
loss: 7.590530  [  547/ 7851]
loss: 5.912457  [ 1015/ 7851]
loss: 5.565119  [ 1483/ 7851]
loss: 5.785905  [ 1951/ 7851]
loss: 5.686110  [ 2419/ 7851]
loss: 5.865335  [ 2887/ 7851]
loss: 5.041686  [ 3355/ 7851]
loss: 8.361972  [ 3823/ 7851]
loss: 8.248474  [ 4290/ 7851]
loss: 4.223784  [ 4758/ 7851]
loss: 7.110042  [ 5226/ 7851]
loss: 8.629871  [ 5694/ 7851]
loss: 4.194272  [ 6162/ 7851]
loss: 4.281825  [ 6630/ 7851]
loss: 7.400543  [ 7098/ 7851]
loss: 7.465896  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943263 
Epoch 15
-------------------------------
loss: 5.496287  [   79/ 7851]
loss: 7.590553  [  547/ 7851]
loss: 5.912456  [ 1015/ 7851]
loss: 5.565116  [ 1483/ 7851]
loss: 5.785928  [ 1951/ 7851]
loss: 5.686098  [ 2419/ 7851]
loss: 5.865295  [ 2887/ 7851]
loss: 5.041675  [ 3355/ 7851]
loss: 8.361896  [ 3823/ 7851]
loss: 8.248470  [ 4290/ 7851]
loss: 4.223737  [ 4758/ 7851]
loss: 7.109918  [ 5226/ 7851]
loss: 8.629878  [ 5694/ 7851]
loss: 4.194218  [ 6162/ 7851]
loss: 4.281732  [ 6630/ 7851]
loss: 7.400512  [ 7098/ 7851]
loss: 7.465929  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943220 
Epoch 16
-------------------------------
loss: 5.496219  [   79/ 7851]
loss: 7.590575  [  547/ 7851]
loss: 5.912457  [ 1015/ 7851]
loss: 5.565113  [ 1483/ 7851]
loss: 5.785947  [ 1951/ 7851]
loss: 5.686083  [ 2419/ 7851]
loss: 5.865263  [ 2887/ 7851]
loss: 5.041667  [ 3355/ 7851]
loss: 8.361835  [ 3823/ 7851]
loss: 8.248466  [ 4290/ 7851]
loss: 4.223698  [ 4758/ 7851]
loss: 7.109821  [ 5226/ 7851]
loss: 8.629884  [ 5694/ 7851]
loss: 4.194172  [ 6162/ 7851]
loss: 4.281662  [ 6630/ 7851]
loss: 7.400495  [ 7098/ 7851]
loss: 7.465955  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943192 
Epoch 17
-------------------------------
loss: 5.496174  [   79/ 7851]
loss: 7.590599  [  547/ 7851]
loss: 5.912459  [ 1015/ 7851]
loss: 5.565110  [ 1483/ 7851]
loss: 5.785963  [ 1951/ 7851]
loss: 5.686069  [ 2419/ 7851]
loss: 5.865236  [ 2887/ 7851]
loss: 5.041660  [ 3355/ 7851]
loss: 8.361787  [ 3823/ 7851]
loss: 8.248461  [ 4290/ 7851]
loss: 4.223666  [ 4758/ 7851]
loss: 7.109743  [ 5226/ 7851]
loss: 8.629888  [ 5694/ 7851]
loss: 4.194135  [ 6162/ 7851]
loss: 4.281609  [ 6630/ 7851]
loss: 7.400484  [ 7098/ 7851]
loss: 7.465978  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943172 
Epoch 18
-------------------------------
loss: 5.496146  [   79/ 7851]
loss: 7.590621  [  547/ 7851]
loss: 5.912462  [ 1015/ 7851]
loss: 5.565108  [ 1483/ 7851]
loss: 5.785976  [ 1951/ 7851]
loss: 5.686055  [ 2419/ 7851]
loss: 5.865214  [ 2887/ 7851]
loss: 5.041655  [ 3355/ 7851]
loss: 8.361746  [ 3823/ 7851]
loss: 8.248457  [ 4290/ 7851]
loss: 4.223639  [ 4758/ 7851]
loss: 7.109680  [ 5226/ 7851]
loss: 8.629889  [ 5694/ 7851]
loss: 4.194102  [ 6162/ 7851]
loss: 4.281568  [ 6630/ 7851]
loss: 7.400482  [ 7098/ 7851]
loss: 7.465997  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943161 
Epoch 19
-------------------------------
loss: 5.496128  [   79/ 7851]
loss: 7.590643  [  547/ 7851]
loss: 5.912466  [ 1015/ 7851]
loss: 5.565105  [ 1483/ 7851]
loss: 5.785988  [ 1951/ 7851]
loss: 5.686041  [ 2419/ 7851]
loss: 5.865195  [ 2887/ 7851]
loss: 5.041650  [ 3355/ 7851]
loss: 8.361712  [ 3823/ 7851]
loss: 8.248452  [ 4290/ 7851]
loss: 4.223618  [ 4758/ 7851]
loss: 7.109630  [ 5226/ 7851]
loss: 8.629891  [ 5694/ 7851]
loss: 4.194075  [ 6162/ 7851]
loss: 4.281537  [ 6630/ 7851]
loss: 7.400483  [ 7098/ 7851]
loss: 7.466012  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943154 
Epoch 20
-------------------------------
loss: 5.496118  [   79/ 7851]
loss: 7.590663  [  547/ 7851]
loss: 5.912470  [ 1015/ 7851]
loss: 5.565104  [ 1483/ 7851]
loss: 5.785999  [ 1951/ 7851]
loss: 5.686028  [ 2419/ 7851]
loss: 5.865180  [ 2887/ 7851]
loss: 5.041645  [ 3355/ 7851]
loss: 8.361686  [ 3823/ 7851]
loss: 8.248448  [ 4290/ 7851]
loss: 4.223599  [ 4758/ 7851]
loss: 7.109589  [ 5226/ 7851]
loss: 8.629891  [ 5694/ 7851]
loss: 4.194052  [ 6162/ 7851]
loss: 4.281513  [ 6630/ 7851]
loss: 7.400486  [ 7098/ 7851]
loss: 7.466026  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.943152 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 80]                 32,080
==========================================================================================
Total params: 64,480
Trainable params: 64,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.45
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.38
Params size (MB): 0.26
Estimated Total Size (MB): 0.67
==========================================================================================
Epoch 1
-------------------------------
loss: 19.874321  [   79/ 7851]
loss: 98.656677  [  547/ 7851]
loss: 6.598869  [ 1015/ 7851]
loss: 4.844141  [ 1483/ 7851]
loss: 4.824562  [ 1951/ 7851]
loss: 6.808671  [ 2419/ 7851]
loss: 4.581545  [ 2887/ 7851]
loss: 5.151647  [ 3355/ 7851]
loss: 6.615545  [ 3823/ 7851]
loss: 6.344416  [ 4290/ 7851]
loss: 8.210082  [ 4758/ 7851]
loss: 7.775941  [ 5226/ 7851]
loss: 6.793006  [ 5694/ 7851]
loss: 6.745081  [ 6162/ 7851]
loss: 6.069460  [ 6630/ 7851]
loss: 6.374713  [ 7098/ 7851]
loss: 6.987391  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.0%, Avg loss: 7.304753 
Epoch 2
-------------------------------
loss: 9.030246  [   79/ 7851]
loss: 6.515208  [  547/ 7851]
loss: 5.047770  [ 1015/ 7851]
loss: 4.550199  [ 1483/ 7851]
loss: 4.825259  [ 1951/ 7851]
loss: 6.804440  [ 2419/ 7851]
loss: 4.610488  [ 2887/ 7851]
loss: 5.200940  [ 3355/ 7851]
loss: 6.638023  [ 3823/ 7851]
loss: 6.344937  [ 4290/ 7851]
loss: 8.132892  [ 4758/ 7851]
loss: 7.783237  [ 5226/ 7851]
loss: 6.787604  [ 5694/ 7851]
loss: 6.724974  [ 6162/ 7851]
loss: 6.015093  [ 6630/ 7851]
loss: 6.370518  [ 7098/ 7851]
loss: 6.983077  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.320075 
Epoch 3
-------------------------------
loss: 9.081126  [   79/ 7851]
loss: 6.550549  [  547/ 7851]
loss: 5.071530  [ 1015/ 7851]
loss: 4.519092  [ 1483/ 7851]
loss: 4.917123  [ 1951/ 7851]
loss: 6.829147  [ 2419/ 7851]
loss: 4.579153  [ 2887/ 7851]
loss: 5.303864  [ 3355/ 7851]
loss: 6.731034  [ 3823/ 7851]
loss: 29.613403  [ 4290/ 7851]
loss: 8.143361  [ 4758/ 7851]
loss: 7.796313  [ 5226/ 7851]
loss: 6.802201  [ 5694/ 7851]
loss: 6.731531  [ 6162/ 7851]
loss: 6.001786  [ 6630/ 7851]
loss: 6.364138  [ 7098/ 7851]
loss: 6.992706  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.316798 
Epoch 4
-------------------------------
loss: 9.072012  [   79/ 7851]
loss: 6.549748  [  547/ 7851]
loss: 5.072360  [ 1015/ 7851]
loss: 4.519176  [ 1483/ 7851]
loss: 5.010940  [ 1951/ 7851]
loss: 6.829445  [ 2419/ 7851]
loss: 4.560309  [ 2887/ 7851]
loss: 5.359705  [ 3355/ 7851]
loss: 6.741592  [ 3823/ 7851]
loss: 6.369543  [ 4290/ 7851]
loss: 8.161374  [ 4758/ 7851]
loss: 7.771329  [ 5226/ 7851]
loss: 6.787352  [ 5694/ 7851]
loss: 6.727799  [ 6162/ 7851]
loss: 6.033111  [ 6630/ 7851]
loss: 6.371776  [ 7098/ 7851]
loss: 6.982293  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312368 
Epoch 5
-------------------------------
loss: 9.059742  [   79/ 7851]
loss: 6.542404  [  547/ 7851]
loss: 5.136847  [ 1015/ 7851]
loss: 4.516078  [ 1483/ 7851]
loss: 4.809789  [ 1951/ 7851]
loss: 6.818698  [ 2419/ 7851]
loss: 4.561229  [ 2887/ 7851]
loss: 5.301278  [ 3355/ 7851]
loss: 6.686396  [ 3823/ 7851]
loss: 6.348258  [ 4290/ 7851]
loss: 8.155781  [ 4758/ 7851]
loss: 7.768800  [ 5226/ 7851]
loss: 6.788082  [ 5694/ 7851]
loss: 6.722839  [ 6162/ 7851]
loss: 6.006748  [ 6630/ 7851]
loss: 6.368015  [ 7098/ 7851]
loss: 6.985111  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.317208 
Epoch 6
-------------------------------
loss: 9.075270  [   79/ 7851]
loss: 6.547046  [  547/ 7851]
loss: 5.074033  [ 1015/ 7851]
loss: 4.520244  [ 1483/ 7851]
loss: 4.913545  [ 1951/ 7851]
loss: 6.824171  [ 2419/ 7851]
loss: 4.568829  [ 2887/ 7851]
loss: 5.313434  [ 3355/ 7851]
loss: 6.709686  [ 3823/ 7851]
loss: 6.362321  [ 4290/ 7851]
loss: 8.162514  [ 4758/ 7851]
loss: 7.768517  [ 5226/ 7851]
loss: 6.786120  [ 5694/ 7851]
loss: 6.726670  [ 6162/ 7851]
loss: 6.001394  [ 6630/ 7851]
loss: 6.372274  [ 7098/ 7851]
loss: 6.975638  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.319695 
Epoch 7
-------------------------------
loss: 9.084048  [   79/ 7851]
loss: 6.544644  [  547/ 7851]
loss: 5.078548  [ 1015/ 7851]
loss: 4.521496  [ 1483/ 7851]
loss: 4.915430  [ 1951/ 7851]
loss: 6.824065  [ 2419/ 7851]
loss: 4.567932  [ 2887/ 7851]
loss: 5.315945  [ 3355/ 7851]
loss: 6.709938  [ 3823/ 7851]
loss: 6.361916  [ 4290/ 7851]
loss: 8.161899  [ 4758/ 7851]
loss: 7.768763  [ 5226/ 7851]
loss: 6.786153  [ 5694/ 7851]
loss: 6.726620  [ 6162/ 7851]
loss: 6.035378  [ 6630/ 7851]
loss: 6.372814  [ 7098/ 7851]
loss: 6.981437  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.312662 
Epoch 8
-------------------------------
loss: 9.062003  [   79/ 7851]
loss: 6.542851  [  547/ 7851]
loss: 5.076137  [ 1015/ 7851]
loss: 4.520646  [ 1483/ 7851]
loss: 4.912401  [ 1951/ 7851]
loss: 6.823104  [ 2419/ 7851]
loss: 4.567922  [ 2887/ 7851]
loss: 5.315635  [ 3355/ 7851]
loss: 6.708980  [ 3823/ 7851]
loss: 6.361466  [ 4290/ 7851]
loss: 8.161698  [ 4758/ 7851]
loss: 7.768759  [ 5226/ 7851]
loss: 6.786095  [ 5694/ 7851]
loss: 6.726576  [ 6162/ 7851]
loss: 6.035273  [ 6630/ 7851]
loss: 6.372832  [ 7098/ 7851]
loss: 6.981472  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.312709 
Epoch 9
-------------------------------
loss: 9.062393  [   79/ 7851]
loss: 6.542871  [  547/ 7851]
loss: 5.076064  [ 1015/ 7851]
loss: 4.520704  [ 1483/ 7851]
loss: 4.912735  [ 1951/ 7851]
loss: 6.822983  [ 2419/ 7851]
loss: 4.567885  [ 2887/ 7851]
loss: 5.316020  [ 3355/ 7851]
loss: 6.708913  [ 3823/ 7851]
loss: 6.361429  [ 4290/ 7851]
loss: 8.161664  [ 4758/ 7851]
loss: 7.768761  [ 5226/ 7851]
loss: 6.786071  [ 5694/ 7851]
loss: 6.726589  [ 6162/ 7851]
loss: 6.035332  [ 6630/ 7851]
loss: 6.372853  [ 7098/ 7851]
loss: 6.981506  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312721 
Epoch 10
-------------------------------
loss: 9.062593  [   79/ 7851]
loss: 6.542879  [  547/ 7851]
loss: 5.076005  [ 1015/ 7851]
loss: 4.520744  [ 1483/ 7851]
loss: 4.912979  [ 1951/ 7851]
loss: 6.822890  [ 2419/ 7851]
loss: 4.567861  [ 2887/ 7851]
loss: 5.316302  [ 3355/ 7851]
loss: 6.708860  [ 3823/ 7851]
loss: 6.361403  [ 4290/ 7851]
loss: 8.161642  [ 4758/ 7851]
loss: 7.768761  [ 5226/ 7851]
loss: 6.786055  [ 5694/ 7851]
loss: 6.726601  [ 6162/ 7851]
loss: 6.035392  [ 6630/ 7851]
loss: 6.372869  [ 7098/ 7851]
loss: 6.981532  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312731 
Epoch 11
-------------------------------
loss: 9.062743  [   79/ 7851]
loss: 6.542885  [  547/ 7851]
loss: 5.075955  [ 1015/ 7851]
loss: 4.520776  [ 1483/ 7851]
loss: 4.913172  [ 1951/ 7851]
loss: 6.822819  [ 2419/ 7851]
loss: 4.567844  [ 2887/ 7851]
loss: 5.316514  [ 3355/ 7851]
loss: 6.708821  [ 3823/ 7851]
loss: 6.361384  [ 4290/ 7851]
loss: 8.161629  [ 4758/ 7851]
loss: 7.768761  [ 5226/ 7851]
loss: 6.786043  [ 5694/ 7851]
loss: 6.726611  [ 6162/ 7851]
loss: 6.035449  [ 6630/ 7851]
loss: 6.372883  [ 7098/ 7851]
loss: 6.981554  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312738 
Epoch 12
-------------------------------
loss: 9.062859  [   79/ 7851]
loss: 6.542892  [  547/ 7851]
loss: 5.075914  [ 1015/ 7851]
loss: 4.520031  [ 1483/ 7851]
loss: 4.907915  [ 1951/ 7851]
loss: 6.822318  [ 2419/ 7851]
loss: 4.569920  [ 2887/ 7851]
loss: 5.311030  [ 3355/ 7851]
loss: 6.709231  [ 3823/ 7851]
loss: 6.361818  [ 4290/ 7851]
loss: 8.161896  [ 4758/ 7851]
loss: 7.768641  [ 5226/ 7851]
loss: 6.785927  [ 5694/ 7851]
loss: 6.726667  [ 6162/ 7851]
loss: 6.036041  [ 6630/ 7851]
loss: 6.372853  [ 7098/ 7851]
loss: 6.981856  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312823 
Epoch 13
-------------------------------
loss: 9.063235  [   79/ 7851]
loss: 6.542898  [  547/ 7851]
loss: 5.075699  [ 1015/ 7851]
loss: 4.520875  [ 1483/ 7851]
loss: 4.913853  [ 1951/ 7851]
loss: 6.822545  [ 2419/ 7851]
loss: 4.567773  [ 2887/ 7851]
loss: 5.317345  [ 3355/ 7851]
loss: 6.708916  [ 3823/ 7851]
loss: 6.361381  [ 4290/ 7851]
loss: 8.161557  [ 4758/ 7851]
loss: 7.768795  [ 5226/ 7851]
loss: 6.786003  [ 5694/ 7851]
loss: 6.726630  [ 6162/ 7851]
loss: 6.035545  [ 6630/ 7851]
loss: 6.372888  [ 7098/ 7851]
loss: 6.981681  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312821 
Epoch 14
-------------------------------
loss: 9.063420  [   79/ 7851]
loss: 6.542930  [  547/ 7851]
loss: 5.075756  [ 1015/ 7851]
loss: 4.520894  [ 1483/ 7851]
loss: 4.913894  [ 1951/ 7851]
loss: 6.822556  [ 2419/ 7851]
loss: 4.567774  [ 2887/ 7851]
loss: 5.317364  [ 3355/ 7851]
loss: 6.708873  [ 3823/ 7851]
loss: 6.361371  [ 4290/ 7851]
loss: 8.161565  [ 4758/ 7851]
loss: 7.768787  [ 5226/ 7851]
loss: 6.786000  [ 5694/ 7851]
loss: 6.726636  [ 6162/ 7851]
loss: 6.035593  [ 6630/ 7851]
loss: 6.372899  [ 7098/ 7851]
loss: 6.981678  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312814 
Epoch 15
-------------------------------
loss: 9.063414  [   79/ 7851]
loss: 6.542931  [  547/ 7851]
loss: 5.075746  [ 1015/ 7851]
loss: 4.520897  [ 1483/ 7851]
loss: 4.913931  [ 1951/ 7851]
loss: 6.822545  [ 2419/ 7851]
loss: 4.567778  [ 2887/ 7851]
loss: 5.317379  [ 3355/ 7851]
loss: 6.708843  [ 3823/ 7851]
loss: 6.361362  [ 4290/ 7851]
loss: 8.161571  [ 4758/ 7851]
loss: 7.768781  [ 5226/ 7851]
loss: 6.785997  [ 5694/ 7851]
loss: 6.726641  [ 6162/ 7851]
loss: 6.035633  [ 6630/ 7851]
loss: 6.372908  [ 7098/ 7851]
loss: 6.981676  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312808 
Epoch 16
-------------------------------
loss: 9.063409  [   79/ 7851]
loss: 6.542931  [  547/ 7851]
loss: 5.075737  [ 1015/ 7851]
loss: 4.520899  [ 1483/ 7851]
loss: 4.913963  [ 1951/ 7851]
loss: 6.822537  [ 2419/ 7851]
loss: 4.567782  [ 2887/ 7851]
loss: 5.317389  [ 3355/ 7851]
loss: 6.708817  [ 3823/ 7851]
loss: 6.361356  [ 4290/ 7851]
loss: 8.161578  [ 4758/ 7851]
loss: 7.768775  [ 5226/ 7851]
loss: 6.785995  [ 5694/ 7851]
loss: 6.726645  [ 6162/ 7851]
loss: 6.035671  [ 6630/ 7851]
loss: 6.372916  [ 7098/ 7851]
loss: 6.981674  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312804 
Epoch 17
-------------------------------
loss: 9.063404  [   79/ 7851]
loss: 6.542931  [  547/ 7851]
loss: 5.075728  [ 1015/ 7851]
loss: 4.520901  [ 1483/ 7851]
loss: 4.913990  [ 1951/ 7851]
loss: 6.822532  [ 2419/ 7851]
loss: 4.567786  [ 2887/ 7851]
loss: 5.317397  [ 3355/ 7851]
loss: 6.708795  [ 3823/ 7851]
loss: 6.361352  [ 4290/ 7851]
loss: 8.161585  [ 4758/ 7851]
loss: 7.768769  [ 5226/ 7851]
loss: 6.785993  [ 5694/ 7851]
loss: 6.726650  [ 6162/ 7851]
loss: 6.035705  [ 6630/ 7851]
loss: 6.372924  [ 7098/ 7851]
loss: 6.981672  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312799 
Epoch 18
-------------------------------
loss: 9.063399  [   79/ 7851]
loss: 6.542931  [  547/ 7851]
loss: 5.075720  [ 1015/ 7851]
loss: 4.520902  [ 1483/ 7851]
loss: 4.914014  [ 1951/ 7851]
loss: 6.822527  [ 2419/ 7851]
loss: 4.567790  [ 2887/ 7851]
loss: 5.317403  [ 3355/ 7851]
loss: 6.708777  [ 3823/ 7851]
loss: 6.361347  [ 4290/ 7851]
loss: 8.161591  [ 4758/ 7851]
loss: 7.768764  [ 5226/ 7851]
loss: 6.785991  [ 5694/ 7851]
loss: 6.726653  [ 6162/ 7851]
loss: 6.035736  [ 6630/ 7851]
loss: 6.372931  [ 7098/ 7851]
loss: 6.981670  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312796 
Epoch 19
-------------------------------
loss: 9.063395  [   79/ 7851]
loss: 6.542931  [  547/ 7851]
loss: 5.075714  [ 1015/ 7851]
loss: 4.520903  [ 1483/ 7851]
loss: 4.914035  [ 1951/ 7851]
loss: 6.822523  [ 2419/ 7851]
loss: 4.567792  [ 2887/ 7851]
loss: 5.317408  [ 3355/ 7851]
loss: 6.708763  [ 3823/ 7851]
loss: 6.361344  [ 4290/ 7851]
loss: 8.161596  [ 4758/ 7851]
loss: 7.768759  [ 5226/ 7851]
loss: 6.785990  [ 5694/ 7851]
loss: 6.726656  [ 6162/ 7851]
loss: 6.035764  [ 6630/ 7851]
loss: 6.372937  [ 7098/ 7851]
loss: 6.981669  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312793 
Epoch 20
-------------------------------
loss: 9.063392  [   79/ 7851]
loss: 6.542932  [  547/ 7851]
loss: 5.075708  [ 1015/ 7851]
loss: 4.520904  [ 1483/ 7851]
loss: 4.914053  [ 1951/ 7851]
loss: 6.822520  [ 2419/ 7851]
loss: 4.567796  [ 2887/ 7851]
loss: 5.317410  [ 3355/ 7851]
loss: 6.708749  [ 3823/ 7851]
loss: 6.361341  [ 4290/ 7851]
loss: 8.161602  [ 4758/ 7851]
loss: 7.768755  [ 5226/ 7851]
loss: 6.785989  [ 5694/ 7851]
loss: 6.726659  [ 6162/ 7851]
loss: 6.035789  [ 6630/ 7851]
loss: 6.372941  [ 7098/ 7851]
loss: 6.981667  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 7.312790 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 80]                 32,080
==========================================================================================
Total params: 64,480
Trainable params: 64,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.45
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.38
Params size (MB): 0.26
Estimated Total Size (MB): 0.67
==========================================================================================
Epoch 1
-------------------------------
loss: 15.944156  [   79/ 7851]
loss: 68.118576  [  547/ 7851]
loss: 7.073968  [ 1015/ 7851]
loss: 5.528735  [ 1483/ 7851]
loss: 6.523209  [ 1951/ 7851]
loss: 5.815609  [ 2419/ 7851]
loss: 5.554144  [ 2887/ 7851]
loss: 6.580015  [ 3355/ 7851]
loss: 8.846163  [ 3823/ 7851]
loss: 10.024332  [ 4290/ 7851]
loss: 4.557058  [ 4758/ 7851]
loss: 6.646152  [ 5226/ 7851]
loss: 6.545105  [ 5694/ 7851]
loss: 6.763652  [ 6162/ 7851]
loss: 9.919933  [ 6630/ 7851]
loss: 3.291940  [ 7098/ 7851]
loss: 9.771217  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.661136 
Epoch 2
-------------------------------
loss: 6.420697  [   79/ 7851]
loss: 16.426455  [  547/ 7851]
loss: 6.493490  [ 1015/ 7851]
loss: 5.831931  [ 1483/ 7851]
loss: 6.473169  [ 1951/ 7851]
loss: 5.809497  [ 2419/ 7851]
loss: 5.600667  [ 2887/ 7851]
loss: 6.585494  [ 3355/ 7851]
loss: 7.633171  [ 3823/ 7851]
loss: 10.021604  [ 4290/ 7851]
loss: 4.543736  [ 4758/ 7851]
loss: 6.636053  [ 5226/ 7851]
loss: 6.545264  [ 5694/ 7851]
loss: 6.775561  [ 6162/ 7851]
loss: 9.993928  [ 6630/ 7851]
loss: 3.303556  [ 7098/ 7851]
loss: 8.945682  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.659589 
Epoch 3
-------------------------------
loss: 5.992429  [   79/ 7851]
loss: 6.624315  [  547/ 7851]
loss: 6.614028  [ 1015/ 7851]
loss: 5.562237  [ 1483/ 7851]
loss: 6.480553  [ 1951/ 7851]
loss: 5.767745  [ 2419/ 7851]
loss: 5.575049  [ 2887/ 7851]
loss: 6.595075  [ 3355/ 7851]
loss: 7.628291  [ 3823/ 7851]
loss: 10.031189  [ 4290/ 7851]
loss: 4.532935  [ 4758/ 7851]
loss: 6.641310  [ 5226/ 7851]
loss: 6.545311  [ 5694/ 7851]
loss: 6.779333  [ 6162/ 7851]
loss: 9.973733  [ 6630/ 7851]
loss: 3.290741  [ 7098/ 7851]
loss: 8.983665  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 7.679564 
Epoch 4
-------------------------------
loss: 5.943468  [   79/ 7851]
loss: 6.612557  [  547/ 7851]
loss: 6.643105  [ 1015/ 7851]
loss: 5.541286  [ 1483/ 7851]
loss: 6.485250  [ 1951/ 7851]
loss: 5.764736  [ 2419/ 7851]
loss: 5.575068  [ 2887/ 7851]
loss: 6.602781  [ 3355/ 7851]
loss: 7.626685  [ 3823/ 7851]
loss: 10.036568  [ 4290/ 7851]
loss: 4.529665  [ 4758/ 7851]
loss: 6.636247  [ 5226/ 7851]
loss: 6.545269  [ 5694/ 7851]
loss: 6.810491  [ 6162/ 7851]
loss: 9.963582  [ 6630/ 7851]
loss: 3.291602  [ 7098/ 7851]
loss: 8.976661  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 7.678603 
Epoch 5
-------------------------------
loss: 5.944691  [   79/ 7851]
loss: 6.600730  [  547/ 7851]
loss: 6.647989  [ 1015/ 7851]
loss: 5.538036  [ 1483/ 7851]
loss: 6.487825  [ 1951/ 7851]
loss: 5.763878  [ 2419/ 7851]
loss: 5.575640  [ 2887/ 7851]
loss: 6.608233  [ 3355/ 7851]
loss: 7.625605  [ 3823/ 7851]
loss: 10.039180  [ 4290/ 7851]
loss: 4.528324  [ 4758/ 7851]
loss: 6.632424  [ 5226/ 7851]
loss: 6.545242  [ 5694/ 7851]
loss: 6.815627  [ 6162/ 7851]
loss: 9.956494  [ 6630/ 7851]
loss: 3.286640  [ 7098/ 7851]
loss: 8.976693  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 7.684233 
Epoch 6
-------------------------------
loss: 5.934235  [   79/ 7851]
loss: 6.590695  [  547/ 7851]
loss: 6.652795  [ 1015/ 7851]
loss: 5.533816  [ 1483/ 7851]
loss: 6.490449  [ 1951/ 7851]
loss: 5.763424  [ 2419/ 7851]
loss: 5.576237  [ 2887/ 7851]
loss: 6.612503  [ 3355/ 7851]
loss: 7.624723  [ 3823/ 7851]
loss: 10.040782  [ 4290/ 7851]
loss: 4.527574  [ 4758/ 7851]
loss: 6.626185  [ 5226/ 7851]
loss: 6.543643  [ 5694/ 7851]
loss: 6.826308  [ 6162/ 7851]
loss: 10.059409  [ 6630/ 7851]
loss: 3.297096  [ 7098/ 7851]
loss: 8.907362  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 7.673182 
Epoch 7
-------------------------------
loss: 5.957507  [   79/ 7851]
loss: 6.578373  [  547/ 7851]
loss: 6.640129  [ 1015/ 7851]
loss: 5.532186  [ 1483/ 7851]
loss: 6.490205  [ 1951/ 7851]
loss: 5.763806  [ 2419/ 7851]
loss: 5.575117  [ 2887/ 7851]
loss: 6.615287  [ 3355/ 7851]
loss: 7.624038  [ 3823/ 7851]
loss: 10.042203  [ 4290/ 7851]
loss: 4.527025  [ 4758/ 7851]
loss: 6.627225  [ 5226/ 7851]
loss: 6.545172  [ 5694/ 7851]
loss: 6.821599  [ 6162/ 7851]
loss: 9.946998  [ 6630/ 7851]
loss: 3.279105  [ 7098/ 7851]
loss: 8.973701  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 7.693210 
Epoch 8
-------------------------------
loss: 5.919472  [   79/ 7851]
loss: 6.574174  [  547/ 7851]
loss: 6.658208  [ 1015/ 7851]
loss: 5.528187  [ 1483/ 7851]
loss: 6.494901  [ 1951/ 7851]
loss: 110.263382  [ 2419/ 7851]
loss: 5.571146  [ 2887/ 7851]
loss: 6.610570  [ 3355/ 7851]
loss: 7.624660  [ 3823/ 7851]
loss: 10.042578  [ 4290/ 7851]
loss: 4.527092  [ 4758/ 7851]
loss: 6.628267  [ 5226/ 7851]
loss: 6.545206  [ 5694/ 7851]
loss: 6.822266  [ 6162/ 7851]
loss: 9.946322  [ 6630/ 7851]
loss: 3.278317  [ 7098/ 7851]
loss: 8.973268  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 7.694704 
Epoch 9
-------------------------------
loss: 5.917312  [   79/ 7851]
loss: 6.571230  [  547/ 7851]
loss: 6.659024  [ 1015/ 7851]
loss: 5.527258  [ 1483/ 7851]
loss: 6.495852  [ 1951/ 7851]
loss: 5.762616  [ 2419/ 7851]
loss: 5.577197  [ 2887/ 7851]
loss: 6.621086  [ 3355/ 7851]
loss: 7.622981  [ 3823/ 7851]
loss: 10.043289  [ 4290/ 7851]
loss: 4.526557  [ 4758/ 7851]
loss: 6.624406  [ 5226/ 7851]
loss: 6.545140  [ 5694/ 7851]
loss: 6.823553  [ 6162/ 7851]
loss: 9.943224  [ 6630/ 7851]
loss: 3.275807  [ 7098/ 7851]
loss: 8.970726  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.697045 
Epoch 10
-------------------------------
loss: 5.913983  [   79/ 7851]
loss: 6.566548  [  547/ 7851]
loss: 6.659313  [ 1015/ 7851]
loss: 5.526370  [ 1483/ 7851]
loss: 6.496984  [ 1951/ 7851]
loss: 5.762598  [ 2419/ 7851]
loss: 5.577484  [ 2887/ 7851]
loss: 6.622722  [ 3355/ 7851]
loss: 7.622712  [ 3823/ 7851]
loss: 10.043601  [ 4290/ 7851]
loss: 4.526433  [ 4758/ 7851]
loss: 6.623403  [ 5226/ 7851]
loss: 6.545146  [ 5694/ 7851]
loss: 6.824193  [ 6162/ 7851]
loss: 9.941810  [ 6630/ 7851]
loss: 3.274499  [ 7098/ 7851]
loss: 8.969329  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.698616 
Epoch 11
-------------------------------
loss: 5.911873  [   79/ 7851]
loss: 6.563319  [  547/ 7851]
loss: 6.659583  [ 1015/ 7851]
loss: 5.525733  [ 1483/ 7851]
loss: 6.497868  [ 1951/ 7851]
loss: 5.762589  [ 2419/ 7851]
loss: 5.577737  [ 2887/ 7851]
loss: 6.624072  [ 3355/ 7851]
loss: 7.622501  [ 3823/ 7851]
loss: 10.043851  [ 4290/ 7851]
loss: 4.526340  [ 4758/ 7851]
loss: 6.622576  [ 5226/ 7851]
loss: 6.545156  [ 5694/ 7851]
loss: 6.824687  [ 6162/ 7851]
loss: 9.940653  [ 6630/ 7851]
loss: 3.273409  [ 7098/ 7851]
loss: 8.968078  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.699938 
Epoch 12
-------------------------------
loss: 5.910142  [   79/ 7851]
loss: 6.560584  [  547/ 7851]
loss: 6.659746  [ 1015/ 7851]
loss: 5.525226  [ 1483/ 7851]
loss: 6.498622  [ 1951/ 7851]
loss: 5.762584  [ 2419/ 7851]
loss: 5.577952  [ 2887/ 7851]
loss: 6.625217  [ 3355/ 7851]
loss: 7.622328  [ 3823/ 7851]
loss: 10.044046  [ 4290/ 7851]
loss: 4.526269  [ 4758/ 7851]
loss: 6.621881  [ 5226/ 7851]
loss: 6.545167  [ 5694/ 7851]
loss: 6.825075  [ 6162/ 7851]
loss: 9.939689  [ 6630/ 7851]
loss: 3.272487  [ 7098/ 7851]
loss: 8.966952  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.701065 
Epoch 13
-------------------------------
loss: 5.908699  [   79/ 7851]
loss: 6.558236  [  547/ 7851]
loss: 6.659836  [ 1015/ 7851]
loss: 5.524816  [ 1483/ 7851]
loss: 6.499272  [ 1951/ 7851]
loss: 5.762582  [ 2419/ 7851]
loss: 5.578136  [ 2887/ 7851]
loss: 6.626199  [ 3355/ 7851]
loss: 7.622183  [ 3823/ 7851]
loss: 10.044203  [ 4290/ 7851]
loss: 4.526215  [ 4758/ 7851]
loss: 6.621288  [ 5226/ 7851]
loss: 6.545180  [ 5694/ 7851]
loss: 6.825382  [ 6162/ 7851]
loss: 9.938874  [ 6630/ 7851]
loss: 3.271695  [ 7098/ 7851]
loss: 8.965938  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 7.702039 
Epoch 14
-------------------------------
loss: 5.907476  [   79/ 7851]
loss: 6.556200  [  547/ 7851]
loss: 6.659877  [ 1015/ 7851]
loss: 5.524478  [ 1483/ 7851]
loss: 6.499837  [ 1951/ 7851]
loss: 5.762581  [ 2419/ 7851]
loss: 5.578298  [ 2887/ 7851]
loss: 6.627051  [ 3355/ 7851]
loss: 7.622060  [ 3823/ 7851]
loss: 10.044330  [ 4290/ 7851]
loss: 4.526171  [ 4758/ 7851]
loss: 6.620777  [ 5226/ 7851]
loss: 6.545194  [ 5694/ 7851]
loss: 6.825631  [ 6162/ 7851]
loss: 9.938177  [ 6630/ 7851]
loss: 3.271009  [ 7098/ 7851]
loss: 8.965022  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.702887 
Epoch 15
-------------------------------
loss: 5.906430  [   79/ 7851]
loss: 6.554417  [  547/ 7851]
loss: 6.659886  [ 1015/ 7851]
loss: 5.524197  [ 1483/ 7851]
loss: 6.500331  [ 1951/ 7851]
loss: 5.762581  [ 2419/ 7851]
loss: 5.578437  [ 2887/ 7851]
loss: 6.627796  [ 3355/ 7851]
loss: 7.621953  [ 3823/ 7851]
loss: 10.044434  [ 4290/ 7851]
loss: 4.526135  [ 4758/ 7851]
loss: 6.620333  [ 5226/ 7851]
loss: 6.545206  [ 5694/ 7851]
loss: 6.825835  [ 6162/ 7851]
loss: 9.937573  [ 6630/ 7851]
loss: 3.270410  [ 7098/ 7851]
loss: 8.964192  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.703632 
Epoch 16
-------------------------------
loss: 5.905524  [   79/ 7851]
loss: 6.552845  [  547/ 7851]
loss: 6.659873  [ 1015/ 7851]
loss: 5.523959  [ 1483/ 7851]
loss: 6.500770  [ 1951/ 7851]
loss: 5.762582  [ 2419/ 7851]
loss: 5.578562  [ 2887/ 7851]
loss: 6.628455  [ 3355/ 7851]
loss: 7.621863  [ 3823/ 7851]
loss: 10.044520  [ 4290/ 7851]
loss: 4.526105  [ 4758/ 7851]
loss: 6.619941  [ 5226/ 7851]
loss: 6.545218  [ 5694/ 7851]
loss: 6.826004  [ 6162/ 7851]
loss: 9.937047  [ 6630/ 7851]
loss: 3.269881  [ 7098/ 7851]
loss: 8.963440  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.704290 
Epoch 17
-------------------------------
loss: 5.904734  [   79/ 7851]
loss: 6.551450  [  547/ 7851]
loss: 6.659845  [ 1015/ 7851]
loss: 5.523757  [ 1483/ 7851]
loss: 6.501158  [ 1951/ 7851]
loss: 5.762584  [ 2419/ 7851]
loss: 5.578672  [ 2887/ 7851]
loss: 6.629038  [ 3355/ 7851]
loss: 7.621784  [ 3823/ 7851]
loss: 10.044594  [ 4290/ 7851]
loss: 4.526082  [ 4758/ 7851]
loss: 6.619596  [ 5226/ 7851]
loss: 6.545231  [ 5694/ 7851]
loss: 6.826144  [ 6162/ 7851]
loss: 9.936584  [ 6630/ 7851]
loss: 3.269413  [ 7098/ 7851]
loss: 8.962755  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.704876 
Epoch 18
-------------------------------
loss: 5.904040  [   79/ 7851]
loss: 6.550206  [  547/ 7851]
loss: 6.659806  [ 1015/ 7851]
loss: 5.523582  [ 1483/ 7851]
loss: 6.501506  [ 1951/ 7851]
loss: 5.762587  [ 2419/ 7851]
loss: 5.578772  [ 2887/ 7851]
loss: 6.629557  [ 3355/ 7851]
loss: 7.621715  [ 3823/ 7851]
loss: 10.044657  [ 4290/ 7851]
loss: 4.526062  [ 4758/ 7851]
loss: 6.619290  [ 5226/ 7851]
loss: 6.545243  [ 5694/ 7851]
loss: 6.826262  [ 6162/ 7851]
loss: 9.936175  [ 6630/ 7851]
loss: 3.268996  [ 7098/ 7851]
loss: 8.962130  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.705399 
Epoch 19
-------------------------------
loss: 5.903426  [   79/ 7851]
loss: 6.549090  [  547/ 7851]
loss: 6.614230  [ 1015/ 7851]
loss: 5.511183  [ 1483/ 7851]
loss: 6.511093  [ 1951/ 7851]
loss: 5.766257  [ 2419/ 7851]
loss: 5.572289  [ 2887/ 7851]
loss: 6.632935  [ 3355/ 7851]
loss: 7.621096  [ 3823/ 7851]
loss: 10.043032  [ 4290/ 7851]
loss: 4.525864  [ 4758/ 7851]
loss: 6.618333  [ 5226/ 7851]
loss: 6.545490  [ 5694/ 7851]
loss: 6.825615  [ 6162/ 7851]
loss: 9.935676  [ 6630/ 7851]
loss: 3.268216  [ 7098/ 7851]
loss: 8.960796  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.706301 
Epoch 20
-------------------------------
loss: 5.902137  [   79/ 7851]
loss: 6.547194  [  547/ 7851]
loss: 6.660008  [ 1015/ 7851]
loss: 5.522831  [ 1483/ 7851]
loss: 6.502393  [ 1951/ 7851]
loss: 5.762479  [ 2419/ 7851]
loss: 5.578716  [ 2887/ 7851]
loss: 6.630876  [ 3355/ 7851]
loss: 7.621444  [ 3823/ 7851]
loss: 10.044910  [ 4290/ 7851]
loss: 4.525986  [ 4758/ 7851]
loss: 6.618602  [ 5226/ 7851]
loss: 6.545294  [ 5694/ 7851]
loss: 6.826683  [ 6162/ 7851]
loss: 9.935050  [ 6630/ 7851]
loss: 3.267896  [ 7098/ 7851]
loss: 8.960796  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 7.706886 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 80]                 32,080
==========================================================================================
Total params: 64,480
Trainable params: 64,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.45
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.38
Params size (MB): 0.26
Estimated Total Size (MB): 0.67
==========================================================================================
Epoch 1
-------------------------------
loss: 15.149733  [   79/ 7851]
loss: 12.223469  [  547/ 7851]
loss: 5.978652  [ 1015/ 7851]
loss: 6.439249  [ 1483/ 7851]
loss: 6.905916  [ 1951/ 7851]
loss: 5.563500  [ 2419/ 7851]
loss: 5.387516  [ 2887/ 7851]
loss: 5.625067  [ 3355/ 7851]
loss: 9.540059  [ 3823/ 7851]
loss: 7.449651  [ 4290/ 7851]
loss: 6.155758  [ 4758/ 7851]
loss: 7.830975  [ 5226/ 7851]
loss: 4.692701  [ 5694/ 7851]
loss: 7.508460  [ 6162/ 7851]
loss: 10.913730  [ 6630/ 7851]
loss: 6.921805  [ 7098/ 7851]
loss: 6.845917  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 5.439518 
Epoch 2
-------------------------------
loss: 7.105944  [   79/ 7851]
loss: 6.170473  [  547/ 7851]
loss: 5.493249  [ 1015/ 7851]
loss: 6.490354  [ 1483/ 7851]
loss: 6.744702  [ 1951/ 7851]
loss: 5.282377  [ 2419/ 7851]
loss: 5.364118  [ 2887/ 7851]
loss: 5.672806  [ 3355/ 7851]
loss: 8.210227  [ 3823/ 7851]
loss: 7.459717  [ 4290/ 7851]
loss: 6.132543  [ 4758/ 7851]
loss: 7.810836  [ 5226/ 7851]
loss: 4.706916  [ 5694/ 7851]
loss: 7.493920  [ 6162/ 7851]
loss: 7.755833  [ 6630/ 7851]
loss: 6.932541  [ 7098/ 7851]
loss: 6.783551  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440907 
Epoch 3
-------------------------------
loss: 7.104348  [   79/ 7851]
loss: 6.187815  [  547/ 7851]
loss: 5.477149  [ 1015/ 7851]
loss: 6.511178  [ 1483/ 7851]
loss: 6.738899  [ 1951/ 7851]
loss: 5.297465  [ 2419/ 7851]
loss: 5.375437  [ 2887/ 7851]
loss: 5.677052  [ 3355/ 7851]
loss: 8.295819  [ 3823/ 7851]
loss: 7.450730  [ 4290/ 7851]
loss: 6.100758  [ 4758/ 7851]
loss: 7.793054  [ 5226/ 7851]
loss: 4.691243  [ 5694/ 7851]
loss: 7.449894  [ 6162/ 7851]
loss: 7.767258  [ 6630/ 7851]
loss: 6.933332  [ 7098/ 7851]
loss: 6.807415  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 5.441348 
Epoch 4
-------------------------------
loss: 7.108615  [   79/ 7851]
loss: 6.188337  [  547/ 7851]
loss: 5.474631  [ 1015/ 7851]
loss: 6.504246  [ 1483/ 7851]
loss: 6.735848  [ 1951/ 7851]
loss: 5.305501  [ 2419/ 7851]
loss: 5.380186  [ 2887/ 7851]
loss: 5.676844  [ 3355/ 7851]
loss: 8.219835  [ 3823/ 7851]
loss: 7.454492  [ 4290/ 7851]
loss: 6.141805  [ 4758/ 7851]
loss: 7.826103  [ 5226/ 7851]
loss: 4.693139  [ 5694/ 7851]
loss: 7.483557  [ 6162/ 7851]
loss: 7.755854  [ 6630/ 7851]
loss: 6.933546  [ 7098/ 7851]
loss: 6.814259  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 5.439807 
Epoch 5
-------------------------------
loss: 7.109717  [   79/ 7851]
loss: 6.187853  [  547/ 7851]
loss: 5.475013  [ 1015/ 7851]
loss: 6.506747  [ 1483/ 7851]
loss: 6.735539  [ 1951/ 7851]
loss: 5.306851  [ 2419/ 7851]
loss: 5.381575  [ 2887/ 7851]
loss: 5.676973  [ 3355/ 7851]
loss: 8.219701  [ 3823/ 7851]
loss: 7.454735  [ 4290/ 7851]
loss: 6.143253  [ 4758/ 7851]
loss: 7.826412  [ 5226/ 7851]
loss: 4.692937  [ 5694/ 7851]
loss: 7.482806  [ 6162/ 7851]
loss: 7.755752  [ 6630/ 7851]
loss: 6.941444  [ 7098/ 7851]
loss: 6.799527  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440373 
Epoch 6
-------------------------------
loss: 7.103985  [   79/ 7851]
loss: 6.188653  [  547/ 7851]
loss: 5.471384  [ 1015/ 7851]
loss: 6.497700  [ 1483/ 7851]
loss: 6.736303  [ 1951/ 7851]
loss: 5.308937  [ 2419/ 7851]
loss: 5.384697  [ 2887/ 7851]
loss: 5.676185  [ 3355/ 7851]
loss: 8.219758  [ 3823/ 7851]
loss: 7.455198  [ 4290/ 7851]
loss: 6.144979  [ 4758/ 7851]
loss: 7.827162  [ 5226/ 7851]
loss: 4.692754  [ 5694/ 7851]
loss: 7.482512  [ 6162/ 7851]
loss: 7.755635  [ 6630/ 7851]
loss: 6.942070  [ 7098/ 7851]
loss: 6.800431  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440327 
Epoch 7
-------------------------------
loss: 7.104052  [   79/ 7851]
loss: 6.188949  [  547/ 7851]
loss: 5.470932  [ 1015/ 7851]
loss: 6.497703  [ 1483/ 7851]
loss: 6.736321  [ 1951/ 7851]
loss: 5.309874  [ 2419/ 7851]
loss: 5.385745  [ 2887/ 7851]
loss: 95.728928  [ 3355/ 7851]
loss: 8.204852  [ 3823/ 7851]
loss: 7.457830  [ 4290/ 7851]
loss: 6.139439  [ 4758/ 7851]
loss: 7.837154  [ 5226/ 7851]
loss: 4.686595  [ 5694/ 7851]
loss: 7.478419  [ 6162/ 7851]
loss: 7.756982  [ 6630/ 7851]
loss: 6.943534  [ 7098/ 7851]
loss: 6.805870  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440321 
Epoch 8
-------------------------------
loss: 7.105026  [   79/ 7851]
loss: 6.189511  [  547/ 7851]
loss: 5.470818  [ 1015/ 7851]
loss: 6.499242  [ 1483/ 7851]
loss: 6.736234  [ 1951/ 7851]
loss: 5.311131  [ 2419/ 7851]
loss: 5.386998  [ 2887/ 7851]
loss: 5.676024  [ 3355/ 7851]
loss: 8.219961  [ 3823/ 7851]
loss: 7.455588  [ 4290/ 7851]
loss: 6.147185  [ 4758/ 7851]
loss: 7.828321  [ 5226/ 7851]
loss: 4.692393  [ 5694/ 7851]
loss: 7.481991  [ 6162/ 7851]
loss: 7.755517  [ 6630/ 7851]
loss: 6.942772  [ 7098/ 7851]
loss: 6.802382  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440234 
Epoch 9
-------------------------------
loss: 7.104513  [   79/ 7851]
loss: 6.189565  [  547/ 7851]
loss: 5.470313  [ 1015/ 7851]
loss: 6.497928  [ 1483/ 7851]
loss: 6.736193  [ 1951/ 7851]
loss: 5.311494  [ 2419/ 7851]
loss: 5.387485  [ 2887/ 7851]
loss: 5.675994  [ 3355/ 7851]
loss: 8.219901  [ 3823/ 7851]
loss: 7.455618  [ 4290/ 7851]
loss: 6.147459  [ 4758/ 7851]
loss: 7.828259  [ 5226/ 7851]
loss: 4.692402  [ 5694/ 7851]
loss: 7.481830  [ 6162/ 7851]
loss: 7.755451  [ 6630/ 7851]
loss: 6.942964  [ 7098/ 7851]
loss: 6.802338  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440217 
Epoch 10
-------------------------------
loss: 7.104444  [   79/ 7851]
loss: 6.189583  [  547/ 7851]
loss: 5.470202  [ 1015/ 7851]
loss: 6.497820  [ 1483/ 7851]
loss: 6.736259  [ 1951/ 7851]
loss: 5.311665  [ 2419/ 7851]
loss: 5.387726  [ 2887/ 7851]
loss: 5.676078  [ 3355/ 7851]
loss: 8.219851  [ 3823/ 7851]
loss: 7.455644  [ 4290/ 7851]
loss: 6.147635  [ 4758/ 7851]
loss: 7.828211  [ 5226/ 7851]
loss: 4.692397  [ 5694/ 7851]
loss: 7.481687  [ 6162/ 7851]
loss: 7.755402  [ 6630/ 7851]
loss: 6.943108  [ 7098/ 7851]
loss: 6.802314  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440203 
Epoch 11
-------------------------------
loss: 7.104399  [   79/ 7851]
loss: 6.189600  [  547/ 7851]
loss: 5.470119  [ 1015/ 7851]
loss: 6.497740  [ 1483/ 7851]
loss: 6.736308  [ 1951/ 7851]
loss: 5.311801  [ 2419/ 7851]
loss: 5.387917  [ 2887/ 7851]
loss: 5.676140  [ 3355/ 7851]
loss: 8.219810  [ 3823/ 7851]
loss: 7.455662  [ 4290/ 7851]
loss: 6.147777  [ 4758/ 7851]
loss: 7.828177  [ 5226/ 7851]
loss: 4.692394  [ 5694/ 7851]
loss: 7.481577  [ 6162/ 7851]
loss: 7.755362  [ 6630/ 7851]
loss: 6.943220  [ 7098/ 7851]
loss: 6.802294  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440191 
Epoch 12
-------------------------------
loss: 7.104367  [   79/ 7851]
loss: 6.189614  [  547/ 7851]
loss: 5.470054  [ 1015/ 7851]
loss: 6.497675  [ 1483/ 7851]
loss: 6.736348  [ 1951/ 7851]
loss: 5.311912  [ 2419/ 7851]
loss: 5.388072  [ 2887/ 7851]
loss: 5.676187  [ 3355/ 7851]
loss: 8.219778  [ 3823/ 7851]
loss: 7.455676  [ 4290/ 7851]
loss: 6.147891  [ 4758/ 7851]
loss: 7.828151  [ 5226/ 7851]
loss: 4.692391  [ 5694/ 7851]
loss: 7.481493  [ 6162/ 7851]
loss: 7.755327  [ 6630/ 7851]
loss: 6.943308  [ 7098/ 7851]
loss: 6.802276  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440181 
Epoch 13
-------------------------------
loss: 7.104342  [   79/ 7851]
loss: 6.189628  [  547/ 7851]
loss: 5.470001  [ 1015/ 7851]
loss: 6.497619  [ 1483/ 7851]
loss: 6.736378  [ 1951/ 7851]
loss: 5.312004  [ 2419/ 7851]
loss: 5.388200  [ 2887/ 7851]
loss: 5.676221  [ 3355/ 7851]
loss: 8.219753  [ 3823/ 7851]
loss: 7.455687  [ 4290/ 7851]
loss: 6.147984  [ 4758/ 7851]
loss: 7.828132  [ 5226/ 7851]
loss: 4.692389  [ 5694/ 7851]
loss: 7.481428  [ 6162/ 7851]
loss: 7.755300  [ 6630/ 7851]
loss: 6.943379  [ 7098/ 7851]
loss: 6.802260  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440173 
Epoch 14
-------------------------------
loss: 7.104322  [   79/ 7851]
loss: 6.189639  [  547/ 7851]
loss: 5.469957  [ 1015/ 7851]
loss: 6.497572  [ 1483/ 7851]
loss: 6.736403  [ 1951/ 7851]
loss: 5.312081  [ 2419/ 7851]
loss: 5.388306  [ 2887/ 7851]
loss: 5.676249  [ 3355/ 7851]
loss: 8.219731  [ 3823/ 7851]
loss: 7.455694  [ 4290/ 7851]
loss: 6.148061  [ 4758/ 7851]
loss: 7.828117  [ 5226/ 7851]
loss: 4.692387  [ 5694/ 7851]
loss: 7.481376  [ 6162/ 7851]
loss: 7.755275  [ 6630/ 7851]
loss: 6.943437  [ 7098/ 7851]
loss: 6.802244  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440166 
Epoch 15
-------------------------------
loss: 7.104308  [   79/ 7851]
loss: 6.189650  [  547/ 7851]
loss: 5.469921  [ 1015/ 7851]
loss: 6.497531  [ 1483/ 7851]
loss: 6.736422  [ 1951/ 7851]
loss: 5.312147  [ 2419/ 7851]
loss: 5.388396  [ 2887/ 7851]
loss: 5.676270  [ 3355/ 7851]
loss: 8.219714  [ 3823/ 7851]
loss: 7.455700  [ 4290/ 7851]
loss: 6.148127  [ 4758/ 7851]
loss: 7.828106  [ 5226/ 7851]
loss: 4.692386  [ 5694/ 7851]
loss: 7.481334  [ 6162/ 7851]
loss: 7.755255  [ 6630/ 7851]
loss: 6.943483  [ 7098/ 7851]
loss: 6.802230  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440161 
Epoch 16
-------------------------------
loss: 7.104294  [   79/ 7851]
loss: 6.189660  [  547/ 7851]
loss: 5.469890  [ 1015/ 7851]
loss: 6.497496  [ 1483/ 7851]
loss: 6.736439  [ 1951/ 7851]
loss: 5.312201  [ 2419/ 7851]
loss: 5.388472  [ 2887/ 7851]
loss: 5.676285  [ 3355/ 7851]
loss: 8.219701  [ 3823/ 7851]
loss: 7.455705  [ 4290/ 7851]
loss: 6.148181  [ 4758/ 7851]
loss: 7.828098  [ 5226/ 7851]
loss: 4.692385  [ 5694/ 7851]
loss: 7.481301  [ 6162/ 7851]
loss: 7.755237  [ 6630/ 7851]
loss: 6.943523  [ 7098/ 7851]
loss: 6.802217  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440156 
Epoch 17
-------------------------------
loss: 7.104284  [   79/ 7851]
loss: 6.189668  [  547/ 7851]
loss: 5.469864  [ 1015/ 7851]
loss: 6.497464  [ 1483/ 7851]
loss: 6.753731  [ 1951/ 7851]
loss: 5.297927  [ 2419/ 7851]
loss: 5.395897  [ 2887/ 7851]
loss: 5.654743  [ 3355/ 7851]
loss: 8.207049  [ 3823/ 7851]
loss: 7.454343  [ 4290/ 7851]
loss: 6.151850  [ 4758/ 7851]
loss: 7.831933  [ 5226/ 7851]
loss: 4.690580  [ 5694/ 7851]
loss: 7.481297  [ 6162/ 7851]
loss: 7.754511  [ 6630/ 7851]
loss: 6.944536  [ 7098/ 7851]
loss: 6.804161  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440071 
Epoch 18
-------------------------------
loss: 7.104534  [   79/ 7851]
loss: 6.189795  [  547/ 7851]
loss: 5.469813  [ 1015/ 7851]
loss: 6.497684  [ 1483/ 7851]
loss: 6.736299  [ 1951/ 7851]
loss: 5.312905  [ 2419/ 7851]
loss: 5.389238  [ 2887/ 7851]
loss: 5.676033  [ 3355/ 7851]
loss: 8.219722  [ 3823/ 7851]
loss: 7.455827  [ 4290/ 7851]
loss: 6.149024  [ 4758/ 7851]
loss: 7.828680  [ 5226/ 7851]
loss: 4.692200  [ 5694/ 7851]
loss: 7.481152  [ 6162/ 7851]
loss: 7.755229  [ 6630/ 7851]
loss: 6.943719  [ 7098/ 7851]
loss: 6.803213  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440123 
Epoch 19
-------------------------------
loss: 7.104578  [   79/ 7851]
loss: 6.189948  [  547/ 7851]
loss: 5.469691  [ 1015/ 7851]
loss: 6.497673  [ 1483/ 7851]
loss: 6.736345  [ 1951/ 7851]
loss: 5.312882  [ 2419/ 7851]
loss: 5.389189  [ 2887/ 7851]
loss: 5.676128  [ 3355/ 7851]
loss: 8.219741  [ 3823/ 7851]
loss: 7.455817  [ 4290/ 7851]
loss: 6.148922  [ 4758/ 7851]
loss: 7.828553  [ 5226/ 7851]
loss: 4.692244  [ 5694/ 7851]
loss: 7.481156  [ 6162/ 7851]
loss: 7.755214  [ 6630/ 7851]
loss: 6.943716  [ 7098/ 7851]
loss: 6.803009  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440124 
Epoch 20
-------------------------------
loss: 7.104515  [   79/ 7851]
loss: 6.189905  [  547/ 7851]
loss: 5.469699  [ 1015/ 7851]
loss: 6.497605  [ 1483/ 7851]
loss: 6.736378  [ 1951/ 7851]
loss: 5.312809  [ 2419/ 7851]
loss: 5.389130  [ 2887/ 7851]
loss: 5.676171  [ 3355/ 7851]
loss: 8.219719  [ 3823/ 7851]
loss: 7.455801  [ 4290/ 7851]
loss: 6.148839  [ 4758/ 7851]
loss: 7.828461  [ 5226/ 7851]
loss: 4.692269  [ 5694/ 7851]
loss: 7.481153  [ 6162/ 7851]
loss: 7.755201  [ 6630/ 7851]
loss: 6.943716  [ 7098/ 7851]
loss: 6.802851  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 5.440124 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 80]                 32,080
==========================================================================================
Total params: 64,480
Trainable params: 64,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.45
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.38
Params size (MB): 0.26
Estimated Total Size (MB): 0.67
==========================================================================================
Epoch 1
-------------------------------
loss: 16.519442  [   79/ 7851]
loss: 5.940380  [  547/ 7851]
loss: 6.117761  [ 1015/ 7851]
loss: 8.354305  [ 1483/ 7851]
loss: 5.979324  [ 1951/ 7851]
loss: 8.125840  [ 2419/ 7851]
loss: 6.753477  [ 2887/ 7851]
loss: 4.694614  [ 3355/ 7851]
loss: 7.992693  [ 3823/ 7851]
loss: 6.860960  [ 4290/ 7851]
loss: 7.720614  [ 4758/ 7851]
loss: 8.596801  [ 5226/ 7851]
loss: 9.541057  [ 5694/ 7851]
loss: 4.509035  [ 6162/ 7851]
loss: 5.638309  [ 6630/ 7851]
loss: 9.003855  [ 7098/ 7851]
loss: 6.068089  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 7.070032 
Epoch 2
-------------------------------
loss: 6.894402  [   79/ 7851]
loss: 3.982223  [  547/ 7851]
loss: 6.194181  [ 1015/ 7851]
loss: 8.005798  [ 1483/ 7851]
loss: 6.344622  [ 1951/ 7851]
loss: 7.805253  [ 2419/ 7851]
loss: 7.072950  [ 2887/ 7851]
loss: 4.435947  [ 3355/ 7851]
loss: 7.926453  [ 3823/ 7851]
loss: 5.002599  [ 4290/ 7851]
loss: 6.809995  [ 4758/ 7851]
loss: 7.380749  [ 5226/ 7851]
loss: 9.817060  [ 5694/ 7851]
loss: 3.960864  [ 6162/ 7851]
loss: 5.594608  [ 6630/ 7851]
loss: 10.261967  [ 7098/ 7851]
loss: 7.008835  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.437605 
Epoch 3
-------------------------------
loss: 5.962624  [   79/ 7851]
loss: 4.495506  [  547/ 7851]
loss: 6.916810  [ 1015/ 7851]
loss: 7.857680  [ 1483/ 7851]
loss: 5.240623  [ 1951/ 7851]
loss: 8.007516  [ 2419/ 7851]
loss: 6.583984  [ 2887/ 7851]
loss: 4.143971  [ 3355/ 7851]
loss: 8.030593  [ 3823/ 7851]
loss: 5.819697  [ 4290/ 7851]
loss: 6.905604  [ 4758/ 7851]
loss: 7.038411  [ 5226/ 7851]
loss: 9.135951  [ 5694/ 7851]
loss: 4.955674  [ 6162/ 7851]
loss: 5.439163  [ 6630/ 7851]
loss: 8.511904  [ 7098/ 7851]
loss: 5.831744  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 7.248771 
Epoch 4
-------------------------------
loss: 6.562227  [   79/ 7851]
loss: 4.336400  [  547/ 7851]
loss: 5.709582  [ 1015/ 7851]
loss: 7.985245  [ 1483/ 7851]
loss: 4.805679  [ 1951/ 7851]
loss: 7.490053  [ 2419/ 7851]
loss: 6.129647  [ 2887/ 7851]
loss: 4.514372  [ 3355/ 7851]
loss: 7.671221  [ 3823/ 7851]
loss: 5.159204  [ 4290/ 7851]
loss: 6.714921  [ 4758/ 7851]
loss: 7.018705  [ 5226/ 7851]
loss: 9.031202  [ 5694/ 7851]
loss: 4.110013  [ 6162/ 7851]
loss: 5.049685  [ 6630/ 7851]
loss: 8.930279  [ 7098/ 7851]
loss: 7.330682  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.180198 
Epoch 5
-------------------------------
loss: 5.655399  [   79/ 7851]
loss: 5.367964  [  547/ 7851]
loss: 5.615112  [ 1015/ 7851]
loss: 7.224499  [ 1483/ 7851]
loss: 5.238943  [ 1951/ 7851]
loss: 7.953745  [ 2419/ 7851]
loss: 6.012242  [ 2887/ 7851]
loss: 4.526064  [ 3355/ 7851]
loss: 8.225052  [ 3823/ 7851]
loss: 5.731410  [ 4290/ 7851]
loss: 6.287120  [ 4758/ 7851]
loss: 7.350698  [ 5226/ 7851]
loss: 9.088634  [ 5694/ 7851]
loss: 4.121922  [ 6162/ 7851]
loss: 5.435701  [ 6630/ 7851]
loss: 8.582429  [ 7098/ 7851]
loss: 6.110891  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.987337 
Epoch 6
-------------------------------
loss: 6.615840  [   79/ 7851]
loss: 5.257992  [  547/ 7851]
loss: 5.660122  [ 1015/ 7851]
loss: 7.514925  [ 1483/ 7851]
loss: 4.856987  [ 1951/ 7851]
loss: 7.517871  [ 2419/ 7851]
loss: 6.075212  [ 2887/ 7851]
loss: 4.365819  [ 3355/ 7851]
loss: 7.947863  [ 3823/ 7851]
loss: 5.121922  [ 4290/ 7851]
loss: 6.394359  [ 4758/ 7851]
loss: 7.791646  [ 5226/ 7851]
loss: 8.962802  [ 5694/ 7851]
loss: 4.660041  [ 6162/ 7851]
loss: 5.219243  [ 6630/ 7851]
loss: 8.816053  [ 7098/ 7851]
loss: 6.197391  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.824713 
Epoch 7
-------------------------------
loss: 6.010707  [   79/ 7851]
loss: 4.863182  [  547/ 7851]
loss: 5.683218  [ 1015/ 7851]
loss: 7.125976  [ 1483/ 7851]
loss: 5.609222  [ 1951/ 7851]
loss: 8.217710  [ 2419/ 7851]
loss: 6.818847  [ 2887/ 7851]
loss: 4.204316  [ 3355/ 7851]
loss: 7.733008  [ 3823/ 7851]
loss: 5.060943  [ 4290/ 7851]
loss: 7.271732  [ 4758/ 7851]
loss: 6.700899  [ 5226/ 7851]
loss: 9.484978  [ 5694/ 7851]
loss: 4.126288  [ 6162/ 7851]
loss: 5.544877  [ 6630/ 7851]
loss: 8.579777  [ 7098/ 7851]
loss: 6.008319  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.658825 
Epoch 8
-------------------------------
loss: 6.497235  [   79/ 7851]
loss: 4.834724  [  547/ 7851]
loss: 6.059838  [ 1015/ 7851]
loss: 7.300107  [ 1483/ 7851]
loss: 5.264556  [ 1951/ 7851]
loss: 7.054605  [ 2419/ 7851]
loss: 6.098347  [ 2887/ 7851]
loss: 3.878766  [ 3355/ 7851]
loss: 7.668296  [ 3823/ 7851]
loss: 4.912261  [ 4290/ 7851]
loss: 6.779857  [ 4758/ 7851]
loss: 7.599648  [ 5226/ 7851]
loss: 10.115319  [ 5694/ 7851]
loss: 4.534199  [ 6162/ 7851]
loss: 5.241771  [ 6630/ 7851]
loss: 9.000868  [ 7098/ 7851]
loss: 6.199070  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.3%, Avg loss: 6.479056 
Epoch 9
-------------------------------
loss: 6.218389  [   79/ 7851]
loss: 3.883528  [  547/ 7851]
loss: 5.519485  [ 1015/ 7851]
loss: 7.314270  [ 1483/ 7851]
loss: 4.474676  [ 1951/ 7851]
loss: 7.928970  [ 2419/ 7851]
loss: 6.134037  [ 2887/ 7851]
loss: 4.365268  [ 3355/ 7851]
loss: 7.679480  [ 3823/ 7851]
loss: 5.226154  [ 4290/ 7851]
loss: 6.804397  [ 4758/ 7851]
loss: 6.471581  [ 5226/ 7851]
loss: 8.727416  [ 5694/ 7851]
loss: 4.898962  [ 6162/ 7851]
loss: 5.210227  [ 6630/ 7851]
loss: 9.092638  [ 7098/ 7851]
loss: 5.484464  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.261006 
Epoch 10
-------------------------------
loss: 6.305814  [   79/ 7851]
loss: 4.730488  [  547/ 7851]
loss: 5.241576  [ 1015/ 7851]
loss: 7.648969  [ 1483/ 7851]
loss: 5.430192  [ 1951/ 7851]
loss: 7.252193  [ 2419/ 7851]
loss: 5.917910  [ 2887/ 7851]
loss: 4.154649  [ 3355/ 7851]
loss: 8.102166  [ 3823/ 7851]
loss: 5.356202  [ 4290/ 7851]
loss: 6.708601  [ 4758/ 7851]
loss: 5.839964  [ 5226/ 7851]
loss: 9.245900  [ 5694/ 7851]
loss: 4.309944  [ 6162/ 7851]
loss: 5.245780  [ 6630/ 7851]
loss: 9.071341  [ 7098/ 7851]
loss: 6.259073  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.381039 
Epoch 11
-------------------------------
loss: 7.421617  [   79/ 7851]
loss: 4.926696  [  547/ 7851]
loss: 5.776989  [ 1015/ 7851]
loss: 7.685639  [ 1483/ 7851]
loss: 5.335826  [ 1951/ 7851]
loss: 7.497838  [ 2419/ 7851]
loss: 5.970113  [ 2887/ 7851]
loss: 4.259299  [ 3355/ 7851]
loss: 7.480819  [ 3823/ 7851]
loss: 5.113635  [ 4290/ 7851]
loss: 6.249621  [ 4758/ 7851]
loss: 6.450977  [ 5226/ 7851]
loss: 8.621077  [ 5694/ 7851]
loss: 4.201775  [ 6162/ 7851]
loss: 5.306278  [ 6630/ 7851]
loss: 8.333783  [ 7098/ 7851]
loss: 5.582927  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 6.758466 
Epoch 12
-------------------------------
loss: 7.028070  [   79/ 7851]
loss: 4.060173  [  547/ 7851]
loss: 6.000560  [ 1015/ 7851]
loss: 8.120283  [ 1483/ 7851]
loss: 4.784017  [ 1951/ 7851]
loss: 7.689354  [ 2419/ 7851]
loss: 6.095036  [ 2887/ 7851]
loss: 4.443111  [ 3355/ 7851]
loss: 7.924341  [ 3823/ 7851]
loss: 5.094839  [ 4290/ 7851]
loss: 6.510464  [ 4758/ 7851]
loss: 7.021935  [ 5226/ 7851]
loss: 9.141408  [ 5694/ 7851]
loss: 4.499003  [ 6162/ 7851]
loss: 5.008023  [ 6630/ 7851]
loss: 8.734812  [ 7098/ 7851]
loss: 5.709533  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 6.736105 
Epoch 13
-------------------------------
loss: 6.574708  [   79/ 7851]
loss: 4.353471  [  547/ 7851]
loss: 5.579160  [ 1015/ 7851]
loss: 7.341733  [ 1483/ 7851]
loss: 4.977073  [ 1951/ 7851]
loss: 7.773052  [ 2419/ 7851]
loss: 5.676505  [ 2887/ 7851]
loss: 4.421350  [ 3355/ 7851]
loss: 7.578871  [ 3823/ 7851]
loss: 5.198800  [ 4290/ 7851]
loss: 6.826814  [ 4758/ 7851]
loss: 6.946967  [ 5226/ 7851]
loss: 9.489056  [ 5694/ 7851]
loss: 3.981369  [ 6162/ 7851]
loss: 5.005668  [ 6630/ 7851]
loss: 8.667850  [ 7098/ 7851]
loss: 6.428106  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.743876 
Epoch 14
-------------------------------
loss: 6.289361  [   79/ 7851]
loss: 4.955101  [  547/ 7851]
loss: 5.680326  [ 1015/ 7851]
loss: 7.711447  [ 1483/ 7851]
loss: 4.786375  [ 1951/ 7851]
loss: 7.849803  [ 2419/ 7851]
loss: 5.557843  [ 2887/ 7851]
loss: 4.549713  [ 3355/ 7851]
loss: 7.635617  [ 3823/ 7851]
loss: 5.227948  [ 4290/ 7851]
loss: 6.868083  [ 4758/ 7851]
loss: 6.877488  [ 5226/ 7851]
loss: 9.079830  [ 5694/ 7851]
loss: 3.751842  [ 6162/ 7851]
loss: 5.079952  [ 6630/ 7851]
loss: 9.176524  [ 7098/ 7851]
loss: 6.211664  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.553771 
Epoch 15
-------------------------------
loss: 6.587875  [   79/ 7851]
loss: 4.075536  [  547/ 7851]
loss: 5.417514  [ 1015/ 7851]
loss: 7.028869  [ 1483/ 7851]
loss: 4.823298  [ 1951/ 7851]
loss: 7.493024  [ 2419/ 7851]
loss: 6.642874  [ 2887/ 7851]
loss: 5.340261  [ 3355/ 7851]
loss: 7.593092  [ 3823/ 7851]
loss: 5.424397  [ 4290/ 7851]
loss: 6.186726  [ 4758/ 7851]
loss: 7.022321  [ 5226/ 7851]
loss: 9.122638  [ 5694/ 7851]
loss: 4.731721  [ 6162/ 7851]
loss: 5.214047  [ 6630/ 7851]
loss: 9.099061  [ 7098/ 7851]
loss: 5.832610  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.158391 
Epoch 16
-------------------------------
loss: 6.219324  [   79/ 7851]
loss: 4.244511  [  547/ 7851]
loss: 6.044820  [ 1015/ 7851]
loss: 7.900500  [ 1483/ 7851]
loss: 5.394483  [ 1951/ 7851]
loss: 7.470066  [ 2419/ 7851]
loss: 6.419115  [ 2887/ 7851]
loss: 4.733371  [ 3355/ 7851]
loss: 6.896087  [ 3823/ 7851]
loss: 4.997244  [ 4290/ 7851]
loss: 6.705312  [ 4758/ 7851]
loss: 7.025889  [ 5226/ 7851]
loss: 9.440269  [ 5694/ 7851]
loss: 4.140008  [ 6162/ 7851]
loss: 5.468490  [ 6630/ 7851]
loss: 8.344158  [ 7098/ 7851]
loss: 6.315892  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 7.004895 
Epoch 17
-------------------------------
loss: 6.752673  [   79/ 7851]
loss: 4.162812  [  547/ 7851]
loss: 5.721788  [ 1015/ 7851]
loss: 6.809003  [ 1483/ 7851]
loss: 4.887234  [ 1951/ 7851]
loss: 7.278328  [ 2419/ 7851]
loss: 6.323692  [ 2887/ 7851]
loss: 4.393018  [ 3355/ 7851]
loss: 7.791093  [ 3823/ 7851]
loss: 4.900945  [ 4290/ 7851]
loss: 6.458059  [ 4758/ 7851]
loss: 6.239708  [ 5226/ 7851]
loss: 9.732401  [ 5694/ 7851]
loss: 4.313971  [ 6162/ 7851]
loss: 5.237250  [ 6630/ 7851]
loss: 9.064119  [ 7098/ 7851]
loss: 5.822563  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 6.550148 
Epoch 18
-------------------------------
loss: 6.329941  [   79/ 7851]
loss: 4.442471  [  547/ 7851]
loss: 5.926888  [ 1015/ 7851]
loss: 7.701310  [ 1483/ 7851]
loss: 5.313378  [ 1951/ 7851]
loss: 7.435473  [ 2419/ 7851]
loss: 5.964624  [ 2887/ 7851]
loss: 4.441525  [ 3355/ 7851]
loss: 8.024050  [ 3823/ 7851]
loss: 5.342533  [ 4290/ 7851]
loss: 7.184730  [ 4758/ 7851]
loss: 6.595575  [ 5226/ 7851]
loss: 8.926483  [ 5694/ 7851]
loss: 4.340014  [ 6162/ 7851]
loss: 5.041592  [ 6630/ 7851]
loss: 8.377066  [ 7098/ 7851]
loss: 6.395576  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 7.090569 
Epoch 19
-------------------------------
loss: 6.487816  [   79/ 7851]
loss: 4.877919  [  547/ 7851]
loss: 5.912651  [ 1015/ 7851]
loss: 7.706895  [ 1483/ 7851]
loss: 5.205948  [ 1951/ 7851]
loss: 6.972794  [ 2419/ 7851]
loss: 6.900403  [ 2887/ 7851]
loss: 4.330247  [ 3355/ 7851]
loss: 7.772761  [ 3823/ 7851]
loss: 4.706885  [ 4290/ 7851]
loss: 6.840902  [ 4758/ 7851]
loss: 6.848931  [ 5226/ 7851]
loss: 9.608609  [ 5694/ 7851]
loss: 4.430104  [ 6162/ 7851]
loss: 5.410899  [ 6630/ 7851]
loss: 9.151822  [ 7098/ 7851]
loss: 6.189807  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.350878 
Epoch 20
-------------------------------
loss: 7.482183  [   79/ 7851]
loss: 5.127640  [  547/ 7851]
loss: 5.933985  [ 1015/ 7851]
loss: 7.470858  [ 1483/ 7851]
loss: 5.761459  [ 1951/ 7851]
loss: 7.773698  [ 2419/ 7851]
loss: 7.279716  [ 2887/ 7851]
loss: 4.452002  [ 3355/ 7851]
loss: 7.739093  [ 3823/ 7851]
loss: 5.432022  [ 4290/ 7851]
loss: 6.831902  [ 4758/ 7851]
loss: 6.332484  [ 5226/ 7851]
loss: 9.315722  [ 5694/ 7851]
loss: 4.318551  [ 6162/ 7851]
loss: 4.998906  [ 6630/ 7851]
loss: 9.207590  [ 7098/ 7851]
loss: 6.850432  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.7%, Avg loss: 6.446823 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Linear: 2-1                       [100, 400]                32,400
│    └─ReLU: 2-2                         [100, 400]                --
│    └─Linear: 2-3                       [100, 80]                 32,080
==========================================================================================
Total params: 64,480
Trainable params: 64,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.45
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.38
Params size (MB): 0.26
Estimated Total Size (MB): 0.67
==========================================================================================
Epoch 1
-------------------------------
loss: 16.476543  [   79/ 7851]
loss: 12.017744  [  547/ 7851]
loss: 6.640546  [ 1015/ 7851]
loss: 7.182228  [ 1483/ 7851]
loss: 7.822280  [ 1951/ 7851]
loss: 8.583689  [ 2419/ 7851]
loss: 6.218016  [ 2887/ 7851]
loss: 9.402940  [ 3355/ 7851]
loss: 5.166141  [ 3823/ 7851]
loss: 6.178696  [ 4290/ 7851]
loss: 8.391349  [ 4758/ 7851]
loss: 7.369817  [ 5226/ 7851]
loss: 8.569078  [ 5694/ 7851]
loss: 7.548595  [ 6162/ 7851]
loss: 6.764288  [ 6630/ 7851]
loss: 5.095759  [ 7098/ 7851]
loss: 6.138576  [ 7566/ 7851]

Test Error: 
 Accuracy: 0.9%, Avg loss: 6.739264 
Epoch 2
-------------------------------
loss: 6.926414  [   79/ 7851]
loss: 6.378812  [  547/ 7851]
loss: 5.998460  [ 1015/ 7851]
loss: 6.869078  [ 1483/ 7851]
loss: 6.553116  [ 1951/ 7851]
loss: 7.174074  [ 2419/ 7851]
loss: 6.835508  [ 2887/ 7851]
loss: 9.064373  [ 3355/ 7851]
loss: 5.401161  [ 3823/ 7851]
loss: 6.165641  [ 4290/ 7851]
loss: 7.695507  [ 4758/ 7851]
loss: 6.202881  [ 5226/ 7851]
loss: 9.440483  [ 5694/ 7851]
loss: 7.637337  [ 6162/ 7851]
loss: 6.056145  [ 6630/ 7851]
loss: 5.037047  [ 7098/ 7851]
loss: 5.878494  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 6.889779 
Epoch 3
-------------------------------
loss: 7.236682  [   79/ 7851]
loss: 5.923235  [  547/ 7851]
loss: 5.667194  [ 1015/ 7851]
loss: 6.554155  [ 1483/ 7851]
loss: 7.793591  [ 1951/ 7851]
loss: 7.529332  [ 2419/ 7851]
loss: 7.486926  [ 2887/ 7851]
loss: 9.470005  [ 3355/ 7851]
loss: 5.463743  [ 3823/ 7851]
loss: 5.745453  [ 4290/ 7851]
loss: 7.789307  [ 4758/ 7851]
loss: 5.844676  [ 5226/ 7851]
loss: 8.609630  [ 5694/ 7851]
loss: 8.107410  [ 6162/ 7851]
loss: 6.989798  [ 6630/ 7851]
loss: 5.494538  [ 7098/ 7851]
loss: 6.106763  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.657105 
Epoch 4
-------------------------------
loss: 6.317041  [   79/ 7851]
loss: 5.982501  [  547/ 7851]
loss: 5.873790  [ 1015/ 7851]
loss: 7.110503  [ 1483/ 7851]
loss: 6.492075  [ 1951/ 7851]
loss: 7.734164  [ 2419/ 7851]
loss: 6.873333  [ 2887/ 7851]
loss: 9.224956  [ 3355/ 7851]
loss: 5.016342  [ 3823/ 7851]
loss: 6.502339  [ 4290/ 7851]
loss: 7.717431  [ 4758/ 7851]
loss: 6.149102  [ 5226/ 7851]
loss: 8.298093  [ 5694/ 7851]
loss: 7.595950  [ 6162/ 7851]
loss: 5.891256  [ 6630/ 7851]
loss: 5.169352  [ 7098/ 7851]
loss: 5.517991  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 6.734783 
Epoch 5
-------------------------------
loss: 6.323964  [   79/ 7851]
loss: 6.237571  [  547/ 7851]
loss: 6.243705  [ 1015/ 7851]
loss: 6.880153  [ 1483/ 7851]
loss: 6.388355  [ 1951/ 7851]
loss: 7.875340  [ 2419/ 7851]
loss: 5.621801  [ 2887/ 7851]
loss: 9.146630  [ 3355/ 7851]
loss: 5.305841  [ 3823/ 7851]
loss: 5.949294  [ 4290/ 7851]
loss: 7.707623  [ 4758/ 7851]
loss: 6.209078  [ 5226/ 7851]
loss: 8.220117  [ 5694/ 7851]
loss: 7.817153  [ 6162/ 7851]
loss: 5.878916  [ 6630/ 7851]
loss: 5.147969  [ 7098/ 7851]
loss: 5.766714  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 6.824219 
Epoch 6
-------------------------------
loss: 6.612800  [   79/ 7851]
loss: 5.717439  [  547/ 7851]
loss: 6.214644  [ 1015/ 7851]
loss: 7.323484  [ 1483/ 7851]
loss: 6.071224  [ 1951/ 7851]
loss: 8.215611  [ 2419/ 7851]
loss: 6.277018  [ 2887/ 7851]
loss: 8.649851  [ 3355/ 7851]
loss: 5.637778  [ 3823/ 7851]
loss: 6.046253  [ 4290/ 7851]
loss: 7.204326  [ 4758/ 7851]
loss: 6.408445  [ 5226/ 7851]
loss: 9.230494  [ 5694/ 7851]
loss: 7.634513  [ 6162/ 7851]
loss: 6.347276  [ 6630/ 7851]
loss: 5.081561  [ 7098/ 7851]
loss: 5.550045  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.310752 
Epoch 7
-------------------------------
loss: 6.512193  [   79/ 7851]
loss: 6.154174  [  547/ 7851]
loss: 5.847393  [ 1015/ 7851]
loss: 6.962957  [ 1483/ 7851]
loss: 6.469403  [ 1951/ 7851]
loss: 7.186560  [ 2419/ 7851]
loss: 6.056031  [ 2887/ 7851]
loss: 8.865323  [ 3355/ 7851]
loss: 5.037029  [ 3823/ 7851]
loss: 5.763387  [ 4290/ 7851]
loss: 7.344469  [ 4758/ 7851]
loss: 6.177850  [ 5226/ 7851]
loss: 9.011716  [ 5694/ 7851]
loss: 7.982856  [ 6162/ 7851]
loss: 6.122388  [ 6630/ 7851]
loss: 4.962920  [ 7098/ 7851]
loss: 6.428459  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 6.282408 
Epoch 8
-------------------------------
loss: 6.209675  [   79/ 7851]
loss: 5.837384  [  547/ 7851]
loss: 5.607841  [ 1015/ 7851]
loss: 6.442837  [ 1483/ 7851]
loss: 6.476893  [ 1951/ 7851]
loss: 7.729010  [ 2419/ 7851]
loss: 6.396374  [ 2887/ 7851]
loss: 8.510172  [ 3355/ 7851]
loss: 5.199853  [ 3823/ 7851]
loss: 6.228785  [ 4290/ 7851]
loss: 7.703084  [ 4758/ 7851]
loss: 5.827602  [ 5226/ 7851]
loss: 8.989313  [ 5694/ 7851]
loss: 8.179150  [ 6162/ 7851]
loss: 5.888247  [ 6630/ 7851]
loss: 5.100847  [ 7098/ 7851]
loss: 5.814981  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.5%, Avg loss: 6.504507 
Epoch 9
-------------------------------
loss: 6.440017  [   79/ 7851]
loss: 5.873821  [  547/ 7851]
loss: 6.048373  [ 1015/ 7851]
loss: 7.057287  [ 1483/ 7851]
loss: 6.374753  [ 1951/ 7851]
loss: 7.057388  [ 2419/ 7851]
loss: 6.352856  [ 2887/ 7851]
loss: 8.857275  [ 3355/ 7851]
loss: 5.188800  [ 3823/ 7851]
loss: 6.194864  [ 4290/ 7851]
loss: 7.487883  [ 4758/ 7851]
loss: 6.163586  [ 5226/ 7851]
loss: 9.825212  [ 5694/ 7851]
loss: 7.513266  [ 6162/ 7851]
loss: 6.035556  [ 6630/ 7851]
loss: 4.344959  [ 7098/ 7851]
loss: 5.784665  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 5.874649 
Epoch 10
-------------------------------
loss: 6.333344  [   79/ 7851]
loss: 5.803761  [  547/ 7851]
loss: 6.025004  [ 1015/ 7851]
loss: 6.363967  [ 1483/ 7851]
loss: 6.712821  [ 1951/ 7851]
loss: 7.140343  [ 2419/ 7851]
loss: 6.628529  [ 2887/ 7851]
loss: 9.727898  [ 3355/ 7851]
loss: 5.222530  [ 3823/ 7851]
loss: 6.007795  [ 4290/ 7851]
loss: 6.977915  [ 4758/ 7851]
loss: 5.873765  [ 5226/ 7851]
loss: 8.304822  [ 5694/ 7851]
loss: 8.243728  [ 6162/ 7851]
loss: 6.101974  [ 6630/ 7851]
loss: 4.950485  [ 7098/ 7851]
loss: 6.066937  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.898060 
Epoch 11
-------------------------------
loss: 6.716687  [   79/ 7851]
loss: 6.008833  [  547/ 7851]
loss: 5.964447  [ 1015/ 7851]
loss: 5.742390  [ 1483/ 7851]
loss: 6.624410  [ 1951/ 7851]
loss: 6.996399  [ 2419/ 7851]
loss: 6.010275  [ 2887/ 7851]
loss: 8.755820  [ 3355/ 7851]
loss: 5.346925  [ 3823/ 7851]
loss: 5.936790  [ 4290/ 7851]
loss: 6.920374  [ 4758/ 7851]
loss: 6.214890  [ 5226/ 7851]
loss: 7.937218  [ 5694/ 7851]
loss: 7.051454  [ 6162/ 7851]
loss: 6.557392  [ 6630/ 7851]
loss: 5.079165  [ 7098/ 7851]
loss: 5.451043  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 6.439956 
Epoch 12
-------------------------------
loss: 5.888709  [   79/ 7851]
loss: 5.814973  [  547/ 7851]
loss: 5.393874  [ 1015/ 7851]
loss: 6.776474  [ 1483/ 7851]
loss: 5.786217  [ 1951/ 7851]
loss: 7.214238  [ 2419/ 7851]
loss: 6.294957  [ 2887/ 7851]
loss: 7.590534  [ 3355/ 7851]
loss: 4.605330  [ 3823/ 7851]
loss: 6.156560  [ 4290/ 7851]
loss: 7.347394  [ 4758/ 7851]
loss: 5.914022  [ 5226/ 7851]
loss: 8.960376  [ 5694/ 7851]
loss: 7.085180  [ 6162/ 7851]
loss: 5.917290  [ 6630/ 7851]
loss: 5.055041  [ 7098/ 7851]
loss: 6.189348  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 6.517652 
Epoch 13
-------------------------------
loss: 6.554717  [   79/ 7851]
loss: 5.522449  [  547/ 7851]
loss: 6.088068  [ 1015/ 7851]
loss: 7.981974  [ 1483/ 7851]
loss: 6.349424  [ 1951/ 7851]
loss: 7.077297  [ 2419/ 7851]
loss: 5.835115  [ 2887/ 7851]
loss: 9.109087  [ 3355/ 7851]
loss: 5.218467  [ 3823/ 7851]
loss: 5.932874  [ 4290/ 7851]
loss: 7.712047  [ 4758/ 7851]
loss: 6.226712  [ 5226/ 7851]
loss: 8.347341  [ 5694/ 7851]
loss: 6.811435  [ 6162/ 7851]
loss: 5.878348  [ 6630/ 7851]
loss: 4.735379  [ 7098/ 7851]
loss: 5.743925  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.667549 
Epoch 14
-------------------------------
loss: 5.809165  [   79/ 7851]
loss: 5.882932  [  547/ 7851]
loss: 6.230657  [ 1015/ 7851]
loss: 6.782965  [ 1483/ 7851]
loss: 6.401642  [ 1951/ 7851]
loss: 7.841217  [ 2419/ 7851]
loss: 5.960464  [ 2887/ 7851]
loss: 9.883149  [ 3355/ 7851]
loss: 5.494874  [ 3823/ 7851]
loss: 6.247055  [ 4290/ 7851]
loss: 7.786171  [ 4758/ 7851]
loss: 5.764113  [ 5226/ 7851]
loss: 9.059936  [ 5694/ 7851]
loss: 7.368737  [ 6162/ 7851]
loss: 6.953424  [ 6630/ 7851]
loss: 5.029428  [ 7098/ 7851]
loss: 6.299664  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 6.746770 
Epoch 15
-------------------------------
loss: 6.294273  [   79/ 7851]
loss: 5.679068  [  547/ 7851]
loss: 5.761264  [ 1015/ 7851]
loss: 6.797740  [ 1483/ 7851]
loss: 5.855718  [ 1951/ 7851]
loss: 7.005115  [ 2419/ 7851]
loss: 6.284036  [ 2887/ 7851]
loss: 9.566690  [ 3355/ 7851]
loss: 5.732056  [ 3823/ 7851]
loss: 5.962647  [ 4290/ 7851]
loss: 7.253075  [ 4758/ 7851]
loss: 6.516602  [ 5226/ 7851]
loss: 8.153525  [ 5694/ 7851]
loss: 7.329434  [ 6162/ 7851]
loss: 5.810380  [ 6630/ 7851]
loss: 4.880119  [ 7098/ 7851]
loss: 6.023966  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.4%, Avg loss: 6.755800 
Epoch 16
-------------------------------
loss: 6.898679  [   79/ 7851]
loss: 5.622793  [  547/ 7851]
loss: 5.590555  [ 1015/ 7851]
loss: 6.720227  [ 1483/ 7851]
loss: 6.326145  [ 1951/ 7851]
loss: 7.643520  [ 2419/ 7851]
loss: 5.468577  [ 2887/ 7851]
loss: 8.998566  [ 3355/ 7851]
loss: 4.871881  [ 3823/ 7851]
loss: 6.142016  [ 4290/ 7851]
loss: 7.658051  [ 4758/ 7851]
loss: 6.482960  [ 5226/ 7851]
loss: 7.704946  [ 5694/ 7851]
loss: 6.516164  [ 6162/ 7851]
loss: 6.681116  [ 6630/ 7851]
loss: 4.685418  [ 7098/ 7851]
loss: 5.712519  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.448885 
Epoch 17
-------------------------------
loss: 6.525067  [   79/ 7851]
loss: 6.439823  [  547/ 7851]
loss: 6.605542  [ 1015/ 7851]
loss: 6.842766  [ 1483/ 7851]
loss: 6.131458  [ 1951/ 7851]
loss: 7.040019  [ 2419/ 7851]
loss: 6.625002  [ 2887/ 7851]
loss: 8.771885  [ 3355/ 7851]
loss: 5.488742  [ 3823/ 7851]
loss: 6.144799  [ 4290/ 7851]
loss: 7.543875  [ 4758/ 7851]
loss: 5.971556  [ 5226/ 7851]
loss: 9.102015  [ 5694/ 7851]
loss: 7.464038  [ 6162/ 7851]
loss: 6.493937  [ 6630/ 7851]
loss: 4.919205  [ 7098/ 7851]
loss: 6.197500  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 6.499964 
Epoch 18
-------------------------------
loss: 6.291971  [   79/ 7851]
loss: 5.489320  [  547/ 7851]
loss: 4.935051  [ 1015/ 7851]
loss: 6.685251  [ 1483/ 7851]
loss: 6.214506  [ 1951/ 7851]
loss: 7.061466  [ 2419/ 7851]
loss: 6.062071  [ 2887/ 7851]
loss: 9.168921  [ 3355/ 7851]
loss: 5.138449  [ 3823/ 7851]
loss: 5.707016  [ 4290/ 7851]
loss: 7.619437  [ 4758/ 7851]
loss: 6.414642  [ 5226/ 7851]
loss: 8.853467  [ 5694/ 7851]
loss: 7.462567  [ 6162/ 7851]
loss: 5.720655  [ 6630/ 7851]
loss: 4.831117  [ 7098/ 7851]
loss: 6.273205  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 6.527454 
Epoch 19
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 1, 1]           6,480
│    └─ReLU: 2-2                         [100, 80, 1, 1]           --
│    └─Flatten: 2-3                      [100, 80]                 --
==========================================================================================
Total params: 6,480
Trainable params: 6,480
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.65
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.06
Params size (MB): 0.03
Estimated Total Size (MB): 0.12
==========================================================================================
Epoch 1
-------------------------------
loss: 10.977759  [   79/ 7851]
loss: 7.774559  [  547/ 7851]
loss: 9.964613  [ 1015/ 7851]
loss: 7.507228  [ 1483/ 7851]
loss: 8.388787  [ 1951/ 7851]
loss: 6.895623  [ 2419/ 7851]
loss: 6.789528  [ 2887/ 7851]
loss: 10.215988  [ 3355/ 7851]
loss: 11.474747  [ 3823/ 7851]
loss: 10.178980  [ 4290/ 7851]
loss: 6.701463  [ 4758/ 7851]
loss: 8.826473  [ 5226/ 7851]
loss: 7.751354  [ 5694/ 7851]
loss: 7.383013  [ 6162/ 7851]
loss: 6.964880  [ 6630/ 7851]
loss: 8.014121  [ 7098/ 7851]
loss: 8.550282  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 8.001467 
Epoch 2
-------------------------------
loss: 6.033861  [   79/ 7851]
loss: 6.699434  [  547/ 7851]
loss: 8.685600  [ 1015/ 7851]
loss: 7.136777  [ 1483/ 7851]
loss: 7.964077  [ 1951/ 7851]
loss: 6.612887  [ 2419/ 7851]
loss: 6.210059  [ 2887/ 7851]
loss: 9.840217  [ 3355/ 7851]
loss: 11.401856  [ 3823/ 7851]
loss: 10.215348  [ 4290/ 7851]
loss: 6.346619  [ 4758/ 7851]
loss: 8.930408  [ 5226/ 7851]
loss: 7.431459  [ 5694/ 7851]
loss: 7.481643  [ 6162/ 7851]
loss: 6.625602  [ 6630/ 7851]
loss: 7.675338  [ 7098/ 7851]
loss: 8.125787  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.4%, Avg loss: 7.634116 
Epoch 3
-------------------------------
loss: 5.823849  [   79/ 7851]
loss: 6.342855  [  547/ 7851]
loss: 8.080032  [ 1015/ 7851]
loss: 7.303011  [ 1483/ 7851]
loss: 7.306412  [ 1951/ 7851]
loss: 6.947021  [ 2419/ 7851]
loss: 6.306186  [ 2887/ 7851]
loss: 9.351337  [ 3355/ 7851]
loss: 11.391308  [ 3823/ 7851]
loss: 9.749024  [ 4290/ 7851]
loss: 6.627066  [ 4758/ 7851]
loss: 8.836556  [ 5226/ 7851]
loss: 7.315782  [ 5694/ 7851]
loss: 7.269149  [ 6162/ 7851]
loss: 6.467629  [ 6630/ 7851]
loss: 7.455993  [ 7098/ 7851]
loss: 8.137638  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.0%, Avg loss: 7.575622 
Epoch 4
-------------------------------
loss: 5.596850  [   79/ 7851]
loss: 6.310784  [  547/ 7851]
loss: 7.718166  [ 1015/ 7851]
loss: 7.129376  [ 1483/ 7851]
loss: 6.902556  [ 1951/ 7851]
loss: 6.966663  [ 2419/ 7851]
loss: 6.394950  [ 2887/ 7851]
loss: 9.643956  [ 3355/ 7851]
loss: 11.890841  [ 3823/ 7851]
loss: 9.733354  [ 4290/ 7851]
loss: 6.643202  [ 4758/ 7851]
loss: 9.018370  [ 5226/ 7851]
loss: 7.313285  [ 5694/ 7851]
loss: 6.742087  [ 6162/ 7851]
loss: 6.446669  [ 6630/ 7851]
loss: 7.694448  [ 7098/ 7851]
loss: 7.982242  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.737044 
Epoch 5
-------------------------------
loss: 5.390763  [   79/ 7851]
loss: 6.250090  [  547/ 7851]
loss: 7.525199  [ 1015/ 7851]
loss: 7.088665  [ 1483/ 7851]
loss: 7.543634  [ 1951/ 7851]
loss: 6.905749  [ 2419/ 7851]
loss: 5.989652  [ 2887/ 7851]
loss: 9.413839  [ 3355/ 7851]
loss: 11.327650  [ 3823/ 7851]
loss: 9.463096  [ 4290/ 7851]
loss: 6.765826  [ 4758/ 7851]
loss: 9.156572  [ 5226/ 7851]
loss: 6.871936  [ 5694/ 7851]
loss: 7.558944  [ 6162/ 7851]
loss: 6.318215  [ 6630/ 7851]
loss: 7.803257  [ 7098/ 7851]
loss: 8.161950  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.8%, Avg loss: 7.451927 
Epoch 6
-------------------------------
loss: 5.832905  [   79/ 7851]
loss: 6.758084  [  547/ 7851]
loss: 8.562880  [ 1015/ 7851]
loss: 7.495832  [ 1483/ 7851]
loss: 7.302751  [ 1951/ 7851]
loss: 6.850999  [ 2419/ 7851]
loss: 5.696562  [ 2887/ 7851]
loss: 9.530654  [ 3355/ 7851]
loss: 12.120582  [ 3823/ 7851]
loss: 9.708831  [ 4290/ 7851]
loss: 6.431690  [ 4758/ 7851]
loss: 9.431325  [ 5226/ 7851]
loss: 7.666153  [ 5694/ 7851]
loss: 7.170368  [ 6162/ 7851]
loss: 6.369277  [ 6630/ 7851]
loss: 7.511598  [ 7098/ 7851]
loss: 7.821345  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 7.399711 
Epoch 7
-------------------------------
loss: 5.674919  [   79/ 7851]
loss: 6.340860  [  547/ 7851]
loss: 7.967204  [ 1015/ 7851]
loss: 6.965716  [ 1483/ 7851]
loss: 7.407755  [ 1951/ 7851]
loss: 7.012341  [ 2419/ 7851]
loss: 6.332914  [ 2887/ 7851]
loss: 9.623754  [ 3355/ 7851]
loss: 11.231345  [ 3823/ 7851]
loss: 9.553580  [ 4290/ 7851]
loss: 6.679574  [ 4758/ 7851]
loss: 8.871093  [ 5226/ 7851]
loss: 6.903636  [ 5694/ 7851]
loss: 6.968544  [ 6162/ 7851]
loss: 6.481755  [ 6630/ 7851]
loss: 7.581374  [ 7098/ 7851]
loss: 8.187981  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.693392 
Epoch 8
-------------------------------
loss: 5.571206  [   79/ 7851]
loss: 6.563344  [  547/ 7851]
loss: 8.041107  [ 1015/ 7851]
loss: 7.091693  [ 1483/ 7851]
loss: 7.539416  [ 1951/ 7851]
loss: 6.898485  [ 2419/ 7851]
loss: 6.078157  [ 2887/ 7851]
loss: 9.112882  [ 3355/ 7851]
loss: 11.535704  [ 3823/ 7851]
loss: 9.355566  [ 4290/ 7851]
loss: 6.161992  [ 4758/ 7851]
loss: 9.165371  [ 5226/ 7851]
loss: 7.322710  [ 5694/ 7851]
loss: 7.099133  [ 6162/ 7851]
loss: 6.260306  [ 6630/ 7851]
loss: 7.392636  [ 7098/ 7851]
loss: 8.267707  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.7%, Avg loss: 7.137795 
Epoch 9
-------------------------------
loss: 5.719648  [   79/ 7851]
loss: 5.934439  [  547/ 7851]
loss: 8.028383  [ 1015/ 7851]
loss: 7.420923  [ 1483/ 7851]
loss: 7.479456  [ 1951/ 7851]
loss: 7.132706  [ 2419/ 7851]
loss: 5.778689  [ 2887/ 7851]
loss: 8.702036  [ 3355/ 7851]
loss: 11.443072  [ 3823/ 7851]
loss: 9.424861  [ 4290/ 7851]
loss: 6.437596  [ 4758/ 7851]
loss: 9.191123  [ 5226/ 7851]
loss: 7.073197  [ 5694/ 7851]
loss: 7.081012  [ 6162/ 7851]
loss: 5.980263  [ 6630/ 7851]
loss: 7.585906  [ 7098/ 7851]
loss: 7.618793  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 7.629063 
Epoch 10
-------------------------------
loss: 5.268503  [   79/ 7851]
loss: 5.905924  [  547/ 7851]
loss: 7.888595  [ 1015/ 7851]
loss: 7.421648  [ 1483/ 7851]
loss: 7.500035  [ 1951/ 7851]
loss: 7.267570  [ 2419/ 7851]
loss: 6.207555  [ 2887/ 7851]
loss: 9.229640  [ 3355/ 7851]
loss: 11.839705  [ 3823/ 7851]
loss: 9.477572  [ 4290/ 7851]
loss: 6.872797  [ 4758/ 7851]
loss: 9.030026  [ 5226/ 7851]
loss: 7.351844  [ 5694/ 7851]
loss: 7.110467  [ 6162/ 7851]
loss: 6.337102  [ 6630/ 7851]
loss: 6.521395  [ 7098/ 7851]
loss: 8.018910  [ 7566/ 7851]

Test Error: 
 Accuracy: 3.6%, Avg loss: 7.120629 
Epoch 11
-------------------------------
loss: 5.709116  [   79/ 7851]
loss: 5.988697  [  547/ 7851]
loss: 7.947624  [ 1015/ 7851]
loss: 7.186679  [ 1483/ 7851]
loss: 7.366034  [ 1951/ 7851]
loss: 6.706835  [ 2419/ 7851]
loss: 6.068639  [ 2887/ 7851]
loss: 9.204034  [ 3355/ 7851]
loss: 11.173079  [ 3823/ 7851]
loss: 9.625435  [ 4290/ 7851]
loss: 6.991294  [ 4758/ 7851]
loss: 8.649918  [ 5226/ 7851]
loss: 7.312530  [ 5694/ 7851]
loss: 6.804076  [ 6162/ 7851]
loss: 5.934481  [ 6630/ 7851]
loss: 6.677644  [ 7098/ 7851]
loss: 7.941318  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.7%, Avg loss: 7.647485 
Epoch 12
-------------------------------
loss: 5.371813  [   79/ 7851]
loss: 5.916508  [  547/ 7851]
loss: 8.115167  [ 1015/ 7851]
loss: 7.314851  [ 1483/ 7851]
loss: 7.625547  [ 1951/ 7851]
loss: 6.682290  [ 2419/ 7851]
loss: 5.728596  [ 2887/ 7851]
loss: 9.526825  [ 3355/ 7851]
loss: 11.305022  [ 3823/ 7851]
loss: 9.764138  [ 4290/ 7851]
loss: 6.352104  [ 4758/ 7851]
loss: 8.647135  [ 5226/ 7851]
loss: 6.457970  [ 5694/ 7851]
loss: 6.891017  [ 6162/ 7851]
loss: 6.225855  [ 6630/ 7851]
loss: 7.145678  [ 7098/ 7851]
loss: 7.392854  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.5%, Avg loss: 7.644557 
Epoch 13
-------------------------------
loss: 5.241189  [   79/ 7851]
loss: 5.741755  [  547/ 7851]
loss: 7.532978  [ 1015/ 7851]
loss: 6.605175  [ 1483/ 7851]
loss: 7.169853  [ 1951/ 7851]
loss: 6.637759  [ 2419/ 7851]
loss: 5.444372  [ 2887/ 7851]
loss: 9.532275  [ 3355/ 7851]
loss: 11.202136  [ 3823/ 7851]
loss: 9.282464  [ 4290/ 7851]
loss: 6.248079  [ 4758/ 7851]
loss: 8.300900  [ 5226/ 7851]
loss: 6.566645  [ 5694/ 7851]
loss: 7.000410  [ 6162/ 7851]
loss: 5.577622  [ 6630/ 7851]
loss: 7.225651  [ 7098/ 7851]
loss: 7.836546  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.2%, Avg loss: 7.484878 
Epoch 14
-------------------------------
loss: 5.354201  [   79/ 7851]
loss: 6.268432  [  547/ 7851]
loss: 7.596130  [ 1015/ 7851]
loss: 7.668263  [ 1483/ 7851]
loss: 7.450712  [ 1951/ 7851]
loss: 6.856940  [ 2419/ 7851]
loss: 6.046337  [ 2887/ 7851]
loss: 9.346895  [ 3355/ 7851]
loss: 11.292747  [ 3823/ 7851]
loss: 9.144619  [ 4290/ 7851]
loss: 6.530077  [ 4758/ 7851]
loss: 8.942327  [ 5226/ 7851]
loss: 6.882205  [ 5694/ 7851]
loss: 7.001664  [ 6162/ 7851]
loss: 6.401904  [ 6630/ 7851]
loss: 6.837022  [ 7098/ 7851]
loss: 7.282351  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.050766 
Epoch 15
-------------------------------
loss: 5.706825  [   79/ 7851]
loss: 5.867958  [  547/ 7851]
loss: 7.715364  [ 1015/ 7851]
loss: 7.194902  [ 1483/ 7851]
loss: 6.827129  [ 1951/ 7851]
loss: 6.747868  [ 2419/ 7851]
loss: 5.846369  [ 2887/ 7851]
loss: 8.664590  [ 3355/ 7851]
loss: 11.427677  [ 3823/ 7851]
loss: 9.678191  [ 4290/ 7851]
loss: 6.265191  [ 4758/ 7851]
loss: 8.604462  [ 5226/ 7851]
loss: 7.123045  [ 5694/ 7851]
loss: 7.189146  [ 6162/ 7851]
loss: 6.250697  [ 6630/ 7851]
loss: 7.321198  [ 7098/ 7851]
loss: 7.543437  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.3%, Avg loss: 7.299546 
Epoch 16
-------------------------------
loss: 5.708054  [   79/ 7851]
loss: 5.956081  [  547/ 7851]
loss: 7.957664  [ 1015/ 7851]
loss: 7.605587  [ 1483/ 7851]
loss: 7.250011  [ 1951/ 7851]
loss: 7.153509  [ 2419/ 7851]
loss: 5.677962  [ 2887/ 7851]
loss: 8.612642  [ 3355/ 7851]
loss: 11.021016  [ 3823/ 7851]
loss: 9.830912  [ 4290/ 7851]
loss: 6.106967  [ 4758/ 7851]
loss: 8.393826  [ 5226/ 7851]
loss: 7.146409  [ 5694/ 7851]
loss: 7.219676  [ 6162/ 7851]
loss: 6.656624  [ 6630/ 7851]
loss: 7.686798  [ 7098/ 7851]
loss: 8.127925  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.1%, Avg loss: 7.524139 
Epoch 17
-------------------------------
loss: 5.143137  [   79/ 7851]
loss: 6.105294  [  547/ 7851]
loss: 7.810017  [ 1015/ 7851]
loss: 7.022592  [ 1483/ 7851]
loss: 6.950724  [ 1951/ 7851]
loss: 6.475351  [ 2419/ 7851]
loss: 5.552331  [ 2887/ 7851]
loss: 8.998702  [ 3355/ 7851]
loss: 12.018043  [ 3823/ 7851]
loss: 9.066474  [ 4290/ 7851]
loss: 5.985057  [ 4758/ 7851]
loss: 8.749279  [ 5226/ 7851]
loss: 7.264384  [ 5694/ 7851]
loss: 6.727007  [ 6162/ 7851]
loss: 6.216627  [ 6630/ 7851]
loss: 7.322214  [ 7098/ 7851]
loss: 7.630228  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.6%, Avg loss: 7.295313 
Epoch 18
-------------------------------
loss: 4.947660  [   79/ 7851]
loss: 5.701716  [  547/ 7851]
loss: 7.516234  [ 1015/ 7851]
loss: 7.064013  [ 1483/ 7851]
loss: 7.243126  [ 1951/ 7851]
loss: 6.819178  [ 2419/ 7851]
loss: 5.647759  [ 2887/ 7851]
loss: 8.950664  [ 3355/ 7851]
loss: 11.612376  [ 3823/ 7851]
loss: 9.751838  [ 4290/ 7851]
loss: 6.343830  [ 4758/ 7851]
loss: 8.672188  [ 5226/ 7851]
loss: 7.829973  [ 5694/ 7851]
loss: 6.475136  [ 6162/ 7851]
loss: 6.492316  [ 6630/ 7851]
loss: 7.062144  [ 7098/ 7851]
loss: 8.102310  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 7.588497 
Epoch 19
-------------------------------
loss: 5.295357  [   79/ 7851]
loss: 6.124084  [  547/ 7851]
loss: 7.531323  [ 1015/ 7851]
loss: 7.212833  [ 1483/ 7851]
loss: 7.295227  [ 1951/ 7851]
loss: 6.554568  [ 2419/ 7851]
loss: 6.119759  [ 2887/ 7851]
loss: 8.476532  [ 3355/ 7851]
loss: 11.394729  [ 3823/ 7851]
loss: 9.368828  [ 4290/ 7851]
loss: 6.423232  [ 4758/ 7851]
loss: 9.018670  [ 5226/ 7851]
loss: 7.117594  [ 5694/ 7851]
loss: 7.103085  [ 6162/ 7851]
loss: 6.777576  [ 6630/ 7851]
loss: 7.300801  [ 7098/ 7851]
loss: 7.642693  [ 7566/ 7851]

Test Error: 
 Accuracy: 1.9%, Avg loss: 7.626674 
Epoch 20
-------------------------------
loss: 5.629773  [   79/ 7851]
loss: 6.211013  [  547/ 7851]
loss: 7.359876  [ 1015/ 7851]
loss: 7.231119  [ 1483/ 7851]
loss: 7.046533  [ 1951/ 7851]
loss: 6.423444  [ 2419/ 7851]
loss: 6.330708  [ 2887/ 7851]
loss: 9.143337  [ 3355/ 7851]
loss: 10.659943  [ 3823/ 7851]
loss: 9.648212  [ 4290/ 7851]
loss: 6.509857  [ 4758/ 7851]
loss: 9.523771  [ 5226/ 7851]
loss: 6.837391  [ 5694/ 7851]
loss: 6.647967  [ 6162/ 7851]
loss: 6.266617  [ 6630/ 7851]
loss: 7.069164  [ 7098/ 7851]
loss: 7.355098  [ 7566/ 7851]

Test Error: 
 Accuracy: 2.6%, Avg loss: 7.306850 
Done!
Model weights saved to model_weights/Extreme.pth
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
Training Model
===============================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Extreme                                  [100, 40, 2]              --
├─Sequential: 1-1                        [100, 80]                 --
│    └─Conv2d: 2-1                       [100, 80, 41, 3]          400
│    └─ReLU: 2-2                         [100, 80, 41, 3]          --
│    └─Conv2d: 2-3                       [100, 400, 40, 2]         128,400
│    └─Flatten: 2-4                      [100, 32000]              --
│    └─ReLU: 2-5                         [100, 32000]              --
│    └─Linear: 2-6                       [100, 80]                 2,560,080
==========================================================================================
Total params: 2,688,880
Trainable params: 2,688,880
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.29
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 33.54
Params size (MB): 10.76
Estimated Total Size (MB): 44.32
==========================================================================================
Epoch 1
-------------------------------
loss: 14.317626  [  148/14783]
loss: 10663.628906  [ 1030/14783]
loss: 53.601646  [ 1912/14783]
loss: 6.831043  [ 2794/14783]
loss: 8.146793  [ 3676/14783]
loss: 8.390823  [ 4558/14783]
loss: 6.168657  [ 5440/14783]
loss: 8.949517  [ 6322/14783]
loss: 8.837971  [ 7204/14783]
loss: 6.984076  [ 8086/14783]
loss: 5.877842  [ 8968/14783]
loss: 8.271973  [ 9850/14783]
loss: 5.825209  [10732/14783]
loss: 8.653880  [11614/14783]
loss: 7.244071  [12495/14783]
loss: 6.974285  [13377/14783]
loss: 5.980665  [14259/14783]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.309310 
Epoch 2
-------------------------------
loss: 6.592274  [  148/14783]
loss: 6.602267  [ 1030/14783]
loss: 6.953444  [ 1912/14783]
loss: 5.893221  [ 2794/14783]
loss: 6.984351  [ 3676/14783]
loss: 5.276759  [ 4558/14783]
loss: 5.772017  [ 5440/14783]
loss: 8.499352  [ 6322/14783]
loss: 8.711049  [ 7204/14783]
loss: 6.472780  [ 8086/14783]
loss: 5.855661  [ 8968/14783]
loss: 8.367307  [ 9850/14783]
loss: 5.892747  [10732/14783]
loss: 8.614151  [11614/14783]
loss: 7.227006  [12495/14783]
loss: 6.968215  [13377/14783]
loss: 5.970733  [14259/14783]

Test Error: 
 Accuracy: 1.0%, Avg loss: 6.311792 
Epoch 3
-------------------------------
loss: 6.591340  [  148/14783]
loss: 6.593228  [ 1030/14783]
loss: 6.956303  [ 1912/14783]
loss: 5.891838  [ 2794/14783]
loss: 6.977938  [ 3676/14783]
loss: 5.270148  [ 4558/14783]
loss: 5.768390  [ 5440/14783]
loss: 8.500355  [ 6322/14783]
loss: 8.710770  [ 7204/14783]
loss: 6.493834  [ 8086/14783]
loss: 5.856525  [ 8968/14783]
loss: 8.394110  [ 9850/14783]
loss: 5.902160  [10732/14783]
loss: 8.613964  [11614/14783]
loss: 7.227175  [12495/14783]
loss: 6.967766  [13377/14783]
loss: 5.969966  [14259/14783]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.312274 
Epoch 4
-------------------------------
loss: 6.591527  [  148/14783]
loss: 6.592683  [ 1030/14783]
loss: 6.957249  [ 1912/14783]
loss: 5.891705  [ 2794/14783]
loss: 6.975697  [ 3676/14783]
loss: 5.267793  [ 4558/14783]
loss: 5.763524  [ 5440/14783]
loss: 8.501871  [ 6322/14783]
loss: 8.707471  [ 7204/14783]
loss: 6.509970  [ 8086/14783]
loss: 5.857566  [ 8968/14783]
loss: 8.415406  [ 9850/14783]
loss: 5.909126  [10732/14783]
loss: 8.613560  [11614/14783]
loss: 7.227205  [12495/14783]
loss: 6.967624  [13377/14783]
loss: 5.969380  [14259/14783]

Test Error: 
 Accuracy: 1.1%, Avg loss: 6.312625 
Epoch 5
-------------------------------
loss: 6.591685  [  148/14783]
loss: 6.592436  [ 1030/14783]
loss: 6.957774  [ 1912/14783]
loss: 5.891258  [ 2794/14783]
loss: 6.974410  [ 3676/14783]
loss: 5.266572  [ 4558/14783]
loss: 5.759259  [ 5440/14783]
loss: 8.503261  [ 6322/14783]
loss: 8.704123  [ 7204/14783]
loss: 6.521633  [ 8086/14783]
loss: 5.858680  [ 8968/14783]
loss: 8.431255  [ 9850/14783]
loss: 5.915057  [10732/14783]
loss: 8.613126  [11614/14783]
loss: 7.227196  [12495/14783]
loss: 6.967760  [13377/14783]
loss: 5.968909  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.312871 
Epoch 6
-------------------------------
loss: 6.591815  [  148/14783]
loss: 6.592371  [ 1030/14783]
loss: 6.958063  [ 1912/14783]
loss: 5.890821  [ 2794/14783]
loss: 6.973638  [ 3676/14783]
loss: 5.265869  [ 4558/14783]
loss: 5.755837  [ 5440/14783]
loss: 8.504475  [ 6322/14783]
loss: 8.701241  [ 7204/14783]
loss: 6.530060  [ 8086/14783]
loss: 5.859766  [ 8968/14783]
loss: 8.442962  [ 9850/14783]
loss: 5.920175  [10732/14783]
loss: 8.612747  [11614/14783]
loss: 7.227174  [12495/14783]
loss: 6.968022  [13377/14783]
loss: 5.968542  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313037 
Epoch 7
-------------------------------
loss: 6.591917  [  148/14783]
loss: 6.592392  [ 1030/14783]
loss: 6.958223  [ 1912/14783]
loss: 5.890459  [ 2794/14783]
loss: 6.973151  [ 3676/14783]
loss: 5.265433  [ 4558/14783]
loss: 5.753119  [ 5440/14783]
loss: 8.505539  [ 6322/14783]
loss: 8.698878  [ 7204/14783]
loss: 6.536268  [ 8086/14783]
loss: 5.860763  [ 8968/14783]
loss: 8.451676  [ 9850/14783]
loss: 5.924546  [10732/14783]
loss: 8.612443  [11614/14783]
loss: 7.227140  [12495/14783]
loss: 6.968317  [13377/14783]
loss: 5.968260  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313146 
Epoch 8
-------------------------------
loss: 6.591990  [  148/14783]
loss: 6.592445  [ 1030/14783]
loss: 6.958307  [ 1912/14783]
loss: 5.890172  [ 2794/14783]
loss: 6.972830  [ 3676/14783]
loss: 5.265149  [ 4558/14783]
loss: 5.750931  [ 5440/14783]
loss: 8.506474  [ 6322/14783]
loss: 8.696948  [ 7204/14783]
loss: 6.540953  [ 8086/14783]
loss: 5.861653  [ 8968/14783]
loss: 8.458267  [ 9850/14783]
loss: 5.928245  [10732/14783]
loss: 8.612206  [11614/14783]
loss: 7.227097  [12495/14783]
loss: 6.968602  [13377/14783]
loss: 5.968051  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313211 
Epoch 9
-------------------------------
loss: 6.592035  [  148/14783]
loss: 6.592507  [ 1030/14783]
loss: 6.958350  [ 1912/14783]
loss: 5.889948  [ 2794/14783]
loss: 6.972611  [ 3676/14783]
loss: 5.264958  [ 4558/14783]
loss: 5.749147  [ 5440/14783]
loss: 8.507297  [ 6322/14783]
loss: 8.695357  [ 7204/14783]
loss: 6.544571  [ 8086/14783]
loss: 5.862430  [ 8968/14783]
loss: 8.463353  [ 9850/14783]
loss: 5.931357  [10732/14783]
loss: 8.612023  [11614/14783]
loss: 7.227049  [12495/14783]
loss: 6.968858  [13377/14783]
loss: 5.967901  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313247 
Epoch 10
-------------------------------
loss: 6.592057  [  148/14783]
loss: 6.592566  [ 1030/14783]
loss: 6.958371  [ 1912/14783]
loss: 5.889774  [ 2794/14783]
loss: 6.972455  [ 3676/14783]
loss: 5.264827  [ 4558/14783]
loss: 5.747676  [ 5440/14783]
loss: 8.508019  [ 6322/14783]
loss: 8.694027  [ 7204/14783]
loss: 6.547423  [ 8086/14783]
loss: 5.863102  [ 8968/14783]
loss: 8.467355  [ 9850/14783]
loss: 5.933973  [10732/14783]
loss: 8.611879  [11614/14783]
loss: 7.226998  [12495/14783]
loss: 6.969082  [13377/14783]
loss: 5.967797  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313262 
Epoch 11
-------------------------------
loss: 6.592060  [  148/14783]
loss: 6.592621  [ 1030/14783]
loss: 6.958384  [ 1912/14783]
loss: 5.889640  [ 2794/14783]
loss: 6.972341  [ 3676/14783]
loss: 5.264734  [ 4558/14783]
loss: 5.746449  [ 5440/14783]
loss: 8.508651  [ 6322/14783]
loss: 8.692896  [ 7204/14783]
loss: 6.549711  [ 8086/14783]
loss: 5.863680  [ 8968/14783]
loss: 8.470570  [ 9850/14783]
loss: 5.936174  [10732/14783]
loss: 8.611767  [11614/14783]
loss: 7.226948  [12495/14783]
loss: 6.969274  [13377/14783]
loss: 5.967730  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313262 
Epoch 12
-------------------------------
loss: 6.592049  [  148/14783]
loss: 6.592669  [ 1030/14783]
loss: 6.958396  [ 1912/14783]
loss: 5.889537  [ 2794/14783]
loss: 6.972255  [ 3676/14783]
loss: 5.264667  [ 4558/14783]
loss: 5.745417  [ 5440/14783]
loss: 8.509205  [ 6322/14783]
loss: 8.691923  [ 7204/14783]
loss: 6.551573  [ 8086/14783]
loss: 5.864174  [ 8968/14783]
loss: 8.473193  [ 9850/14783]
loss: 5.938029  [10732/14783]
loss: 8.611676  [11614/14783]
loss: 7.226902  [12495/14783]
loss: 6.969436  [13377/14783]
loss: 5.967690  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313254 
Epoch 13
-------------------------------
loss: 6.592030  [  148/14783]
loss: 6.592712  [ 1030/14783]
loss: 6.958409  [ 1912/14783]
loss: 5.889459  [ 2794/14783]
loss: 6.972189  [ 3676/14783]
loss: 5.264617  [ 4558/14783]
loss: 5.744545  [ 5440/14783]
loss: 8.509689  [ 6322/14783]
loss: 8.691083  [ 7204/14783]
loss: 6.553109  [ 8086/14783]
loss: 5.864596  [ 8968/14783]
loss: 8.475367  [ 9850/14783]
loss: 5.939598  [10732/14783]
loss: 8.611603  [11614/14783]
loss: 7.226858  [12495/14783]
loss: 6.969573  [13377/14783]
loss: 5.967672  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313239 
Epoch 14
-------------------------------
loss: 6.592003  [  148/14783]
loss: 6.592750  [ 1030/14783]
loss: 6.958426  [ 1912/14783]
loss: 5.889399  [ 2794/14783]
loss: 6.972139  [ 3676/14783]
loss: 5.264579  [ 4558/14783]
loss: 5.743802  [ 5440/14783]
loss: 8.510112  [ 6322/14783]
loss: 8.690348  [ 7204/14783]
loss: 6.554387  [ 8086/14783]
loss: 5.864956  [ 8968/14783]
loss: 8.477193  [ 9850/14783]
loss: 5.940932  [10732/14783]
loss: 8.611544  [11614/14783]
loss: 7.226819  [12495/14783]
loss: 6.969688  [13377/14783]
loss: 5.967669  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313221 
Epoch 15
-------------------------------
loss: 6.591973  [  148/14783]
loss: 6.592783  [ 1030/14783]
loss: 6.958448  [ 1912/14783]
loss: 5.889354  [ 2794/14783]
loss: 6.972101  [ 3676/14783]
loss: 5.264552  [ 4558/14783]
loss: 5.743165  [ 5440/14783]
loss: 8.510485  [ 6322/14783]
loss: 8.689701  [ 7204/14783]
loss: 6.555463  [ 8086/14783]
loss: 5.865262  [ 8968/14783]
loss: 8.478741  [ 9850/14783]
loss: 5.942069  [10732/14783]
loss: 8.611495  [11614/14783]
loss: 7.226784  [12495/14783]
loss: 6.969784  [13377/14783]
loss: 5.967674  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313201 
Epoch 16
-------------------------------
loss: 6.591942  [  148/14783]
loss: 6.592813  [ 1030/14783]
loss: 6.958472  [ 1912/14783]
loss: 5.889320  [ 2794/14783]
loss: 6.972070  [ 3676/14783]
loss: 5.264528  [ 4558/14783]
loss: 5.742616  [ 5440/14783]
loss: 8.510811  [ 6322/14783]
loss: 8.689133  [ 7204/14783]
loss: 6.556374  [ 8086/14783]
loss: 5.865523  [ 8968/14783]
loss: 8.480064  [ 9850/14783]
loss: 5.943042  [10732/14783]
loss: 8.611455  [11614/14783]
loss: 7.226754  [12495/14783]
loss: 6.969864  [13377/14783]
loss: 5.967689  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313181 
Epoch 17
-------------------------------
loss: 6.591912  [  148/14783]
loss: 6.592839  [ 1030/14783]
loss: 6.958499  [ 1912/14783]
loss: 5.889294  [ 2794/14783]
loss: 6.972049  [ 3676/14783]
loss: 5.264510  [ 4558/14783]
loss: 5.742142  [ 5440/14783]
loss: 8.511099  [ 6322/14783]
loss: 8.688628  [ 7204/14783]
loss: 6.557149  [ 8086/14783]
loss: 5.865745  [ 8968/14783]
loss: 8.481205  [ 9850/14783]
loss: 5.943879  [10732/14783]
loss: 8.611423  [11614/14783]
loss: 7.226726  [12495/14783]
loss: 6.969931  [13377/14783]
loss: 5.967709  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313162 
Epoch 18
-------------------------------
loss: 6.591881  [  148/14783]
loss: 6.592863  [ 1030/14783]
loss: 6.958529  [ 1912/14783]
loss: 5.889274  [ 2794/14783]
loss: 6.972032  [ 3676/14783]
loss: 5.264494  [ 4558/14783]
loss: 5.741730  [ 5440/14783]
loss: 8.511353  [ 6322/14783]
loss: 8.688181  [ 7204/14783]
loss: 6.557815  [ 8086/14783]
loss: 5.865933  [ 8968/14783]
loss: 8.482195  [ 9850/14783]
loss: 5.944601  [10732/14783]
loss: 8.611395  [11614/14783]
loss: 7.226703  [12495/14783]
loss: 6.969988  [13377/14783]
loss: 5.967731  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313143 
Epoch 19
-------------------------------
loss: 6.591854  [  148/14783]
loss: 6.592883  [ 1030/14783]
loss: 6.958558  [ 1912/14783]
loss: 5.889259  [ 2794/14783]
loss: 6.972020  [ 3676/14783]
loss: 5.264482  [ 4558/14783]
loss: 5.741371  [ 5440/14783]
loss: 8.511580  [ 6322/14783]
loss: 8.687784  [ 7204/14783]
loss: 6.558388  [ 8086/14783]
loss: 5.866094  [ 8968/14783]
loss: 8.483057  [ 9850/14783]
loss: 5.945225  [10732/14783]
loss: 8.611372  [11614/14783]
loss: 7.226681  [12495/14783]
loss: 6.970035  [13377/14783]
loss: 5.967755  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313126 
Epoch 20
-------------------------------
loss: 6.591826  [  148/14783]
loss: 6.592901  [ 1030/14783]
loss: 6.958589  [ 1912/14783]
loss: 5.889248  [ 2794/14783]
loss: 6.972012  [ 3676/14783]
loss: 5.264470  [ 4558/14783]
loss: 5.741058  [ 5440/14783]
loss: 8.511781  [ 6322/14783]
loss: 8.687430  [ 7204/14783]
loss: 6.558883  [ 8086/14783]
loss: 5.866231  [ 8968/14783]
loss: 8.483809  [ 9850/14783]
loss: 5.945768  [10732/14783]
loss: 8.611353  [11614/14783]
loss: 7.226663  [12495/14783]
loss: 6.970075  [13377/14783]
loss: 5.967780  [14259/14783]

Test Error: 
 Accuracy: 1.2%, Avg loss: 6.313110 
Done!
Model weights saved to model_weights/Extreme.pth
